{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ea6e917",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of characters 20479\n",
      "I HAD always thought Jack Gisburn rather a cheap genius--though a good fellow enough--so it was no \n"
     ]
    }
   ],
   "source": [
    "with open(\"the-verdict.txt\",\"r\", encoding = \"utf-8\") as f:\n",
    "    raw_text=f.read()\n",
    "    \n",
    "print(\"Number of characters\", len(raw_text))\n",
    "print(raw_text[:99])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7743ec3a",
   "metadata": {},
   "source": [
    "# Creating Tokenizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "289bf1a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello', ',', '', ' ', 'world', '.', '', ' ', '', '--', 'Hi', ' ', 'I', \"'\", 'm', ' ', 'LLM', ',', '', ' ', 'Is', ' ', 'a', ' ', 'test', '?', '', ' ', 'If', ' ', 'yes', ':', '', ' ', 'I', \"'\", 'm', ' ', 'going', ' ', 'to', ' ', 'smash', ' ', 'it', '!', '']\n",
      "\n",
      " ['Hello', ',', 'world', '.', '--', 'Hi', 'I', \"'\", 'm', 'LLM', ',', 'Is', 'a', 'test', '?', 'If', 'yes', ':', 'I', \"'\", 'm', 'going', 'to', 'smash', 'it', '!']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "text = \"Hello, world. --Hi I'm LLM, Is a test? If yes: I'm going to smash it!\"\n",
    "result = re.split(r'([,.:;?_!\"()\\']|--|\\s)', text)\n",
    "print(result)\n",
    "result =[item.strip() for item in result if item.strip()]\n",
    "print('\\n',result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "639c0a25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'HAD', 'always', 'thought', 'Jack', 'Gisburn', 'rather', 'a', 'cheap', 'genius', '--', 'though', 'a', 'good', 'fellow', 'enough', '--', 'so', 'it', 'was', 'no', 'great', 'surprise', 'to', 'me', 'to', 'hear', 'that', ',', 'in', 'the', 'height', 'of', 'his', 'glory', ',', 'he', 'had', 'dropped', 'his', 'painting', ',', 'married', 'a', 'rich', 'widow', ',', 'and', 'established', 'himself']\n",
      "\n",
      " 4690\n"
     ]
    }
   ],
   "source": [
    "preprocessed = re.split(r'([,.:;?_!\"()\\']|--|\\s)', raw_text)\n",
    "preprocessed =[item.strip() for item in preprocessed if item.strip()]\n",
    "print(preprocessed[:50])\n",
    "print('\\n',len(preprocessed))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d281234c",
   "metadata": {},
   "source": [
    "# Creating Token IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5254115",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1130\n"
     ]
    }
   ],
   "source": [
    "words = sorted(set(preprocessed))\n",
    "\n",
    "print(len(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3155f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = {token:integer for integer,token in enumerate(words)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c67d3522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0: !\n",
      " 1: \"\n",
      " 2: '\n",
      " 3: (\n",
      " 4: )\n",
      " 5: ,\n",
      " 6: --\n",
      " 7: .\n",
      " 8: :\n",
      " 9: ;\n",
      "10: ?\n",
      "11: A\n",
      "12: Ah\n",
      "13: Among\n",
      "14: And\n",
      "15: Are\n",
      "16: Arrt\n",
      "17: As\n",
      "18: At\n",
      "19: Be\n"
     ]
    }
   ],
   "source": [
    "for i, (token, idx) in enumerate(vocab.items()):\n",
    "    if i >= 20:\n",
    "        break\n",
    "    print(f\"{i:2d}: {token}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "943d5685",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleTokenizerV1:\n",
    "    def __init__(self, vocab):\n",
    "        self.str_to_int = vocab\n",
    "        self.int_to_str = {i:s for s,i in vocab.items()}\n",
    "    \n",
    "    def encode(self, text):\n",
    "        preprocessed = re.split(r'([,.:;?_!\"()\\']|--|\\s)', text)\n",
    "        preprocessed = [item.strip() for item in preprocessed if item.strip()]\n",
    "        ids = [self.str_to_int[s] for s in preprocessed]\n",
    "        \n",
    "        return ids\n",
    "        \n",
    "    def decode(self, ids):\n",
    "        text = \" \".join([self.int_to_str[i] for i in ids])\n",
    "\n",
    "        # Remove space before punctuation\n",
    "        text = re.sub(r\"\\s+([,.?;:!()\\\"'])\", r\"\\1\", text)\n",
    "\n",
    "        # Remove space only after opening quotes — not closing\n",
    "        text = re.sub(r'(^|[\\s(\\[\"])\\s+', r'\\1', text)\n",
    "\n",
    "        # Fix -- spacing\n",
    "        text = re.sub(r\"\\s+--\\s+\", \"--\", text)\n",
    "\n",
    "        # Fix common contractions\n",
    "        text = re.sub(r\"'\\s+s\\b\", \"'s\", text)\n",
    "        text = re.sub(r\"'\\s+t\\b\", \"'t\", text)\n",
    "        text = re.sub(r\"'\\s+re\\b\", \"'re\", text)\n",
    "        text = re.sub(r\"'\\s+ve\\b\", \"'ve\", text)\n",
    "        text = re.sub(r\"'\\s+d\\b\", \"'d\", text)\n",
    "        text = re.sub(r\"'\\s+ll\\b\", \"'ll\", text)\n",
    "        text = re.sub(r\"'\\s+m\\b\", \"'m\", text)\n",
    "\n",
    "        # Add space after ?\" or !\" if followed by any letter\n",
    "        text = re.sub(r'([,?.!])(\")([A-Za-z])', r'\\1\\2 \\3', text)\n",
    "\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b7dbf041",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 111, 114, 529, 114, 533, 261, 748, 10, 1, 53, 179, 120, 7]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = SimpleTokenizerV1(vocab)\n",
    "\n",
    "text = \"\"\"\"Why _has_ he chucked painting?\" I asked abruptly.\"\"\"\n",
    "ids = tokenizer.encode(text)\n",
    "print(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "effc0ff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Why _ has _ he chucked painting?\" I asked abruptly.\n"
     ]
    }
   ],
   "source": [
    "text = tokenizer.decode(ids)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b75be6",
   "metadata": {},
   "source": [
    "# Adding Special tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e725647e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1132\n",
      "[('younger', 1127), ('your', 1128), ('yourself', 1129), ('<|endoftext|>', 1130), ('<|unk|>', 1131)]\n"
     ]
    }
   ],
   "source": [
    "all_tokens = sorted(list(set(preprocessed)))\n",
    "all_tokens.extend([\"<|endoftext|>\", \"<|unk|>\"])\n",
    "\n",
    "vocab = {token:integer for integer,token in enumerate(all_tokens)}\n",
    "print(len(vocab))  \n",
    "print(list(vocab.items())[-5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f2e8b26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleTokenizerV2:\n",
    "    def __init__(self, vocab):\n",
    "        self.str_to_int = vocab\n",
    "        self.int_to_str = {i:s for s,i in vocab.items()}\n",
    "    \n",
    "    def encode(self, text):\n",
    "        preprocessed = re.split(r'([,.:;?_!\"()\\']|--|\\s)', text)\n",
    "        preprocessed = [item.strip() for item in preprocessed if item.strip()]\n",
    "        preprocessed = [item if item in self.str_to_int else \"<|unk|>\" for item in preprocessed]\n",
    "        ids = [self.str_to_int[s] for s in preprocessed]\n",
    "        \n",
    "        return ids\n",
    "        \n",
    "    def decode(self, ids):\n",
    "        text = \" \".join([self.int_to_str[i] for i in ids])\n",
    "\n",
    "        # Remove space before punctuation\n",
    "        text = re.sub(r\"\\s+([,.?;:!()\\\"'])\", r\"\\1\", text)\n",
    "\n",
    "        # Remove space only after opening quotes — not closing\n",
    "        text = re.sub(r'(^|[\\s(\\[\"])\\s+', r'\\1', text)\n",
    "\n",
    "        # Fix -- spacing\n",
    "        text = re.sub(r\"\\s+--\\s+\", \"--\", text)\n",
    "\n",
    "        # Fix common contractions\n",
    "        text = re.sub(r\"'\\s+s\\b\", \"'s\", text)\n",
    "        text = re.sub(r\"'\\s+t\\b\", \"'t\", text)\n",
    "        text = re.sub(r\"'\\s+re\\b\", \"'re\", text)\n",
    "        text = re.sub(r\"'\\s+ve\\b\", \"'ve\", text)\n",
    "        text = re.sub(r\"'\\s+d\\b\", \"'d\", text)\n",
    "        text = re.sub(r\"'\\s+ll\\b\", \"'ll\", text)\n",
    "        text = re.sub(r\"'\\s+m\\b\", \"'m\", text)\n",
    "\n",
    "        # Add space after ?\" or ,\" etc. if followed by a word (any letter)\n",
    "        text = re.sub(r'([,?.!])(\")([A-Za-z])', r'\\1\\2 \\3', text)\n",
    "\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "836c3386",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, do you like tea? <|endoftext|> She raised her eyebrows with a hint of good-humoured surprise.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = SimpleTokenizerV2(vocab)\n",
    "\n",
    "text1 = \"Hello, do you like tea?\"\n",
    "text2 = \"She raised her eyebrows with a hint of good-humoured surprise.\"\n",
    "\n",
    "text = \" <|endoftext|> \".join((text1,text2))\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a7dfe9e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1131,\n",
       " 5,\n",
       " 355,\n",
       " 1126,\n",
       " 628,\n",
       " 975,\n",
       " 10,\n",
       " 1130,\n",
       " 88,\n",
       " 816,\n",
       " 539,\n",
       " 416,\n",
       " 1108,\n",
       " 115,\n",
       " 548,\n",
       " 722,\n",
       " 502,\n",
       " 961,\n",
       " 7]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d422caa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|unk|>, do you like tea? <|endoftext|> She raised her eyebrows with a hint of good-humoured surprise.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokenizer.encode(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5fab1e",
   "metadata": {},
   "source": [
    "\"Hello\" was not vocab but SimpleTokenizerV2 handles it now"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f34cbf",
   "metadata": {},
   "source": [
    "# Byte pair Encoding \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb2f49c",
   "metadata": {},
   "source": [
    "With chatgpt tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9bfa48af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tiktoken in /Users/junaeidshoaib/anaconda3/lib/python3.11/site-packages (0.9.0)\r\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Users/junaeidshoaib/anaconda3/lib/python3.11/site-packages (from tiktoken) (2022.7.9)\r\n",
      "Requirement already satisfied: requests>=2.26.0 in /Users/junaeidshoaib/anaconda3/lib/python3.11/site-packages (from tiktoken) (2.32.4)\r\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/junaeidshoaib/anaconda3/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken) (2.0.4)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/junaeidshoaib/anaconda3/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken) (3.4)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/junaeidshoaib/anaconda3/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken) (1.26.16)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/junaeidshoaib/anaconda3/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken) (2024.7.4)\r\n"
     ]
    }
   ],
   "source": [
    "! pip3 install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b9c97466",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tiktoken version: 0.9.0\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import tiktoken\n",
    "\n",
    "print(\"tiktoken version:\", importlib.metadata.version(\"tiktoken\"))\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "472e7799",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15496, 11, 466, 345, 588, 8887, 30, 220, 50256, 554, 262, 4252, 18250, 8812, 2114, 1659, 617, 34680, 27271, 13]\n"
     ]
    }
   ],
   "source": [
    "text = (\"Hello, do you like tea? <|endoftext|> In the sunlit terraces\"\n",
    "     \"of someunknownPlace.\")\n",
    "\n",
    "integers = tokenizer.encode(text, allowed_special={\"<|endoftext|>\"})\n",
    "\n",
    "print(integers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b06d53ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, do you like tea? <|endoftext|> In the sunlit terracesof someunknownPlace.\n"
     ]
    }
   ],
   "source": [
    "text = tokenizer.decode(integers)\n",
    "\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52346a30",
   "metadata": {},
   "source": [
    "# input-target pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "414ac347",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5145\n"
     ]
    }
   ],
   "source": [
    "encoded_text = tokenizer.encode(raw_text) #byte pair encoding\n",
    "print(len(encoded_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "50a7f103",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5095\n"
     ]
    }
   ],
   "source": [
    "encoded_sample = encoded_text[50:]\n",
    "print(len(encoded_sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bd61e52c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: [290, 4920, 2241, 287]\n",
      "y:      [4920, 2241, 287, 257]\n"
     ]
    }
   ],
   "source": [
    "context_size = 4\n",
    "\n",
    "x = encoded_sample[:context_size]\n",
    "y = encoded_sample[1:context_size+1]\n",
    "print(f'x:',x)\n",
    "print(f'y:     ',y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d602b0d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " and -->  established\n",
      " and established -->  himself\n",
      " and established himself -->  in\n",
      " and established himself in -->  a\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, context_size+1):\n",
    "    context = encoded_sample[:i]\n",
    "    desired = encoded_sample[i]\n",
    "    print(tokenizer.decode(context), \"-->\",tokenizer.decode([desired]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81615e7b",
   "metadata": {},
   "source": [
    "# Data loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6fb053be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "class GPTDatasetV1(Dataset):\n",
    "    def __init__(self, txt, tokenizer, max_length, stride):\n",
    "        self.input_ids = []\n",
    "        self.target_ids = []\n",
    "\n",
    "        # Tokenize the entire text\n",
    "        token_ids = tokenizer.encode(txt, allowed_special={\"<|endoftext|>\"})\n",
    "\n",
    "        # Use a sliding window to chunk the book into overlapping sequences of max_length\n",
    "        for i in range(0, len(token_ids) - max_length, stride):\n",
    "            input_chunk = token_ids[i:i + max_length]\n",
    "            target_chunk = token_ids[i + 1: i + max_length + 1]\n",
    "            self.input_ids.append(torch.tensor(input_chunk))\n",
    "            self.target_ids.append(torch.tensor(target_chunk))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_ids[idx], self.target_ids[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b9f0a030",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloader_v1(txt, batch_size=4, max_length=256, \n",
    "                         stride=128, shuffle=True, drop_last=True,\n",
    "                         num_workers=0):\n",
    "\n",
    "    # Initialize the tokenizer\n",
    "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "    # Create dataset\n",
    "    dataset = GPTDatasetV1(txt, tokenizer, max_length, stride)\n",
    "\n",
    "    # Create dataloader\n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        drop_last=drop_last,\n",
    "        num_workers=num_workers\n",
    "    )\n",
    "\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1dfe2b83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.6.0\n",
      "[tensor([[  40,  367, 2885, 1464]]), tensor([[ 367, 2885, 1464, 1807]])]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"PyTorch version:\", torch.__version__)\n",
    "dataloader = create_dataloader_v1(raw_text, batch_size=1, max_length=4, stride=1, shuffle=False)\n",
    "\n",
    "data_iter = iter(dataloader)\n",
    "first_batch = next(data_iter)\n",
    "print(first_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "12c3c2e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[ 367, 2885, 1464, 1807]]), tensor([[2885, 1464, 1807, 3619]])]\n"
     ]
    }
   ],
   "source": [
    "second_batch = next(data_iter)\n",
    "print(second_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "236b72a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs:\n",
      " tensor([[   40,   367,  2885,  1464],\n",
      "        [ 1807,  3619,   402,   271],\n",
      "        [10899,  2138,   257,  7026],\n",
      "        [15632,   438,  2016,   257],\n",
      "        [  922,  5891,  1576,   438],\n",
      "        [  568,   340,   373,   645],\n",
      "        [ 1049,  5975,   284,   502],\n",
      "        [  284,  3285,   326,    11]])\n",
      "\n",
      "Targets:\n",
      " tensor([[  367,  2885,  1464,  1807],\n",
      "        [ 3619,   402,   271, 10899],\n",
      "        [ 2138,   257,  7026, 15632],\n",
      "        [  438,  2016,   257,   922],\n",
      "        [ 5891,  1576,   438,   568],\n",
      "        [  340,   373,   645,  1049],\n",
      "        [ 5975,   284,   502,   284],\n",
      "        [ 3285,   326,    11,   287]])\n"
     ]
    }
   ],
   "source": [
    "dataloader = create_dataloader_v1(raw_text, batch_size=8, max_length=4, stride=4, shuffle=False)\n",
    "\n",
    "data_iter = iter(dataloader)\n",
    "inputs, targets = next(data_iter)\n",
    "print(\"Inputs:\\n\", inputs)\n",
    "print(\"\\nTargets:\\n\", targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b298f6da",
   "metadata": {},
   "source": [
    "# Create token embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9275b1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = torch.tensor([2, 3, 5, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ee847ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 6\n",
    "output_dim = 3\n",
    "\n",
    "torch.manual_seed(123)\n",
    "embedding_layer = torch.nn.Embedding(vocab_size, output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f8aff211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.3374, -0.1778, -0.1690],\n",
      "        [ 0.9178,  1.5810,  1.3010],\n",
      "        [ 1.2753, -0.2010, -0.1606],\n",
      "        [-0.4015,  0.9666, -1.1481],\n",
      "        [-1.1589,  0.3255, -0.6315],\n",
      "        [-2.8400, -0.7849, -1.4096]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(embedding_layer.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "aac71204",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.4015,  0.9666, -1.1481]], grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(embedding_layer(torch.tensor([3])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "88289600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.2753, -0.2010, -0.1606],\n",
      "        [-0.4015,  0.9666, -1.1481],\n",
      "        [-2.8400, -0.7849, -1.4096],\n",
      "        [ 0.9178,  1.5810,  1.3010]], grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(embedding_layer(input_ids))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58deba9",
   "metadata": {},
   "source": [
    "# Positional embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4b733bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 50257\n",
    "output_dim = 256\n",
    "\n",
    "token_embedding_layer = torch.nn.Embedding(vocab_size, output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3093b53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 4\n",
    "dataloader = create_dataloader_v1(\n",
    "    raw_text, batch_size=8, max_length=max_length,\n",
    "    stride=max_length, shuffle=False\n",
    ")\n",
    "data_iter = iter(dataloader)\n",
    "inputs, targets = next(data_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "452dbf50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token IDs:\n",
      " tensor([[   40,   367,  2885,  1464],\n",
      "        [ 1807,  3619,   402,   271],\n",
      "        [10899,  2138,   257,  7026],\n",
      "        [15632,   438,  2016,   257],\n",
      "        [  922,  5891,  1576,   438],\n",
      "        [  568,   340,   373,   645],\n",
      "        [ 1049,  5975,   284,   502],\n",
      "        [  284,  3285,   326,    11]])\n",
      "\n",
      "Inputs shape:\n",
      " torch.Size([8, 4])\n"
     ]
    }
   ],
   "source": [
    "print(\"Token IDs:\\n\", inputs)\n",
    "print(\"\\nInputs shape:\\n\", inputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e02e5685",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 4, 256])\n"
     ]
    }
   ],
   "source": [
    "token_embeddings = token_embedding_layer(inputs)\n",
    "print(token_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "508d1017",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_length = max_length\n",
    "pos_embedding_layer = torch.nn.Embedding(context_length, output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9a03776e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 256])\n"
     ]
    }
   ],
   "source": [
    "pos_embeddings = pos_embedding_layer(torch.arange(max_length))\n",
    "print(pos_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f2d9701b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 4, 256])\n"
     ]
    }
   ],
   "source": [
    "input_embeddings = token_embeddings + pos_embeddings\n",
    "print(input_embeddings.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3266684",
   "metadata": {},
   "source": [
    "# Implementing Simplified Attention Mechanism"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6c4c57",
   "metadata": {},
   "source": [
    "For the sake of simplicity: we are considering 3-D vector so that it fits on the page without linr breaking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3e74f080",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "inputs = torch.tensor(\n",
    "  [[0.43, 0.15, 0.89], # Your     (x^1)\n",
    "   [0.55, 0.87, 0.66], # journey  (x^2)\n",
    "   [0.57, 0.85, 0.64], # starts   (x^3)\n",
    "   [0.22, 0.58, 0.33], # with     (x^4)\n",
    "   [0.77, 0.25, 0.10], # one      (x^5)\n",
    "   [0.05, 0.80, 0.55]] # step     (x^6)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2ab8c5c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# Corresponding words\n",
    "words = ['Your', 'journey', 'starts', 'with', 'one', 'step']\n",
    "\n",
    "# Extract x, y, z coordinates\n",
    "x_coords = inputs[:, 0].numpy()\n",
    "y_coords = inputs[:, 1].numpy()\n",
    "z_coords = inputs[:, 2].numpy()\n",
    "\n",
    "# Create 3D plot\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Plot each point and annotate with corresponding word\n",
    "for x, y, z, word in zip(x_coords, y_coords, z_coords, words):\n",
    "    ax.scatter(x, y, z)\n",
    "    ax.text(x, y, z, word, fontsize=10)\n",
    "\n",
    "# Set labels for axes\n",
    "ax.set_xlabel('X')\n",
    "ax.set_ylabel('Y')\n",
    "ax.set_zlabel('Z')\n",
    "\n",
    "\n",
    "plt.title('3D Plot of Word Embeddings')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f3abbf2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.9544, 1.4950, 1.4754, 0.8434, 0.7070, 1.0865])\n"
     ]
    }
   ],
   "source": [
    "query = inputs[1]  # 2nd input token is the query \"journey\"\n",
    "\n",
    "attn_scores_2 = torch.empty(inputs.shape[0])\n",
    "for i, x_i in enumerate(inputs):\n",
    "    attn_scores_2[i] = torch.dot(x_i, query) # dot product (transpose not necessary here since they are 1-dim vectors)\n",
    "\n",
    "print(attn_scores_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "917c43d2",
   "metadata": {},
   "source": [
    "In the next step, we normalize each of the attention scores that we computed previously.\n",
    "\n",
    "The main goal behind the normalization is to obtain attention weights that sum up to 1.\n",
    "\n",
    "This normalization is a convention that is useful for interpretation and for maintaining training stability in an LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "efb6ebb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention weights: tensor([0.1455, 0.2278, 0.2249, 0.1285, 0.1077, 0.1656])\n",
      "Sum: tensor(1.0000)\n"
     ]
    }
   ],
   "source": [
    "attn_weights_2_tmp = attn_scores_2 / attn_scores_2.sum()\n",
    "\n",
    "print(\"Attention weights:\", attn_weights_2_tmp)\n",
    "print(\"Sum:\", attn_weights_2_tmp.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "71382151",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention weights: tensor([0.1385, 0.2379, 0.2333, 0.1240, 0.1082, 0.1581])\n",
      "Sum: tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "#normal softmax\n",
    "def softmax_naive(x):\n",
    "    return torch.exp(x) / torch.exp(x).sum(dim=0)\n",
    "\n",
    "attn_weights_2_naive = softmax_naive(attn_scores_2)\n",
    "\n",
    "print(\"Attention weights:\", attn_weights_2_naive)\n",
    "print(\"Sum:\", attn_weights_2_naive.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8b4400d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention weights: tensor([0.1385, 0.2379, 0.2333, 0.1240, 0.1082, 0.1581])\n",
      "Sum: tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "#py torch soft max (better and usual practice because of enormous values)\n",
    "attn_weights_2 = torch.softmax(attn_scores_2, dim=0)\n",
    "print(\"Attention weights:\", attn_weights_2)\n",
    "print(\"Sum:\", attn_weights_2.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "afb3a784",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.4419, 0.6515, 0.5683])\n"
     ]
    }
   ],
   "source": [
    "context_vec_2 = torch.zeros(query.shape)\n",
    "for i,x_i in enumerate(inputs):\n",
    "    context_vec_2 += attn_weights_2[i]*x_i\n",
    "\n",
    "print(context_vec_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f0b0f94",
   "metadata": {},
   "source": [
    "Now, we can extend this computation to calculate attention weights and context vectors for all inputs.\n",
    "\n",
    "First, we add an additional for-loop to compute the dot products for all pairs of inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f15fcaa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9995, 0.9544, 0.9422, 0.4753, 0.4576, 0.6310],\n",
      "        [0.9544, 1.4950, 1.4754, 0.8434, 0.7070, 1.0865],\n",
      "        [0.9422, 1.4754, 1.4570, 0.8296, 0.7154, 1.0605],\n",
      "        [0.4753, 0.8434, 0.8296, 0.4937, 0.3474, 0.6565],\n",
      "        [0.4576, 0.7070, 0.7154, 0.3474, 0.6654, 0.2935],\n",
      "        [0.6310, 1.0865, 1.0605, 0.6565, 0.2935, 0.9450]])\n"
     ]
    }
   ],
   "source": [
    "attn_scores = torch.empty(6, 6)\n",
    "\n",
    "for i, x_i in enumerate(inputs):\n",
    "    for j, x_j in enumerate(inputs):\n",
    "        attn_scores[i, j] = torch.dot(x_i, x_j)\n",
    "\n",
    "print(attn_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7782f22b",
   "metadata": {},
   "source": [
    "this will take ages to compute\n",
    "so what will do is a shortcut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ecd4d90d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9995, 0.9544, 0.9422, 0.4753, 0.4576, 0.6310],\n",
      "        [0.9544, 1.4950, 1.4754, 0.8434, 0.7070, 1.0865],\n",
      "        [0.9422, 1.4754, 1.4570, 0.8296, 0.7154, 1.0605],\n",
      "        [0.4753, 0.8434, 0.8296, 0.4937, 0.3474, 0.6565],\n",
      "        [0.4576, 0.7070, 0.7154, 0.3474, 0.6654, 0.2935],\n",
      "        [0.6310, 1.0865, 1.0605, 0.6565, 0.2935, 0.9450]])\n"
     ]
    }
   ],
   "source": [
    "attn_scores = inputs @ inputs.T\n",
    "print(attn_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "15eb0c19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2098, 0.2006, 0.1981, 0.1242, 0.1220, 0.1452],\n",
      "        [0.1385, 0.2379, 0.2333, 0.1240, 0.1082, 0.1581],\n",
      "        [0.1390, 0.2369, 0.2326, 0.1242, 0.1108, 0.1565],\n",
      "        [0.1435, 0.2074, 0.2046, 0.1462, 0.1263, 0.1720],\n",
      "        [0.1526, 0.1958, 0.1975, 0.1367, 0.1879, 0.1295],\n",
      "        [0.1385, 0.2184, 0.2128, 0.1420, 0.0988, 0.1896]])\n"
     ]
    }
   ],
   "source": [
    "attn_weights = torch.softmax(attn_scores, dim=-1)\n",
    "print(attn_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec1138af",
   "metadata": {},
   "source": [
    "we now use these attention weights to compute all context vectors via matrix multiplication:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "07959dd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4421, 0.5931, 0.5790],\n",
      "        [0.4419, 0.6515, 0.5683],\n",
      "        [0.4431, 0.6496, 0.5671],\n",
      "        [0.4304, 0.6298, 0.5510],\n",
      "        [0.4671, 0.5910, 0.5266],\n",
      "        [0.4177, 0.6503, 0.5645]])\n"
     ]
    }
   ],
   "source": [
    "all_context_vecs = attn_weights @ inputs\n",
    "print(all_context_vecs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "334549e0",
   "metadata": {},
   "source": [
    "# IMPLEMENTING SELF ATTENTION WITH TRAINABLE WEIGHTS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f42c5081",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_2 = inputs[1] #A\n",
    "d_in = inputs.shape[1] #B\n",
    "d_out = 2 #C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d4f4b7aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W_query:\n",
      " Parameter containing:\n",
      "tensor([[0.2961, 0.5166],\n",
      "        [0.2517, 0.6886],\n",
      "        [0.0740, 0.8665]])\n",
      "W_key :\n",
      " Parameter containing:\n",
      "tensor([[0.1366, 0.1025],\n",
      "        [0.1841, 0.7264],\n",
      "        [0.3153, 0.6871]])\n",
      "W_value:\n",
      " Parameter containing:\n",
      "tensor([[0.0756, 0.1966],\n",
      "        [0.3164, 0.4017],\n",
      "        [0.1186, 0.8274]])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "W_query = torch.nn.Parameter(torch.rand(d_in, d_out), requires_grad=False)\n",
    "W_key = torch.nn.Parameter(torch.rand(d_in, d_out), requires_grad=False)\n",
    "W_value = torch.nn.Parameter(torch.rand(d_in, d_out), requires_grad=False)\n",
    "print(f'W_query:\\n',W_query)\n",
    "print(f'W_key :\\n',W_key )\n",
    "print(f'W_value:\\n',W_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a693020b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.4306, 1.4551])\n"
     ]
    }
   ],
   "source": [
    "query_2 = x_2 @ W_query\n",
    "key_2 = x_2 @ W_key\n",
    "value_2 = x_2 @ W_value\n",
    "print(query_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "50244cfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "queries.shape: torch.Size([6, 2])\n",
      "queries:\n",
      " tensor([[0.2309, 1.0966],\n",
      "        [0.4306, 1.4551],\n",
      "        [0.4300, 1.4343],\n",
      "        [0.2355, 0.7990],\n",
      "        [0.2983, 0.6565],\n",
      "        [0.2568, 1.0533]])\n",
      "keys.shape: torch.Size([6, 2])\n",
      "keys:\n",
      " tensor([[0.3669, 0.7646],\n",
      "        [0.4433, 1.1419],\n",
      "        [0.4361, 1.1156],\n",
      "        [0.2408, 0.6706],\n",
      "        [0.1827, 0.3292],\n",
      "        [0.3275, 0.9642]])\n",
      "values.shape: torch.Size([6, 2])\n",
      "values:\n",
      " tensor([[0.1855, 0.8812],\n",
      "        [0.3951, 1.0037],\n",
      "        [0.3879, 0.9831],\n",
      "        [0.2393, 0.5493],\n",
      "        [0.1492, 0.3346],\n",
      "        [0.3221, 0.7863]])\n"
     ]
    }
   ],
   "source": [
    "keys = inputs @ W_key\n",
    "values = inputs @ W_value\n",
    "queries = inputs @ W_query\n",
    "print(\"queries.shape:\", queries.shape)\n",
    "print(\"queries:\\n\", queries)\n",
    "\n",
    "print(\"keys.shape:\", keys.shape)\n",
    "print(\"keys:\\n\", keys)\n",
    "\n",
    "print(\"values.shape:\", values.shape)\n",
    "print(\"values:\\n\", values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "733839ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.8524)\n"
     ]
    }
   ],
   "source": [
    "keys_2 = keys[1] #A\n",
    "attn_score_22 = query_2.dot(keys_2)\n",
    "print(attn_score_22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ca2c8fe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.2705, 1.8524, 1.8111, 1.0795, 0.5577, 1.5440])\n"
     ]
    }
   ],
   "source": [
    "attn_scores_2 = query_2 @ keys.T # All attention scores for given query (T because 1x2 dot 6,2 with T = 2,6)\n",
    "print(attn_scores_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a86a11fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9231, 1.3545, 1.3241, 0.7910, 0.4032, 1.1330],\n",
      "        [1.2705, 1.8524, 1.8111, 1.0795, 0.5577, 1.5440],\n",
      "        [1.2544, 1.8284, 1.7877, 1.0654, 0.5508, 1.5238],\n",
      "        [0.6973, 1.0167, 0.9941, 0.5925, 0.3061, 0.8475],\n",
      "        [0.6114, 0.8819, 0.8626, 0.5121, 0.2707, 0.7307],\n",
      "        [0.8995, 1.3165, 1.2871, 0.7682, 0.3937, 1.0996]])\n"
     ]
    }
   ],
   "source": [
    "attn_scores = queries @ keys.T\n",
    "print(attn_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2fe7107e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1500, 0.2264, 0.2199, 0.1311, 0.0906, 0.1820])\n"
     ]
    }
   ],
   "source": [
    "d_k = keys.shape[-1]\n",
    "attn_weights_2 = torch.softmax(attn_scores_2 / d_k**0.5, dim=-1)\n",
    "print(attn_weights_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f49da181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1551, 0.2104, 0.2059, 0.1413, 0.1074, 0.1799],\n",
      "        [0.1500, 0.2264, 0.2199, 0.1311, 0.0906, 0.1820],\n",
      "        [0.1503, 0.2256, 0.2192, 0.1315, 0.0914, 0.1819],\n",
      "        [0.1591, 0.1994, 0.1962, 0.1477, 0.1206, 0.1769],\n",
      "        [0.1610, 0.1949, 0.1923, 0.1501, 0.1265, 0.1752],\n",
      "        [0.1557, 0.2092, 0.2048, 0.1419, 0.1089, 0.1794]])\n"
     ]
    }
   ],
   "source": [
    "attn_weights = torch.softmax(attn_scores/d_k**0.5, dim=-1)\n",
    "print(attn_weights) # we got our attention matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "36e0c852",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2996, 0.8053],\n",
      "        [0.3061, 0.8210],\n",
      "        [0.3058, 0.8203],\n",
      "        [0.2948, 0.7939],\n",
      "        [0.2927, 0.7891],\n",
      "        [0.2990, 0.8040]])\n"
     ]
    }
   ],
   "source": [
    "context_vec = attn_weights @ values\n",
    "print(context_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70986b0e",
   "metadata": {},
   "source": [
    "# lets make python class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ed2b01dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class SelfAttention_v2(nn.Module):\n",
    "\n",
    "    def __init__(self, d_in, d_out, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_key   = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        keys = self.W_key(x)\n",
    "        queries = self.W_query(x)\n",
    "        values = self.W_value(x)\n",
    "        \n",
    "        attn_scores = queries @ keys.T\n",
    "        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
    "\n",
    "        context_vec = attn_weights @ values\n",
    "        return context_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f8c709e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.5337, -0.1051],\n",
      "        [-0.5323, -0.1080],\n",
      "        [-0.5323, -0.1079],\n",
      "        [-0.5297, -0.1076],\n",
      "        [-0.5311, -0.1066],\n",
      "        [-0.5299, -0.1081]], grad_fn=<MmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "sa_v2 = SelfAttention_v2(d_in, d_out)\n",
    "print(sa_v2(inputs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a8a66e8",
   "metadata": {},
   "source": [
    "# Causal Attention/Masked Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a1820fca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1717, 0.1762, 0.1761, 0.1555, 0.1627, 0.1579],\n",
      "        [0.1636, 0.1749, 0.1746, 0.1612, 0.1605, 0.1652],\n",
      "        [0.1637, 0.1749, 0.1746, 0.1611, 0.1606, 0.1651],\n",
      "        [0.1636, 0.1704, 0.1702, 0.1652, 0.1632, 0.1674],\n",
      "        [0.1667, 0.1722, 0.1721, 0.1618, 0.1633, 0.1639],\n",
      "        [0.1624, 0.1709, 0.1706, 0.1654, 0.1625, 0.1682]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "queries = sa_v2.W_query(inputs) #A\n",
    "keys = sa_v2.W_key(inputs)\n",
    "attn_scores = queries @ keys.T\n",
    "attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=1)\n",
    "print(attn_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "cb7f1def",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1717, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1636, 0.1749, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1637, 0.1749, 0.1746, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1636, 0.1704, 0.1702, 0.1652, 0.0000, 0.0000],\n",
      "        [0.1667, 0.1722, 0.1721, 0.1618, 0.1633, 0.0000],\n",
      "        [0.1624, 0.1709, 0.1706, 0.1654, 0.1625, 0.1682]],\n",
      "       grad_fn=<TrilBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# context_length = attn_scores.shape[0]\n",
    "# mask_simple = torch.tril(torch.ones(context_length, context_length))\n",
    "# print(mask_simple)\n",
    "# masked_simple = attn_weights*mask_simple\n",
    "# print(masked_simple)\n",
    "context_length = attn_scores.shape[0]\n",
    "mask_simple = torch.tril(attn_weights)\n",
    "print(mask_simple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "328820dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.4833, 0.5167, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.3190, 0.3408, 0.3402, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2445, 0.2545, 0.2542, 0.2468, 0.0000, 0.0000],\n",
      "        [0.1994, 0.2060, 0.2058, 0.1935, 0.1953, 0.0000],\n",
      "        [0.1624, 0.1709, 0.1706, 0.1654, 0.1625, 0.1682]],\n",
      "       grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "row_sums = mask_simple.sum(dim=1, keepdim=True)\n",
    "mask_simple_norm = mask_simple / row_sums\n",
    "print(mask_simple_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ad0efa",
   "metadata": {},
   "source": [
    "But this leads to data leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "da07a70f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3111,   -inf,   -inf,   -inf,   -inf,   -inf],\n",
      "        [0.1655, 0.2602,   -inf,   -inf,   -inf,   -inf],\n",
      "        [0.1667, 0.2602, 0.2577,   -inf,   -inf,   -inf],\n",
      "        [0.0510, 0.1080, 0.1064, 0.0643,   -inf,   -inf],\n",
      "        [0.1415, 0.1875, 0.1863, 0.0987, 0.1121,   -inf],\n",
      "        [0.0476, 0.1192, 0.1171, 0.0731, 0.0477, 0.0966]],\n",
      "       grad_fn=<MaskedFillBackward0>)\n"
     ]
    }
   ],
   "source": [
    "mask = torch.triu(torch.ones(context_length, context_length), diagonal=1)\n",
    "masked = attn_scores.masked_fill(mask.bool(), -torch.inf)\n",
    "print(masked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ab5f2f23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.4833, 0.5167, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.3190, 0.3408, 0.3402, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2445, 0.2545, 0.2542, 0.2468, 0.0000, 0.0000],\n",
      "        [0.1994, 0.2060, 0.2058, 0.1935, 0.1953, 0.0000],\n",
      "        [0.1624, 0.1709, 0.1706, 0.1654, 0.1625, 0.1682]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "attn_weights = torch.softmax(masked / keys.shape[-1]**0.5, dim=1)\n",
    "print(attn_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd366ac",
   "metadata": {},
   "source": [
    "# Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea45e615",
   "metadata": {},
   "source": [
    "In the following code example, we use a dropout rate of 50%, which means masking out half of the attention weights.\n",
    "\n",
    "When we train the GPT model in later chapters, we will use a lower dropout rate, such as 0.1 or 0.2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "4acfc5c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2., 2., 0., 2., 2., 0.],\n",
      "        [0., 0., 0., 2., 0., 2.],\n",
      "        [2., 2., 2., 2., 0., 2.],\n",
      "        [0., 2., 2., 0., 0., 2.],\n",
      "        [0., 2., 0., 2., 0., 2.],\n",
      "        [0., 2., 2., 2., 2., 0.]])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "dropout = torch.nn.Dropout(0.5) #A\n",
    "example = torch.ones(6, 6) #B\n",
    "print(dropout(example))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e09bc09e",
   "metadata": {},
   "source": [
    "When applying dropout to an attention weight matrix with a rate of 50%, half of the elements in the matrix are randomly set to zero.\n",
    "\n",
    "To compensate for the reduction in active elements, the values of the remaining elements in the matrix are scaled up by a factor of 1/0.5 =2.\n",
    "\n",
    "This scaling is crucial to maintain the overall balance of the attention weights, ensuring that the average influence of the attention mechanism remains consistent during both the training and inference phases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "147474f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.6380, 0.6816, 0.6804, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.5090, 0.5085, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.4120, 0.0000, 0.3869, 0.0000, 0.0000],\n",
      "        [0.0000, 0.3418, 0.3413, 0.3308, 0.3249, 0.0000]],\n",
      "       grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "print(dropout(attn_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "98333334",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 6, 3])\n"
     ]
    }
   ],
   "source": [
    "batch = torch.stack((inputs, inputs,inputs), dim=0) # To compute multiple lines at a time\n",
    "print(batch.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "301ea695",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CausalAttention(nn.Module):\n",
    "\n",
    "    def __init__(self, d_in, d_out, context_length,\n",
    "                 dropout, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        self.d_out = d_out\n",
    "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_key   = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.dropout = nn.Dropout(dropout) # New\n",
    "        self.register_buffer('mask', torch.triu(torch.ones(context_length, context_length), diagonal=1)) # New\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, num_tokens, d_in = x.shape # New batch dimension b\n",
    "        keys = self.W_key(x)\n",
    "        queries = self.W_query(x)\n",
    "        values = self.W_value(x)\n",
    "\n",
    "        attn_scores = queries @ keys.transpose(1, 2) # Changed transpose\n",
    "        attn_scores.masked_fill_(  # New, _ ops are in-place\n",
    "            self.mask.bool()[:num_tokens, :num_tokens], -torch.inf)  # `:num_tokens` to account for cases where the number of tokens in the batch is smaller than the supported context_size\n",
    "        attn_weights = torch.softmax(\n",
    "            attn_scores / keys.shape[-1]**0.5, dim=-1\n",
    "        )\n",
    "        attn_weights = self.dropout(attn_weights) # New\n",
    "\n",
    "        context_vec = attn_weights @ values\n",
    "        return context_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e7a3b15b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_vecs.shape: torch.Size([3, 6, 2])\n",
      "tensor([[[-0.4519,  0.2216],\n",
      "         [-0.5874,  0.0058],\n",
      "         [-0.6300, -0.0632],\n",
      "         [-0.5675, -0.0843],\n",
      "         [-0.5526, -0.0981],\n",
      "         [-0.5299, -0.1081]],\n",
      "\n",
      "        [[-0.4519,  0.2216],\n",
      "         [-0.5874,  0.0058],\n",
      "         [-0.6300, -0.0632],\n",
      "         [-0.5675, -0.0843],\n",
      "         [-0.5526, -0.0981],\n",
      "         [-0.5299, -0.1081]],\n",
      "\n",
      "        [[-0.4519,  0.2216],\n",
      "         [-0.5874,  0.0058],\n",
      "         [-0.6300, -0.0632],\n",
      "         [-0.5675, -0.0843],\n",
      "         [-0.5526, -0.0981],\n",
      "         [-0.5299, -0.1081]]], grad_fn=<UnsafeViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "context_length = batch.shape[1]\n",
    "ca = CausalAttention(d_in, d_out, context_length, 0.0)\n",
    "context_vecs = ca(batch)\n",
    "print(\"context_vecs.shape:\", context_vecs.shape)\n",
    "print(context_vecs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea02af5",
   "metadata": {},
   "source": [
    "# Multihead ATTENTION LAYER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "5fdd91ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttentionWrapper(nn.Module):\n",
    "\n",
    "    def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList(\n",
    "            [CausalAttention(d_in, d_out, context_length, dropout, qkv_bias) \n",
    "             for _ in range(num_heads)]\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.cat([head(x) for head in self.heads], dim=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "17d4b620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.4519,  0.2216,  0.4772,  0.1063],\n",
      "         [-0.5874,  0.0058,  0.5891,  0.3257],\n",
      "         [-0.6300, -0.0632,  0.6202,  0.3860],\n",
      "         [-0.5675, -0.0843,  0.5478,  0.3589],\n",
      "         [-0.5526, -0.0981,  0.5321,  0.3428],\n",
      "         [-0.5299, -0.1081,  0.5077,  0.3493]],\n",
      "\n",
      "        [[-0.4519,  0.2216,  0.4772,  0.1063],\n",
      "         [-0.5874,  0.0058,  0.5891,  0.3257],\n",
      "         [-0.6300, -0.0632,  0.6202,  0.3860],\n",
      "         [-0.5675, -0.0843,  0.5478,  0.3589],\n",
      "         [-0.5526, -0.0981,  0.5321,  0.3428],\n",
      "         [-0.5299, -0.1081,  0.5077,  0.3493]],\n",
      "\n",
      "        [[-0.4519,  0.2216,  0.4772,  0.1063],\n",
      "         [-0.5874,  0.0058,  0.5891,  0.3257],\n",
      "         [-0.6300, -0.0632,  0.6202,  0.3860],\n",
      "         [-0.5675, -0.0843,  0.5478,  0.3589],\n",
      "         [-0.5526, -0.0981,  0.5321,  0.3428],\n",
      "         [-0.5299, -0.1081,  0.5077,  0.3493]]], grad_fn=<CatBackward0>)\n",
      "context_vecs.shape: torch.Size([3, 6, 4])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "context_length = batch.shape[1] # This is the number of tokens\n",
    "d_in, d_out = 3, 2\n",
    "mha = MultiHeadAttentionWrapper(d_in, d_out, context_length, 0.0, num_heads=2)\n",
    "context_vecs = mha(batch)\n",
    "print(context_vecs)\n",
    "print(\"context_vecs.shape:\", context_vecs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c54ffe",
   "metadata": {},
   "source": [
    "# Multihead with splits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "220c705a",
   "metadata": {},
   "source": [
    "Step 1: Reduce the projection dim to match desired output dim\n",
    "\n",
    "Step 2: Use a Linear layer to combine head outputs\n",
    "\n",
    "Step 3: Tensor shape: (b, num_tokens, d_out)\n",
    "\n",
    "Step 4: We implicitly split the matrix by adding a num_heads dimension. Then we unroll last dim: (b, num_tokens, d_out) -> (b, num_tokens, num_heads, head_dim)\n",
    "\n",
    "Step 5: Transpose from shape (b, num_tokens, num_heads, head_dim) to (b, num_heads, num_tokens, head_dim)\n",
    "\n",
    "Step 6: Compute dot product for each head\n",
    "\n",
    "Step 7: Mask truncated to the number of tokens\n",
    "\n",
    "Step 8: Use the mask to fill attention scores\n",
    "\n",
    "Step 9: Tensor shape: (b, num_tokens, n_heads, head_dim)\n",
    "\n",
    "Step 10: Combine heads, where self.d_out = self.num_heads * self.head_dim\n",
    "\n",
    "Step 11: Add an optional linear projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "8a4487b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        assert (d_out % num_heads == 0), \\\n",
    "            \"d_out must be divisible by num_heads\"\n",
    "\n",
    "        self.d_out = d_out\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = d_out // num_heads # Reduce the projection dim to match desired output dim\n",
    "\n",
    "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.out_proj = nn.Linear(d_out, d_out)  # Linear layer to combine head outputs\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.register_buffer(\n",
    "            \"mask\",\n",
    "            torch.triu(torch.ones(context_length, context_length),\n",
    "                       diagonal=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, num_tokens, d_in = x.shape\n",
    "\n",
    "        keys = self.W_key(x) # Shape: (b, num_tokens, d_out)\n",
    "        queries = self.W_query(x)\n",
    "        values = self.W_value(x)\n",
    "\n",
    "        # We implicitly split the matrix by adding a `num_heads` dimension\n",
    "        # Unroll last dim: (b, num_tokens, d_out) -> (b, num_tokens, num_heads, head_dim)\n",
    "        keys = keys.view(b, num_tokens, self.num_heads, self.head_dim) \n",
    "        values = values.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "        queries = queries.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "\n",
    "        # Transpose: (b, num_tokens, num_heads, head_dim) -> (b, num_heads, num_tokens, head_dim)\n",
    "        keys = keys.transpose(1, 2)\n",
    "        queries = queries.transpose(1, 2)\n",
    "        values = values.transpose(1, 2)\n",
    "\n",
    "        # Compute scaled dot-product attention (aka self-attention) with a causal mask\n",
    "        attn_scores = queries @ keys.transpose(2, 3)  # Dot product for each head\n",
    "\n",
    "        # Original mask truncated to the number of tokens and converted to boolean\n",
    "        mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n",
    "\n",
    "        # Use the mask to fill attention scores\n",
    "        attn_scores.masked_fill_(mask_bool, -torch.inf)\n",
    "        \n",
    "        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
    "        attn_weights = self.dropout(attn_weights)\n",
    "\n",
    "        # Shape: (b, num_tokens, num_heads, head_dim)\n",
    "        context_vec = (attn_weights @ values).transpose(1, 2) \n",
    "        \n",
    "        # Combine heads, where self.d_out = self.num_heads * self.head_dim\n",
    "        context_vec = context_vec.contiguous().view(b, num_tokens, self.d_out)\n",
    "        context_vec = self.out_proj(context_vec) # optional projection\n",
    "\n",
    "        return context_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "b69212a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 3, 6])\n",
      "tensor([[[ 0.1569, -0.0873,  0.0210,  0.0215, -0.3243, -0.2518],\n",
      "         [ 0.1117, -0.0547,  0.0406, -0.0213, -0.3251, -0.2993],\n",
      "         [ 0.1196, -0.0491,  0.0318, -0.0635, -0.2788, -0.2578]],\n",
      "\n",
      "        [[ 0.1569, -0.0873,  0.0210,  0.0215, -0.3243, -0.2518],\n",
      "         [ 0.1117, -0.0547,  0.0406, -0.0213, -0.3251, -0.2993],\n",
      "         [ 0.1196, -0.0491,  0.0318, -0.0635, -0.2788, -0.2578]],\n",
      "\n",
      "        [[ 0.1569, -0.0873,  0.0210,  0.0215, -0.3243, -0.2518],\n",
      "         [ 0.1117, -0.0547,  0.0406, -0.0213, -0.3251, -0.2993],\n",
      "         [ 0.1196, -0.0491,  0.0318, -0.0635, -0.2788, -0.2578]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "context_vecs.shape: torch.Size([3, 3, 6])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "# Define the tensor with 3 rows and 6 columns\n",
    "inputs = torch.tensor(\n",
    "    [[0.43, 0.15, 0.89, 0.55, 0.87, 0.66],  # Row 1\n",
    "     [0.57, 0.85, 0.64, 0.22, 0.58, 0.33],  # Row 2\n",
    "     [0.77, 0.25, 0.10, 0.05, 0.80, 0.55]]  # Row 3\n",
    ")\n",
    "\n",
    "batch = torch.stack((inputs, inputs, inputs), dim=0)\n",
    "print(batch.shape) \n",
    "\n",
    "batch_size, context_length, d_in = batch.shape\n",
    "d_out = 6\n",
    "mha = MultiHeadAttention(d_in, d_out, context_length, 0.0, num_heads=2)\n",
    "context_vecs = mha(batch)\n",
    "print(context_vecs)\n",
    "print(\"context_vecs.shape:\", context_vecs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7bd413",
   "metadata": {},
   "source": [
    "# IMPLEMENTING A GPT MODEL FROM SCRATCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "0f241421",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,    # Vocabulary size\n",
    "    \"context_length\": 1024, # Context length\n",
    "    \"emb_dim\": 768,         # Embedding dimension\n",
    "    \"n_heads\": 12,          # Number of attention heads\n",
    "    \"n_layers\": 12,         # Number of layers\n",
    "    \"drop_rate\": 0.1,       # Dropout rate\n",
    "    \"qkv_bias\": False       # Query-Key-Value bias\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bdb5c42",
   "metadata": {},
   "source": [
    "# GPT Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "1d6b0da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class DummyGPTModel(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
    "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
    "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
    "        \n",
    "        # Use a placeholder for TransformerBlock\n",
    "        self.trf_blocks = nn.Sequential(\n",
    "            *[DummyTransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])])\n",
    "        \n",
    "        # Use a placeholder for LayerNorm\n",
    "        self.final_norm = DummyLayerNorm(cfg[\"emb_dim\"])\n",
    "        self.out_head = nn.Linear(\n",
    "            cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False\n",
    "        )\n",
    "\n",
    "    def forward(self, in_idx):\n",
    "        batch_size, seq_len = in_idx.shape\n",
    "        tok_embeds = self.tok_emb(in_idx)\n",
    "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
    "        x = tok_embeds + pos_embeds\n",
    "        x = self.drop_emb(x)\n",
    "        x = self.trf_blocks(x) # this will do nothing yet\n",
    "        x = self.final_norm(x) # this will do nothing yet (this not the inside normalization of tf block normalization this after the data pass through the tf block)\n",
    "        logits = self.out_head(x)\n",
    "        return logits\n",
    "\n",
    "\n",
    "class DummyTransformerBlock(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        # A simple placeholder\n",
    "\n",
    "    def forward(self, x):\n",
    "        # This block does nothing and just returns its input.\n",
    "        return x\n",
    "\n",
    "\n",
    "class DummyLayerNorm(nn.Module):\n",
    "    def __init__(self, normalized_shape, eps=1e-5):\n",
    "        super().__init__()\n",
    "        # The parameters here are just to mimic the LayerNorm interface.\n",
    "\n",
    "    def forward(self, x):\n",
    "        # This layer does nothing and just returns its input.\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "448c7564",
   "metadata": {},
   "source": [
    "# tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "2253fd56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[6109, 3626, 6100,  345],\n",
      "        [6109, 1110, 6622,  257]])\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "batch = []\n",
    "txt1 = \"Every effort moves you\"\n",
    "txt2 = \"Every day holds a\"\n",
    "batch.append(torch.tensor(tokenizer.encode(txt1)))\n",
    "batch.append(torch.tensor(tokenizer.encode(txt2)))\n",
    "batch = torch.stack(batch, dim=0)\n",
    "print(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1537302c",
   "metadata": {},
   "source": [
    "# Lets try to create an instance of dummy model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "41f581f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([2, 4, 50257])\n",
      "tensor([[[-1.2034,  0.3201, -0.7130,  ..., -1.5548, -0.2390, -0.4667],\n",
      "         [-0.1192,  0.4539, -0.4432,  ...,  0.2392,  1.3469,  1.2430],\n",
      "         [ 0.5307,  1.6720, -0.4695,  ...,  1.1966,  0.0111,  0.5835],\n",
      "         [ 0.0139,  1.6754, -0.3388,  ...,  1.1586, -0.0435, -1.0400]],\n",
      "\n",
      "        [[-1.0908,  0.1798, -0.9484,  ..., -1.6047,  0.2439, -0.4530],\n",
      "         [-0.7860,  0.5581, -0.0610,  ...,  0.4835, -0.0077,  1.6621],\n",
      "         [ 0.3567,  1.2698, -0.6398,  ..., -0.0162, -0.1296,  0.3717],\n",
      "         [-0.2407, -0.7349, -0.5102,  ...,  2.0057, -0.3694,  0.1814]]],\n",
      "       grad_fn=<UnsafeViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "model = DummyGPTModel(GPT_CONFIG_124M)\n",
    "logits = model(batch)\n",
    "print(\"Output shape:\", logits.shape)\n",
    "print(logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ff3c12",
   "metadata": {},
   "source": [
    "# Layer normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "ff685ed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2260, 0.3470, 0.0000, 0.2216, 0.0000, 0.0000],\n",
      "        [0.2133, 0.2394, 0.0000, 0.5198, 0.3297, 0.0000]],\n",
      "       grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "batch_example = torch.randn(2, 5) #A\n",
    "layer = nn.Sequential(nn.Linear(5, 6), nn.ReLU())\n",
    "out = layer(batch_example)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "6f262beb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean:\n",
      " tensor([[0.1324],\n",
      "        [0.2170]], grad_fn=<MeanBackward1>)\n",
      "Variance:\n",
      " tensor([[0.0231],\n",
      "        [0.0398]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "source": [
    "mean = out.mean(dim=-1, keepdim=True)\n",
    "var = out.var(dim=-1, keepdim=True)\n",
    "print(\"Mean:\\n\", mean)\n",
    "print(\"Variance:\\n\", var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "ff574d21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized layer outputs:\n",
      " tensor([[ 0.6159,  1.4126, -0.8719,  0.5872, -0.8719, -0.8719],\n",
      "        [-0.0189,  0.1121, -1.0876,  1.5173,  0.5647, -1.0876]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "Mean:\n",
      " tensor([[-5.9605e-08],\n",
      "        [ 1.9868e-08]], grad_fn=<MeanBackward1>)\n",
      "Variance:\n",
      " tensor([[1.0000],\n",
      "        [1.0000]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "source": [
    "out_norm = (out - mean) / torch.sqrt(var)\n",
    "mean = out_norm.mean(dim=-1, keepdim=True)\n",
    "var = out_norm.var(dim=-1, keepdim=True)\n",
    "print(\"Normalized layer outputs:\\n\", out_norm)\n",
    "print(\"Mean:\\n\", mean)\n",
    "print(\"Variance:\\n\", var)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d3f3d7",
   "metadata": {},
   "source": [
    "Note that the value 2.9802e-08 in the output tensor is the scientific notation for 2.9802 × 10-8, which is 0.0000000298 in decimal form. This value is very close to 0, but it is not exactly 0 due to small numerical errors that can accumulate because of the finite precision with which computers represent numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "0a1e6db5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean:\n",
      " tensor([[    -0.0000],\n",
      "        [     0.0000]], grad_fn=<MeanBackward1>)\n",
      "Variance:\n",
      " tensor([[1.0000],\n",
      "        [1.0000]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.set_printoptions(sci_mode=False)\n",
    "print(\"Mean:\\n\", mean)\n",
    "print(\"Variance:\\n\", var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "1930768b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, emb_dim):\n",
    "        super().__init__()\n",
    "        self.eps = 1e-5\n",
    "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
    "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(dim=-1, keepdim=True)\n",
    "        var = x.var(dim=-1, keepdim=True, unbiased=False) #Bessel's correction, which typically uses n-1 instead of n in the denominator to adjust for bias in sample variance estimation.\n",
    "#This decision results in a so-called biased estimate of the variance.\n",
    "#For large-scale language models (LLMs), where the embedding dimension n is significantly large, the difference between using n and n-1 is practically negligible.\n",
    "\n",
    "        norm_x = (x - mean) / torch.sqrt(var + self.eps)\n",
    "        return self.scale * norm_x + self.shift"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67694eca",
   "metadata": {},
   "source": [
    "# Feed Forward (GELU Activation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "a0eafa2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GELU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return 0.5 * x * (1 + torch.tanh(\n",
    "            torch.sqrt(torch.tensor(2.0 / torch.pi)) * \n",
    "            (x + 0.044715 * torch.pow(x, 3))\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "1ac25ca1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "gelu, relu = GELU(), nn.ReLU()\n",
    "\n",
    "# Some sample data\n",
    "x = torch.linspace(-5, 5, 100)\n",
    "y_gelu, y_relu = gelu(x), relu(x)\n",
    "\n",
    "plt.figure(figsize=(8, 3))\n",
    "for i, (y, label) in enumerate(zip([y_gelu, y_relu], [\"GELU\", \"ReLU\"]), 1):\n",
    "    plt.subplot(1, 2, i)\n",
    "    plt.plot(x, y)\n",
    "    plt.title(f\"{label} activation function\")\n",
    "    plt.xlabel(\"x\")\n",
    "    plt.ylabel(f\"{label}(x)\")\n",
    "    plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "b63e6bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(cfg[\"emb_dim\"], 4 * cfg[\"emb_dim\"]), #Expansion\n",
    "            GELU(),\n",
    "            nn.Linear(4 * cfg[\"emb_dim\"], cfg[\"emb_dim\"]), #Contraction\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "f7b6b5a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 768])\n"
     ]
    }
   ],
   "source": [
    "ffn = FeedForward(GPT_CONFIG_124M)\n",
    "x = torch.rand(2, 3, 768) #A\n",
    "out = ffn(x)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cdb13d6",
   "metadata": {},
   "source": [
    "# Shortcut Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "26ab923e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExampleDeepNeuralNetwork(nn.Module):\n",
    "    def __init__(self, layer_sizes, use_shortcut):\n",
    "        super().__init__()\n",
    "        self.use_shortcut = use_shortcut\n",
    "        self.layers = nn.ModuleList([\n",
    "            nn.Sequential(nn.Linear(layer_sizes[0], layer_sizes[1]), GELU()),\n",
    "            nn.Sequential(nn.Linear(layer_sizes[1], layer_sizes[2]), GELU()),\n",
    "            nn.Sequential(nn.Linear(layer_sizes[2], layer_sizes[3]), GELU()),\n",
    "            nn.Sequential(nn.Linear(layer_sizes[3], layer_sizes[4]), GELU()),\n",
    "            nn.Sequential(nn.Linear(layer_sizes[4], layer_sizes[5]), GELU())\n",
    "        ])\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            # Compute the output of the current layer\n",
    "            layer_output = layer(x)\n",
    "            # Check if shortcut can be applied\n",
    "            if self.use_shortcut and x.shape == layer_output.shape:\n",
    "                x = x + layer_output\n",
    "            else:\n",
    "                x = layer_output\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65030813",
   "metadata": {},
   "source": [
    "Implepenting Backward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "9a6d77b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_sizes = [3, 3, 3, 3, 3, 1]\n",
    "sample_input = torch.tensor([[1., 0., -1.]])\n",
    "torch.manual_seed(123) # specify random seed for the initial weights for reproducibility\n",
    "model_without_shortcut = ExampleDeepNeuralNetwork(\n",
    "layer_sizes, use_shortcut=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "38004031",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_gradients(model, x):\n",
    "    # Forward pass\n",
    "    output = model(x)\n",
    "    target = torch.tensor([[0.]])\n",
    "\n",
    "    # Calculate loss based on how close the target and output are\n",
    "    loss = nn.MSELoss()\n",
    "    loss = loss(output, target)\n",
    "    \n",
    "    # Backward pass to calculate the gradients\n",
    "    loss.backward()\n",
    "\n",
    "    for name, param in model.named_parameters():\n",
    "        if 'weight' in name:\n",
    "            # Print the mean absolute gradient of the weights\n",
    "            print(f\"{name} has gradient mean of {param.grad.abs().mean().item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "3057d7dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers.0.0.weight has gradient mean of 0.00020173587836325169\n",
      "layers.1.0.weight has gradient mean of 0.0001201116101583466\n",
      "layers.2.0.weight has gradient mean of 0.0007152041071094573\n",
      "layers.3.0.weight has gradient mean of 0.0013988735154271126\n",
      "layers.4.0.weight has gradient mean of 0.005049645435065031\n"
     ]
    }
   ],
   "source": [
    "print_gradients(model_without_shortcut, sample_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "cdba1682",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers.0.0.weight has gradient mean of 0.22169791162014008\n",
      "layers.1.0.weight has gradient mean of 0.20694106817245483\n",
      "layers.2.0.weight has gradient mean of 0.32896995544433594\n",
      "layers.3.0.weight has gradient mean of 0.2665732204914093\n",
      "layers.4.0.weight has gradient mean of 1.3258540630340576\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "model_with_shortcut = ExampleDeepNeuralNetwork(\n",
    "layer_sizes, use_shortcut=True\n",
    ")\n",
    "print_gradients(model_with_shortcut, sample_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1684b87",
   "metadata": {},
   "source": [
    "It seems it does solves the problem of vanishing Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d14d2cf4",
   "metadata": {},
   "source": [
    "# Lets put'em All together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "fce71284",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,    # Vocabulary size\n",
    "    \"context_length\": 1024, # Context length\n",
    "    \"emb_dim\": 768,         # Embedding dimension\n",
    "    \"n_heads\": 12,          # Number of attention heads\n",
    "    \"n_layers\": 12,         # Number of layers\n",
    "    \"drop_rate\": 0.1,       # Dropout rate\n",
    "    \"qkv_bias\": False       # Query-Key-Value bias\n",
    "}\n",
    "#tokenizer\n",
    "import tiktoken\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "# #Mutihead-Attention\n",
    "# class MultiHeadAttention(nn.Module):\n",
    "#     def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n",
    "#         super().__init__()\n",
    "#         assert (d_out % num_heads == 0), \\\n",
    "#             \"d_out must be divisible by num_heads\"\n",
    "\n",
    "#         self.d_out = d_out\n",
    "#         self.num_heads = num_heads\n",
    "#         self.head_dim = d_out // num_heads # Reduce the projection dim to match desired output dim\n",
    "\n",
    "#         self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "#         self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "#         self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "#         self.out_proj = nn.Linear(d_out, d_out)  # Linear layer to combine head outputs\n",
    "#         self.dropout = nn.Dropout(dropout)\n",
    "#         self.register_buffer(\n",
    "#             \"mask\",\n",
    "#             torch.triu(torch.ones(context_length, context_length),\n",
    "#                        diagonal=1)\n",
    "#         )\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         b, num_tokens, d_in = x.shape\n",
    "\n",
    "#         keys = self.W_key(x) # Shape: (b, num_tokens, d_out)\n",
    "#         queries = self.W_query(x)\n",
    "#         values = self.W_value(x)\n",
    "\n",
    "#         # We implicitly split the matrix by adding a `num_heads` dimension\n",
    "#         # Unroll last dim: (b, num_tokens, d_out) -> (b, num_tokens, num_heads, head_dim)\n",
    "#         keys = keys.view(b, num_tokens, self.num_heads, self.head_dim) \n",
    "#         values = values.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "#         queries = queries.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "\n",
    "#         # Transpose: (b, num_tokens, num_heads, head_dim) -> (b, num_heads, num_tokens, head_dim)\n",
    "#         keys = keys.transpose(1, 2)\n",
    "#         queries = queries.transpose(1, 2)\n",
    "#         values = values.transpose(1, 2)\n",
    "\n",
    "#         # Compute scaled dot-product attention (aka self-attention) with a causal mask\n",
    "#         attn_scores = queries @ keys.transpose(2, 3)  # Dot product for each head\n",
    "\n",
    "#         # Original mask truncated to the number of tokens and converted to boolean\n",
    "#         mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n",
    "\n",
    "#         # Use the mask to fill attention scores\n",
    "#         attn_scores.masked_fill_(mask_bool, -torch.inf)\n",
    "        \n",
    "#         attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
    "#         attn_weights = self.dropout(attn_weights)\n",
    "\n",
    "#         # Shape: (b, num_tokens, num_heads, head_dim)\n",
    "#         context_vec = (attn_weights @ values).transpose(1, 2) \n",
    "        \n",
    "#         # Combine heads, where self.d_out = self.num_heads * self.head_dim\n",
    "#         context_vec = context_vec.contiguous().view(b, num_tokens, self.d_out)\n",
    "#         context_vec = self.out_proj(context_vec) # optional projection\n",
    "\n",
    "#         return context_vec\n",
    "    \n",
    "# #Layer_Norm\n",
    "# class LayerNorm(nn.Module):\n",
    "#     def __init__(self, emb_dim):\n",
    "#         super().__init__()\n",
    "#         self.eps = 1e-5\n",
    "#         self.scale = nn.Parameter(torch.ones(emb_dim))\n",
    "#         self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         mean = x.mean(dim=-1, keepdim=True)\n",
    "#         var = x.var(dim=-1, keepdim=True, unbiased=False) \n",
    "#         norm_x = (x - mean) / torch.sqrt(var + self.eps)\n",
    "#         return self.scale * norm_x + self.shift\n",
    "    \n",
    "# #GELU_Activation\n",
    "# class GELU(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super().__init__()\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         return 0.5 * x * (1 + torch.tanh(\n",
    "#             torch.sqrt(torch.tensor(2.0 / torch.pi)) * \n",
    "#             (x + 0.044715 * torch.pow(x, 3))\n",
    "#         ))\n",
    "\n",
    "# #FeedForward Function\n",
    "# class FeedForward(nn.Module):\n",
    "#     def __init__(self, cfg):\n",
    "#         super().__init__()\n",
    "#         self.layers = nn.Sequential(\n",
    "#             nn.Linear(cfg[\"emb_dim\"], 4 * cfg[\"emb_dim\"]), #Expansion\n",
    "#             GELU(),                                        #Activation_Function\n",
    "#             nn.Linear(4 * cfg[\"emb_dim\"], cfg[\"emb_dim\"]), #Contraction\n",
    "#         )\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         return self.layers(x)\n",
    "    \n",
    "#Transformerblock  \n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.att = MultiHeadAttention(\n",
    "            d_in=cfg[\"emb_dim\"],\n",
    "            d_out=cfg[\"emb_dim\"],\n",
    "            context_length=cfg[\"context_length\"],\n",
    "            num_heads=cfg[\"n_heads\"], \n",
    "            dropout=cfg[\"drop_rate\"],\n",
    "            qkv_bias=cfg[\"qkv_bias\"])\n",
    "        self.ff = FeedForward(cfg)\n",
    "        self.norm1 = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.norm2 = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.drop_shortcut = nn.Dropout(cfg[\"drop_rate\"])\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Shortcut connection for attention block\n",
    "        shortcut = x\n",
    "        x = self.norm1(x)\n",
    "        x = self.att(x)  # Shape [batch_size, num_tokens, emb_size]\n",
    "        x = self.drop_shortcut(x)\n",
    "        x = x + shortcut  # Add the original input back\n",
    "\n",
    "        # Shortcut connection for feed forward block\n",
    "        shortcut = x\n",
    "        x = self.norm2(x)\n",
    "        x = self.ff(x)\n",
    "        x = self.drop_shortcut(x)\n",
    "        x = x + shortcut  # Add the original input back\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "d0f73905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([2, 6, 768])\n",
      "Output shape: torch.Size([2, 6, 768])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "x = torch.rand(2, 6, 768) #A\n",
    "block = TransformerBlock(GPT_CONFIG_124M)\n",
    "output = block(x)\n",
    "print(\"Input shape:\", x.shape)\n",
    "print(\"Output shape:\", output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458b8954",
   "metadata": {},
   "source": [
    "# Alright Avengers Assemble Sorry... LLM Assemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "6be809dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[6109, 3626, 6100,  345],\n",
      "        [6109, 1110, 6622,  257]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "#tokenizer\n",
    "import tiktoken\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "batch = []\n",
    "txt1 = \"Every effort moves you\"\n",
    "txt2 = \"Every day holds a\"\n",
    "batch.append(torch.tensor(tokenizer.encode(txt1)))\n",
    "batch.append(torch.tensor(tokenizer.encode(txt2)))\n",
    "batch = torch.stack(batch, dim=0)\n",
    "print(batch)\n",
    "\n",
    "class GPTModel(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
    "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
    "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
    "        \n",
    "        # Use TransformerBlock\n",
    "        self.trf_blocks = nn.Sequential(\n",
    "            *[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])])\n",
    "        \n",
    "        #Use Layer_Normalization\n",
    "        self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.out_head = nn.Linear(\n",
    "            cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False\n",
    "        )\n",
    "\n",
    "    def forward(self, in_idx):\n",
    "        batch_size, seq_len = in_idx.shape\n",
    "        tok_embeds = self.tok_emb(in_idx)\n",
    "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
    "        x = tok_embeds + pos_embeds\n",
    "        x = self.drop_emb(x)\n",
    "        x = self.trf_blocks(x) # this will do nothing yet\n",
    "        x = self.final_norm(x) # this will do nothing yet (this not the inside normalization of tf block normalization this after the data pass through the tf block)\n",
    "        logits = self.out_head(x)\n",
    "        return logits\n",
    "\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.att = MultiHeadAttention(\n",
    "            d_in=cfg[\"emb_dim\"],\n",
    "            d_out=cfg[\"emb_dim\"],\n",
    "            context_length=cfg[\"context_length\"],\n",
    "            num_heads=cfg[\"n_heads\"], \n",
    "            dropout=cfg[\"drop_rate\"],\n",
    "            qkv_bias=cfg[\"qkv_bias\"])\n",
    "        self.ff = FeedForward(cfg)\n",
    "        self.norm1 = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.norm2 = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.drop_shortcut = nn.Dropout(cfg[\"drop_rate\"])\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Shortcut connection for attention block\n",
    "        shortcut = x\n",
    "        x = self.norm1(x)\n",
    "        x = self.att(x)  # Shape [batch_size, num_tokens, emb_size]\n",
    "        x = self.drop_shortcut(x)\n",
    "        x = x + shortcut  # Add the original input back\n",
    "\n",
    "        # Shortcut connection for feed forward block\n",
    "        shortcut = x\n",
    "        x = self.norm2(x)\n",
    "        x = self.ff(x)\n",
    "        x = self.drop_shortcut(x)\n",
    "        x = x + shortcut  # Add the original input back\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, emb_dim):\n",
    "        super().__init__()\n",
    "        self.eps = 1e-5\n",
    "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
    "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(dim=-1, keepdim=True)\n",
    "        var = x.var(dim=-1, keepdim=True, unbiased=False) \n",
    "        norm_x = (x - mean) / torch.sqrt(var + self.eps)\n",
    "        return self.scale * norm_x + self.shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "df5da873",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input batch:\n",
      " tensor([[6109, 3626, 6100,  345],\n",
      "        [6109, 1110, 6622,  257]])\n",
      "Input batch:\n",
      " torch.Size([2, 4])\n",
      "\n",
      "Output shape: torch.Size([2, 4, 50257])\n",
      "tensor([[[ 0.3613,  0.4223, -0.0711,  ...,  0.3483,  0.4661, -0.2838],\n",
      "         [-0.1792, -0.5660, -0.9485,  ...,  0.0477,  0.5181, -0.3168],\n",
      "         [ 0.7120,  0.0332,  0.1085,  ...,  0.1018, -0.4327, -0.2553],\n",
      "         [-1.0076,  0.3418, -0.1190,  ...,  0.7195,  0.4023,  0.0532]],\n",
      "\n",
      "        [[-0.2564,  0.0900,  0.0335,  ...,  0.2659,  0.4454, -0.6806],\n",
      "         [ 0.1230,  0.3653, -0.2074,  ...,  0.7705,  0.2710,  0.2246],\n",
      "         [ 1.0558,  1.0318, -0.2800,  ...,  0.6936,  0.3205, -0.3178],\n",
      "         [-0.1565,  0.3926,  0.3288,  ...,  1.2630, -0.1858,  0.0388]]],\n",
      "       grad_fn=<UnsafeViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "out = model(batch)\n",
    "print(\"Input batch:\\n\", batch)\n",
    "print(\"Input batch:\\n\", batch.shape)\n",
    "print(\"\\nOutput shape:\", out.shape)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "8f204f2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 163,009,536\n"
     ]
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Total number of parameters: {total_params:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39c0174",
   "metadata": {},
   "source": [
    "As we know GPT-2 is a 124 million parameter GPT model, so why is the actual number of parameters 163 million, as shown in the preceding code output?\n",
    "The reason is a concept called weight tying that is used in the original GPT-2 architecture, which means that the original GPT-2 architecture is reusing the weights from the token embedding layer in its output layer.\n",
    "\n",
    "To understand what this means, let's take a look at the shapes of the token embedding layer and linear output layer that we initialized on the model via the GPTModel earlier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "b222b79b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token embedding layer shape: torch.Size([50257, 768])\n",
      "Output layer shape: torch.Size([50257, 768])\n"
     ]
    }
   ],
   "source": [
    "print(\"Token embedding layer shape:\", model.tok_emb.weight.shape)\n",
    "print(\"Output layer shape:\", model.out_head.weight.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "eeef2bd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of trainable parameters considering weight tying: 124,412,160\n",
      "Total size of the model: 621.83 MB\n"
     ]
    }
   ],
   "source": [
    "total_params_gpt2 = total_params - sum(p.numel() for p in model.out_head.parameters())\n",
    "print(f\"Number of trainable parameters considering weight tying: {total_params_gpt2:,}\")\n",
    "\n",
    "total_size_bytes = total_params * 4 #A\n",
    "total_size_mb = total_size_bytes / (1024 * 1024) #B\n",
    "print(f\"Total size of the model: {total_size_mb:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2989cc90",
   "metadata": {},
   "source": [
    "# Lets generate text from output logit tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "2ac72879",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text_simple(model, idx, max_new_tokens, context_size):\n",
    "    # idx is (batch, n_tokens) array of indices in the current context\n",
    "    for _ in range(max_new_tokens):\n",
    "        \n",
    "        # Crop current context if it exceeds the supported context size\n",
    "        # E.g., if LLM supports only 5 tokens, and the context size is 10\n",
    "        # then only the last 5 tokens are used as context\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "        \n",
    "        # Get the predictions\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond) # (batch, n_tokens, vocab_size)\n",
    "        \n",
    "        # Focus only on the last time step\n",
    "        # (batch, n_tokens, vocab_size) becomes (batch, vocab_size)\n",
    "        logits = logits[:, -1, :]  \n",
    "\n",
    "        # Apply softmax to get proababilities\n",
    "        probas = torch.softmax(logits, dim=-1)  # (batch, vocab_size)\n",
    "\n",
    "        # Get the idx of the vocab entry with the highest probability value\n",
    "        idx_next = torch.argmax(probas, dim=-1, keepdim=True)  # (batch, 1)\n",
    "\n",
    "        # Append sampled index to the running sequence\n",
    "        idx = torch.cat((idx, idx_next), dim=1)  # (batch, n_tokens+1)\n",
    "\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "1b78ca7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoded: [15496, 11, 314, 716]\n",
      "encoded_tensor.shape: torch.Size([1, 4])\n"
     ]
    }
   ],
   "source": [
    "start_context = \"Hello, I am\"\n",
    "encoded = tokenizer.encode(start_context)\n",
    "print(\"encoded:\", encoded)\n",
    "encoded_tensor = torch.tensor(encoded).unsqueeze(0) #A\n",
    "print(\"encoded_tensor.shape:\", encoded_tensor.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97742555",
   "metadata": {},
   "source": [
    "Next, we put the model into .eval() mode, which disables random components like dropout, which are only used during training, and use the generate_text_simple function on the encoded input tensor:\n",
    "We disable dropout since we are not training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "58d1523d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: tensor([[15496,    11,   314,   716, 27018, 24086, 47843, 30961, 42348,  7267]])\n",
      "Output length: 10\n"
     ]
    }
   ],
   "source": [
    "model.eval() #A\n",
    "out = generate_text_simple(\n",
    "model=model,\n",
    "idx=encoded_tensor,\n",
    "max_new_tokens=6,\n",
    "context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "print(\"Output:\", out)\n",
    "print(\"Output length:\", len(out[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "c4c24749",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, I am Featureiman Byeswickattribute argue\n"
     ]
    }
   ],
   "source": [
    "decoded_text = tokenizer.decode(out.squeeze(0).tolist())\n",
    "print(decoded_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d112ff35",
   "metadata": {},
   "source": [
    "# Using GPT to generate text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "dc4abc27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,   # Vocabulary size\n",
    "    \"context_length\": 256, # Shortened context length (orig: 1024)\n",
    "    \"emb_dim\": 768,        # Embedding dimension\n",
    "    \"n_heads\": 12,         # Number of attention heads\n",
    "    \"n_layers\": 12,        # Number of layers\n",
    "    \"drop_rate\": 0.1,      # Dropout rate\n",
    "    \"qkv_bias\": False      # Query-key-value bias\n",
    "}\n",
    "\n",
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.eval();  # Disable dropout during inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "219283f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you rentingetic wasnم refres RexMeCHicular stren\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "def text_to_token_ids(text, tokenizer):\n",
    "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0) # add batch dimension\n",
    "    return encoded_tensor\n",
    "\n",
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "    flat = token_ids.squeeze(0) # remove batch dimension\n",
    "    return tokenizer.decode(flat.tolist())\n",
    "\n",
    "start_context = \"Every effort moves you\"\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(start_context, tokenizer),\n",
    "    max_new_tokens=10,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab84e06",
   "metadata": {},
   "source": [
    "As we can see above, the model does not produce good text because it has not been trained yet\n",
    "\n",
    "How do we measure or capture what \"good text\" is, in a numeric form, to track it during training?\n",
    "\n",
    "The next subsection introduces metrics to calculate a loss metric for the generated outputs that we can use to measure the training progress\n",
    "\n",
    "The next chapters on finetuning LLMs will also introduce additional ways to measure model quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "5b16dad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.tensor([[16833, 3626, 6100],   # [\"every effort moves\",\n",
    "                       [40,    1107, 588]])   #  \"I really like\"]\n",
    "\n",
    "targets = torch.tensor([[3626, 6100, 345  ],  # [\" effort moves you\",\n",
    "                        [1107,  588, 11311]]) #  \" really like chocolate\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "601a6401",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 50257])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    logits = model(inputs)\n",
    "\n",
    "probas = torch.softmax(logits, dim=-1) # Probability of each token in vocabulary\n",
    "print(probas.shape) # Shape: (batch_size, num_tokens, vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "1527d1c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token IDs:\n",
      " tensor([[[16657],\n",
      "         [  339],\n",
      "         [42826]],\n",
      "\n",
      "        [[49906],\n",
      "         [29669],\n",
      "         [41751]]])\n"
     ]
    }
   ],
   "source": [
    "token_ids = torch.argmax(probas, dim=-1, keepdim=True)\n",
    "print(\"Token IDs:\\n\", token_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "e4bac258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Targets batch 1:  effort moves you\n",
      "Outputs batch 1:  Armed heNetflix\n"
     ]
    }
   ],
   "source": [
    "print(f\"Targets batch 1: {token_ids_to_text(targets[0], tokenizer)}\")\n",
    "print(f\"Outputs batch 1: {token_ids_to_text(token_ids[0].flatten(), tokenizer)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9393be33",
   "metadata": {},
   "source": [
    "# Cross entropy loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "0ed16894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text 1: tensor([    0.0001,     0.0000,     0.0000])\n",
      "Text 2: tensor([    0.0000,     0.0001,     0.0000])\n"
     ]
    }
   ],
   "source": [
    "text_idx = 0\n",
    "target_probas_1 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
    "print(\"Text 1:\", target_probas_1)\n",
    "\n",
    "text_idx = 1\n",
    "target_probas_2 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
    "print(\"Text 2:\", target_probas_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "541a510a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ -9.5042, -10.3796, -11.3677, -11.4798,  -9.7764, -12.2561])\n"
     ]
    }
   ],
   "source": [
    "# Compute logarithm of all token probabilities\n",
    "log_probas = torch.log(torch.cat((target_probas_1, target_probas_2)))\n",
    "print(log_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "96d666be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-10.7940)\n"
     ]
    }
   ],
   "source": [
    "# Calculate the average probability for each token\n",
    "avg_log_probas = torch.mean(log_probas)\n",
    "print(avg_log_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "e2ca7c3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.7940)\n"
     ]
    }
   ],
   "source": [
    "neg_avg_log_probas = avg_log_probas * -1\n",
    "print(neg_avg_log_probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e61685f8",
   "metadata": {},
   "source": [
    "# PyTorch already implements a cross_entropy function that carries out the previous steps\n",
    "\n",
    "Before we apply the cross_entropy function, let's check the shape of the logits and targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "0cc691c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits shape: torch.Size([2, 3, 50257])\n",
      "Targets shape: torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "# Logits have shape (batch_size, num_tokens, vocab_size)\n",
    "print(\"Logits shape:\", logits.shape)\n",
    "\n",
    "# Targets have shape (batch_size, num_tokens)\n",
    "print(\"Targets shape:\", targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "e3aedfd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flattened logits: torch.Size([6, 50257])\n",
      "Flattened targets: torch.Size([6])\n"
     ]
    }
   ],
   "source": [
    "logits_flat = logits.flatten(0, 1)\n",
    "targets_flat = targets.flatten()\n",
    "\n",
    "print(\"Flattened logits:\", logits_flat.shape)\n",
    "print(\"Flattened targets:\", targets_flat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "49162f8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.7940)\n"
     ]
    }
   ],
   "source": [
    "loss = torch.nn.functional.cross_entropy(logits_flat, targets_flat)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d76ca3f1",
   "metadata": {},
   "source": [
    "# Perplexity\n",
    "A concept related to the cross-entropy loss is the perplexity of an LLM.\n",
    "\n",
    "The perplexity is simply the exponential of the cross-entropy loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "c8301447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(48725.8203)\n"
     ]
    }
   ],
   "source": [
    "perplexity = torch.exp(loss)\n",
    "print(perplexity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30aaca4",
   "metadata": {},
   "source": [
    "We use a relatively small dataset for training the LLM (in fact, only one short story)\n",
    "\n",
    "The reasons are:\n",
    "\n",
    "You can run the code examples in a few minutes on a laptop computer without a suitable GPU.\n",
    "\n",
    "The training finishes relatively fast (minutes instead of weeks), which is good for educational purposes.\n",
    "\n",
    "We use a text from the public domain, which can be included in this GitHub repository without violating any usage rights or bloating the repository size.\n",
    "\n",
    "For example, Llama 2 7B required 184,320 GPU hours on A100 GPUs to be trained on 2 trillion tokens\n",
    "\n",
    "At the time of this writing, the hourly cost of an 8xA100 cloud server at AWS is approximately 30 dollars.\n",
    "\n",
    "So, via an off-the-envelope calculation, training this LLM would cost 184,320 / 8 * 30 = 690,000 dollars\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40394b7c",
   "metadata": {},
   "source": [
    "# Calculating the training and validation set losses on verdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "b487fe11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of characters 20479\n",
      "I HAD always thought Jack Gisburn rather a cheap genius--though a good fellow enough--so it was no \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "\n",
    "file_path = \"the-verdict.txt\"\n",
    "url = \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch02/01_main-chapter-code/the-verdict.txt\"\n",
    "\n",
    "if not os.path.exists(file_path):\n",
    "    with urllib.request.urlopen(url) as response:\n",
    "        text_data = response.read().decode('utf-8')\n",
    "    with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(text_data)\n",
    "else:\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        text_data = file.read()\n",
    "\n",
    "# with open(\"the-verdict.txt\",\"r\", encoding = \"utf-8\") as f:\n",
    "#     text_data=f.read()\n",
    "    \n",
    "print(\"Number of characters\", len(text_data))\n",
    "print(text_data[:99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "f80cc055",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Characters: 20479\n",
      "Tokens: 5145\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "total_characters = len(text_data)\n",
    "total_tokens = len(tokenizer.encode(text_data))\n",
    "\n",
    "print(\"Characters:\", total_characters)\n",
    "print(\"Tokens:\", total_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "fe62940e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "class GPTDatasetV1(Dataset):\n",
    "    def __init__(self, txt, tokenizer, max_length, stride):\n",
    "        self.input_ids = []\n",
    "        self.target_ids = []\n",
    "\n",
    "        # Tokenize the entire text\n",
    "        token_ids = tokenizer.encode(txt, allowed_special={\"<|endoftext|>\"})\n",
    "\n",
    "        # Use a sliding window to chunk the book into overlapping sequences of max_length\n",
    "        for i in range(0, len(token_ids) - max_length, stride):\n",
    "            input_chunk = token_ids[i:i + max_length]\n",
    "            target_chunk = token_ids[i + 1: i + max_length + 1]\n",
    "            self.input_ids.append(torch.tensor(input_chunk))\n",
    "            self.target_ids.append(torch.tensor(target_chunk))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_ids[idx], self.target_ids[idx]\n",
    "\n",
    "\n",
    "def create_dataloader_v1(txt, batch_size=4, max_length=256, \n",
    "                         stride=128, shuffle=True, drop_last=True,\n",
    "                         num_workers=0):\n",
    "\n",
    "    # Initialize the tokenizer\n",
    "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "    # Create dataset\n",
    "    dataset = GPTDatasetV1(txt, tokenizer, max_length, stride)\n",
    "\n",
    "    # Create dataloader\n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        drop_last=drop_last,\n",
    "        num_workers=num_workers\n",
    "    )\n",
    "\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "8cd20fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,   # Vocabulary size\n",
    "    \"context_length\": 256, # Shortened context length (orig: 1024)\n",
    "    \"emb_dim\": 768,        # Embedding dimension\n",
    "    \"n_heads\": 12,         # Number of attention heads\n",
    "    \"n_layers\": 12,        # Number of layers\n",
    "    \"drop_rate\": 0.1,      # Dropout rate\n",
    "    \"qkv_bias\": False      # Query-key-value bias\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "7248e9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/validation ratio\n",
    "train_ratio = 0.90\n",
    "split_idx = int(train_ratio * len(text_data))\n",
    "train_data = text_data[:split_idx]\n",
    "val_data = text_data[split_idx:]\n",
    "\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader = create_dataloader_v1(\n",
    "    train_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=True,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "val_loader = create_dataloader_v1(\n",
    "    val_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=False,\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c3dadf",
   "metadata": {},
   "source": [
    "# Sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "3347e9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "if total_tokens * (train_ratio) < GPT_CONFIG_124M[\"context_length\"]:\n",
    "    print(\"Not enough tokens for the training loader. \"\n",
    "          \"Try to lower the `GPT_CONFIG_124M['context_length']` or \"\n",
    "          \"increase the `training_ratio`\")\n",
    "\n",
    "if total_tokens * (1-train_ratio) < GPT_CONFIG_124M[\"context_length\"]:\n",
    "    print(\"Not enough tokens for the validation loader. \"\n",
    "          \"Try to lower the `GPT_CONFIG_124M['context_length']` or \"\n",
    "          \"decrease the `training_ratio`\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "1adae6d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "\n",
      "Validation loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "9\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(\"Train loader:\")\n",
    "for x, y in train_loader:\n",
    "    print(x.shape, y.shape)\n",
    "\n",
    "print(\"\\nValidation loader:\")\n",
    "for x, y in val_loader:\n",
    "    print(x.shape, y.shape)\n",
    "\n",
    "print(len(train_loader))\n",
    "print(len(val_loader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "1f32cff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training tokens: 4608\n",
      "Validation tokens: 512\n",
      "All tokens: 5120\n"
     ]
    }
   ],
   "source": [
    "train_tokens = 0\n",
    "for input_batch, target_batch in train_loader:\n",
    "    train_tokens += input_batch.numel()\n",
    "\n",
    "val_tokens = 0\n",
    "for input_batch, target_batch in val_loader:\n",
    "    val_tokens += input_batch.numel()\n",
    "\n",
    "print(\"Training tokens:\", train_tokens)\n",
    "print(\"Validation tokens:\", val_tokens)\n",
    "print(\"All tokens:\", train_tokens + val_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "244ac6b2",
   "metadata": {},
   "source": [
    "# Here is the GPT Model class we coded earlier. We will need this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "deb91f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTModel(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
    "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
    "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
    "        \n",
    "        self.trf_blocks = nn.Sequential(\n",
    "            *[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])])\n",
    "        \n",
    "        self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.out_head = nn.Linear(\n",
    "            cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False\n",
    "        )\n",
    "\n",
    "    def forward(self, in_idx):\n",
    "        batch_size, seq_len = in_idx.shape\n",
    "        tok_embeds = self.tok_emb(in_idx)\n",
    "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
    "        x = tok_embeds + pos_embeds  # Shape [batch_size, num_tokens, emb_size]\n",
    "        x = self.drop_emb(x)\n",
    "        x = self.trf_blocks(x)\n",
    "        x = self.final_norm(x)\n",
    "        logits = self.out_head(x)\n",
    "        return logits\n",
    "\n",
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.eval();  # Disable dropout during inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "fd3524c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "    logits = model(input_batch)\n",
    "    loss = torch.nn.functional.cross_entropy(logits.flatten(0, 1), target_batch.flatten())\n",
    "    return loss\n",
    "\n",
    "\n",
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0.\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        # Reduce the number of batches to match the total number of batches in the data loader\n",
    "        # if num_batches exceeds the number of batches in the data loader\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "    return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd778a3f",
   "metadata": {},
   "source": [
    "If you have a machine with a CUDA-supported GPU, the LLM will train on the GPU without making any changes to the code.\n",
    "\n",
    "Via the device setting, we ensure that the data is loaded onto the same device as the LLM model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "0d609eb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 10.98758347829183\n",
      "Validation loss: 10.98110580444336\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Note:\n",
    "# Uncommenting the following lines will allow the code to run on Apple Silicon chips, if applicable,\n",
    "# which is approximately 2x faster than on an Apple CPU (as measured on an M3 MacBook Air).\n",
    "# However, the resulting loss values may be slightly different.\n",
    "\n",
    "#if torch.cuda.is_available():\n",
    "#    device = torch.device(\"cuda\")\n",
    "#elif torch.backends.mps.is_available():\n",
    "#    device = torch.device(\"mps\")\n",
    "#else:\n",
    "#    device = torch.device(\"cpu\")\n",
    "#\n",
    "# print(f\"Using {device} device.\")\n",
    "\n",
    "\n",
    "model.to(device) # no assignment model = model.to(device) necessary for nn.Module classes\n",
    "\n",
    "\n",
    "torch.manual_seed(123) # For reproducibility due to the shuffling in the data loader\n",
    "\n",
    "with torch.no_grad(): # Disable gradient tracking for efficiency because we are not training, yet\n",
    "    train_loss = calc_loss_loader(train_loader, model, device)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device)\n",
    "\n",
    "print(\"Training loss:\", train_loss)\n",
    "print(\"Validation loss:\", val_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "204930bb",
   "metadata": {},
   "source": [
    "# Pre training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "4219decf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_simple(model, train_loader, val_loader, optimizer, device, num_epochs,\n",
    "                       eval_freq, eval_iter, start_context, tokenizer):\n",
    "    # Initialize lists to track losses and tokens seen\n",
    "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
    "    tokens_seen, global_step = 0, -1\n",
    "\n",
    "    # Main training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # Set model to training mode\n",
    "        \n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad() # Reset loss gradients from previous batch iteration\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            loss.backward() # Calculate loss gradients\n",
    "            optimizer.step() # Update model weights using loss gradients\n",
    "            tokens_seen += input_batch.numel() # Returns the total number of elements (or tokens) in the input_batch.\n",
    "            global_step += 1\n",
    "\n",
    "            # Optional evaluation step\n",
    "            if global_step % eval_freq == 0: \n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                    model, train_loader, val_loader, device, eval_iter)\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                track_tokens_seen.append(tokens_seen)\n",
    "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
    "                      f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
    "\n",
    "        # Print a sample text after each epoch\n",
    "        generate_and_print_sample(\n",
    "            model, tokenizer, device, start_context\n",
    "        )\n",
    "\n",
    "    return train_losses, val_losses, track_tokens_seen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5445bed2",
   "metadata": {},
   "source": [
    "Step 1: Initialize lists to track losses and tokens seen\n",
    "\n",
    "Step 2: Start the main training loop\n",
    "\n",
    "Step 3: Reset loss gradients from previous batch iteration\n",
    "\n",
    "Step 4: Calculate loss gradients\n",
    "\n",
    "Step 5: Update model weights using loss gradients\n",
    "\n",
    "Step 6: Optional evaluation step\n",
    "\n",
    "Step 7: Print a sample text after each epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "52369d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "    model.train()\n",
    "    return train_loss, val_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b037958",
   "metadata": {},
   "source": [
    "The evaluate_model function calculates the loss over the training and validation set while ensuring the model is in evaluation mode with gradient tracking and dropout disabled when calculating the loss over the training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "51d648bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
    "    model.eval()\n",
    "    context_size = model.pos_emb.weight.shape[0]\n",
    "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
    "    with torch.no_grad():\n",
    "        token_ids = generate_text_simple(\n",
    "            model=model, idx=encoded,\n",
    "            max_new_tokens=50, context_size=context_size\n",
    "        )\n",
    "    decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    print(decoded_text.replace(\"\\n\", \" \"))  # Compact print format\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a03d8d",
   "metadata": {},
   "source": [
    "The generate_and_print_sample function is a convenience function that we use to track whether the model improves during the training.\n",
    "\n",
    "In particular, the generate_and_print_sample function takes a text snippet (start_context) as input, converts it into token IDs, and feeds it to the LLM to generate a text sample using the generate_text_simple function we used earlier\n",
    "\n",
    "Let's see this all in action by training a GPTModel instance for 10 epochs using an AdamW optimizer and the train_model_simple function we defined earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "e118bdef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 9.781, Val loss 9.933\n",
      "Ep 1 (Step 000005): Train loss 8.111, Val loss 8.339\n",
      "Every effort moves you,,,,,,,,,,,,.                                     \n",
      "Ep 2 (Step 000010): Train loss 6.661, Val loss 7.048\n",
      "Ep 2 (Step 000015): Train loss 5.961, Val loss 6.616\n",
      "Every effort moves you, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and,, and, and,\n",
      "Ep 3 (Step 000020): Train loss 5.726, Val loss 6.600\n",
      "Ep 3 (Step 000025): Train loss 5.201, Val loss 6.348\n",
      "Every effort moves you, and I had been.                                            \n",
      "Ep 4 (Step 000030): Train loss 4.417, Val loss 6.278\n",
      "Ep 4 (Step 000035): Train loss 4.069, Val loss 6.226\n",
      "Every effort moves you know the                          \"I he had the donkey and I had the and I had the donkey and down the room, I had\n",
      "Ep 5 (Step 000040): Train loss 3.732, Val loss 6.160\n",
      "Every effort moves you know it was not that the picture--I had the fact by the last I had been--his, and in the            \"Oh, and he said, and down the room, and in\n",
      "Ep 6 (Step 000045): Train loss 2.850, Val loss 6.179\n",
      "Ep 6 (Step 000050): Train loss 2.427, Val loss 6.141\n",
      "Every effort moves you know,\" was one of the picture. The--I had a little of a little: \"Yes, and in fact, and in the picture was, and I had been at my elbow and as his pictures, and down the room, I had\n",
      "Ep 7 (Step 000055): Train loss 2.104, Val loss 6.134\n",
      "Ep 7 (Step 000060): Train loss 1.882, Val loss 6.233\n",
      "Every effort moves you know,\" was one of the picture for nothing--I told Mrs.  \"I was no--as! The women had been, in the moment--as Jack himself, as once one had been the donkey, and were, and in his\n",
      "Ep 8 (Step 000065): Train loss 1.320, Val loss 6.238\n",
      "Ep 8 (Step 000070): Train loss 0.985, Val loss 6.242\n",
      "Every effort moves you know,\" was one of the axioms he had been the tips of a self-confident moustache, I felt to see a smile behind his close grayish beard--as if he had the donkey. \"strongest,\" as his\n",
      "Ep 9 (Step 000075): Train loss 0.717, Val loss 6.293\n",
      "Ep 9 (Step 000080): Train loss 0.541, Val loss 6.393\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back the window-curtains, I had the donkey. \"There were days when I\n",
      "Ep 10 (Step 000085): Train loss 0.391, Val loss 6.452\n",
      "Every effort moves you know,\" was one of the axioms he laid down across the Sevres and silver of an exquisitely appointed luncheon-table, when, on a later day, I had again run over from Monte Carlo; and Mrs. Gis\n",
      "Training completed in 4.52 minutes.\n"
     ]
    }
   ],
   "source": [
    "# Note:\n",
    "# Uncomment the following code to calculate the execution time\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0004, weight_decay=0.1)\n",
    "\n",
    "num_epochs = 10\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
    "    start_context=\"Every effort moves you\", tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "# Note:\n",
    "# Uncomment the following code to show the execution time\n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affca64d",
   "metadata": {},
   "source": [
    "As we can see, based on the results printed during the training, the training loss improves drastically, starting with a value of 9.781 and converging to 0.391.\n",
    "\n",
    "The language skills of the model have improved quite a lot. In the beginning, the model is only able to append commas to the start context (\"Every effort moves you,,,,,,,,,,,,\") or repeat the word \"and\".\n",
    "\n",
    "At the end of the training, it can generate grammatically correct text.\n",
    "Similar to the training set loss, we can see that the validation loss starts high (9.856) and decreases during the training.\n",
    "\n",
    "However, it never becomes as small as the training set loss and remains at 6.372 after the 10th epoch.\n",
    "\n",
    "Let's create a simple plot that shows the training and validation set losses side by side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "1edf2e0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "\n",
    "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "\n",
    "    # Plot training and validation loss against epochs\n",
    "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
    "    ax1.plot(epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.legend(loc=\"upper right\")\n",
    "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))  # only show integer labels on x-axis\n",
    "\n",
    "    # Create a second x-axis for tokens seen\n",
    "    ax2 = ax1.twiny()  # Create a second x-axis that shares the same y-axis\n",
    "    ax2.plot(tokens_seen, train_losses, alpha=0)  # Invisible plot for aligning ticks\n",
    "    ax2.set_xlabel(\"Tokens seen\")\n",
    "\n",
    "    fig.tight_layout()  # Adjust layout to make room\n",
    "    plt.savefig(\"loss-plot.pdf\")\n",
    "    plt.show()\n",
    "\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3fff69",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
