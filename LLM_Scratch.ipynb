{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5054fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"the-verdict.txt\",\"r\", encoding = \"utf-8\") as f:\n",
    "    raw_text=f.read()\n",
    "    \n",
    "print(\"Number of characters\", len(raw_text))\n",
    "print(raw_text[:99])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca80d08b",
   "metadata": {},
   "source": [
    "# Creating Tokenizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "075356d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "text = \"Hello, world. --Hi I'm LLM, Is a test? If yes: I'm going to smash it!\"\n",
    "result = re.split(r'([,.:;?_!\"()\\']|--|\\s)', text)\n",
    "print(result)\n",
    "result =[item.strip() for item in result if item.strip()]\n",
    "print('\\n',result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4243bbbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed = re.split(r'([,.:;?_!\"()\\']|--|\\s)', raw_text)\n",
    "preprocessed =[item.strip() for item in preprocessed if item.strip()]\n",
    "print(preprocessed[:50])\n",
    "print('\\n',len(preprocessed))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef9795c",
   "metadata": {},
   "source": [
    "# Creating Token IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf11d201",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = sorted(set(preprocessed))\n",
    "\n",
    "print(len(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e112297b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = {token:integer for integer,token in enumerate(words)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79a39d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (token, idx) in enumerate(vocab.items()):\n",
    "    if i >= 20:\n",
    "        break\n",
    "    print(f\"{i:2d}: {token}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "92463169",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleTokenizerV1:\n",
    "    def __init__(self, vocab):\n",
    "        self.str_to_int = vocab\n",
    "        self.int_to_str = {i:s for s,i in vocab.items()}\n",
    "    \n",
    "    def encode(self, text):\n",
    "        preprocessed = re.split(r'([,.:;?_!\"()\\']|--|\\s)', text)\n",
    "        preprocessed = [item.strip() for item in preprocessed if item.strip()]\n",
    "        ids = [self.str_to_int[s] for s in preprocessed]\n",
    "        \n",
    "        return ids\n",
    "        \n",
    "    def decode(self, ids):\n",
    "        text = \" \".join([self.int_to_str[i] for i in ids])\n",
    "\n",
    "        # Remove space before punctuation\n",
    "        text = re.sub(r\"\\s+([,.?;:!()\\\"'])\", r\"\\1\", text)\n",
    "\n",
    "        # Remove space only after opening quotes — not closing\n",
    "        text = re.sub(r'(^|[\\s(\\[\"])\\s+', r'\\1', text)\n",
    "\n",
    "        # Fix -- spacing\n",
    "        text = re.sub(r\"\\s+--\\s+\", \"--\", text)\n",
    "\n",
    "        # Fix common contractions\n",
    "        text = re.sub(r\"'\\s+s\\b\", \"'s\", text)\n",
    "        text = re.sub(r\"'\\s+t\\b\", \"'t\", text)\n",
    "        text = re.sub(r\"'\\s+re\\b\", \"'re\", text)\n",
    "        text = re.sub(r\"'\\s+ve\\b\", \"'ve\", text)\n",
    "        text = re.sub(r\"'\\s+d\\b\", \"'d\", text)\n",
    "        text = re.sub(r\"'\\s+ll\\b\", \"'ll\", text)\n",
    "        text = re.sub(r\"'\\s+m\\b\", \"'m\", text)\n",
    "\n",
    "        # Add space after ?\" or !\" if followed by any letter\n",
    "        text = re.sub(r'([,?.!])(\")([A-Za-z])', r'\\1\\2 \\3', text)\n",
    "\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3fea9c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = SimpleTokenizerV1(vocab)\n",
    "\n",
    "text = \"\"\"\"Why _has_ he chucked painting?\" I asked abruptly.\"\"\"\n",
    "ids = tokenizer.encode(text)\n",
    "print(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c28c8a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = tokenizer.decode(ids)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1360c8b",
   "metadata": {},
   "source": [
    "# Adding Special tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "85e3ad3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tokens = sorted(list(set(preprocessed)))\n",
    "all_tokens.extend([\"<|endoftext|>\", \"<|unk|>\"])\n",
    "\n",
    "vocab = {token:integer for integer,token in enumerate(all_tokens)}\n",
    "print(len(vocab))  \n",
    "print(list(vocab.items())[-5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7aea7898",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleTokenizerV2:\n",
    "    def __init__(self, vocab):\n",
    "        self.str_to_int = vocab\n",
    "        self.int_to_str = {i:s for s,i in vocab.items()}\n",
    "    \n",
    "    def encode(self, text):\n",
    "        preprocessed = re.split(r'([,.:;?_!\"()\\']|--|\\s)', text)\n",
    "        preprocessed = [item.strip() for item in preprocessed if item.strip()]\n",
    "        preprocessed = [item if item in self.str_to_int else \"<|unk|>\" for item in preprocessed]\n",
    "        ids = [self.str_to_int[s] for s in preprocessed]\n",
    "        \n",
    "        return ids\n",
    "        \n",
    "    def decode(self, ids):\n",
    "        text = \" \".join([self.int_to_str[i] for i in ids])\n",
    "\n",
    "        # Remove space before punctuation\n",
    "        text = re.sub(r\"\\s+([,.?;:!()\\\"'])\", r\"\\1\", text)\n",
    "\n",
    "        # Remove space only after opening quotes — not closing\n",
    "        text = re.sub(r'(^|[\\s(\\[\"])\\s+', r'\\1', text)\n",
    "\n",
    "        # Fix -- spacing\n",
    "        text = re.sub(r\"\\s+--\\s+\", \"--\", text)\n",
    "\n",
    "        # Fix common contractions\n",
    "        text = re.sub(r\"'\\s+s\\b\", \"'s\", text)\n",
    "        text = re.sub(r\"'\\s+t\\b\", \"'t\", text)\n",
    "        text = re.sub(r\"'\\s+re\\b\", \"'re\", text)\n",
    "        text = re.sub(r\"'\\s+ve\\b\", \"'ve\", text)\n",
    "        text = re.sub(r\"'\\s+d\\b\", \"'d\", text)\n",
    "        text = re.sub(r\"'\\s+ll\\b\", \"'ll\", text)\n",
    "        text = re.sub(r\"'\\s+m\\b\", \"'m\", text)\n",
    "\n",
    "        # Add space after ?\" or ,\" etc. if followed by a word (any letter)\n",
    "        text = re.sub(r'([,?.!])(\")([A-Za-z])', r'\\1\\2 \\3', text)\n",
    "\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c5c43a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = SimpleTokenizerV2(vocab)\n",
    "\n",
    "text1 = \"Hello, do you like tea?\"\n",
    "text2 = \"She raised her eyebrows with a hint of good-humoured surprise.\"\n",
    "\n",
    "text = \" <|endoftext|> \".join((text1,text2))\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7902c3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.encode(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3640fcb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.decode(tokenizer.encode(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88fe65f2",
   "metadata": {},
   "source": [
    "\"Hello\" was not vocab but SimpleTokenizerV2 handles it now"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e82b5bc",
   "metadata": {},
   "source": [
    "# Byte pair Encoding \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c8f964",
   "metadata": {},
   "source": [
    "With chatgpt tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c3394356",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tiktoken in /Users/junaeidshoaib/anaconda3/lib/python3.11/site-packages (0.9.0)\r\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Users/junaeidshoaib/anaconda3/lib/python3.11/site-packages (from tiktoken) (2022.7.9)\r\n",
      "Requirement already satisfied: requests>=2.26.0 in /Users/junaeidshoaib/anaconda3/lib/python3.11/site-packages (from tiktoken) (2.32.4)\r\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/junaeidshoaib/anaconda3/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken) (2.0.4)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/junaeidshoaib/anaconda3/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken) (3.4)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/junaeidshoaib/anaconda3/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken) (1.26.16)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/junaeidshoaib/anaconda3/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken) (2024.7.4)\r\n"
     ]
    }
   ],
   "source": [
    "! pip3 install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1db057e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tiktoken version: 0.9.0\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import tiktoken\n",
    "\n",
    "print(\"tiktoken version:\", importlib.metadata.version(\"tiktoken\"))\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e0d3d7a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15496, 11, 466, 345, 588, 8887, 30, 220, 50256, 554, 262, 4252, 18250, 8812, 2114, 1659, 617, 34680, 27271, 13]\n"
     ]
    }
   ],
   "source": [
    "text = (\"Hello, do you like tea? <|endoftext|> In the sunlit terraces\"\n",
    "     \"of someunknownPlace.\")\n",
    "\n",
    "integers = tokenizer.encode(text, allowed_special={\"<|endoftext|>\"})\n",
    "\n",
    "print(integers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3fe7bd59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, do you like tea? <|endoftext|> In the sunlit terracesof someunknownPlace.\n"
     ]
    }
   ],
   "source": [
    "text = tokenizer.decode(integers)\n",
    "\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca5b73a",
   "metadata": {},
   "source": [
    "# input-target pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6e71f48c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5145\n"
     ]
    }
   ],
   "source": [
    "encoded_text = tokenizer.encode(raw_text) #byte pair encoding\n",
    "print(len(encoded_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0ed20df0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5095\n"
     ]
    }
   ],
   "source": [
    "encoded_sample = encoded_text[50:]\n",
    "print(len(encoded_sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dacf7faf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: [290, 4920, 2241, 287]\n",
      "y:      [4920, 2241, 287, 257]\n"
     ]
    }
   ],
   "source": [
    "context_size = 4\n",
    "\n",
    "x = encoded_sample[:context_size]\n",
    "y = encoded_sample[1:context_size+1]\n",
    "print(f'x:',x)\n",
    "print(f'y:     ',y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ee05e136",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " and -->  established\n",
      " and established -->  himself\n",
      " and established himself -->  in\n",
      " and established himself in -->  a\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, context_size+1):\n",
    "    context = encoded_sample[:i]\n",
    "    desired = encoded_sample[i]\n",
    "    print(tokenizer.decode(context), \"-->\",tokenizer.decode([desired]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa39567d",
   "metadata": {},
   "source": [
    "# Data loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b53a6989",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "class GPTDatasetV1(Dataset):\n",
    "    def __init__(self, txt, tokenizer, max_length, stride):\n",
    "        self.input_ids = []\n",
    "        self.target_ids = []\n",
    "\n",
    "        # Tokenize the entire text\n",
    "        token_ids = tokenizer.encode(txt, allowed_special={\"<|endoftext|>\"})\n",
    "\n",
    "        # Use a sliding window to chunk the book into overlapping sequences of max_length\n",
    "        for i in range(0, len(token_ids) - max_length, stride):\n",
    "            input_chunk = token_ids[i:i + max_length]\n",
    "            target_chunk = token_ids[i + 1: i + max_length + 1]\n",
    "            self.input_ids.append(torch.tensor(input_chunk))\n",
    "            self.target_ids.append(torch.tensor(target_chunk))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_ids[idx], self.target_ids[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "161c957b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloader_v1(txt, batch_size=4, max_length=256, \n",
    "                         stride=128, shuffle=True, drop_last=True,\n",
    "                         num_workers=0):\n",
    "\n",
    "    # Initialize the tokenizer\n",
    "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "    # Create dataset\n",
    "    dataset = GPTDatasetV1(txt, tokenizer, max_length, stride)\n",
    "\n",
    "    # Create dataloader\n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        drop_last=drop_last,\n",
    "        num_workers=num_workers\n",
    "    )\n",
    "\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "278c9a17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.6.0\n",
      "[tensor([[  40,  367, 2885, 1464]]), tensor([[ 367, 2885, 1464, 1807]])]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"PyTorch version:\", torch.__version__)\n",
    "dataloader = create_dataloader_v1(raw_text, batch_size=1, max_length=4, stride=1, shuffle=False)\n",
    "\n",
    "data_iter = iter(dataloader)\n",
    "first_batch = next(data_iter)\n",
    "print(first_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2fe53590",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[ 367, 2885, 1464, 1807]]), tensor([[2885, 1464, 1807, 3619]])]\n"
     ]
    }
   ],
   "source": [
    "second_batch = next(data_iter)\n",
    "print(second_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4e1b8d66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs:\n",
      " tensor([[   40,   367,  2885,  1464],\n",
      "        [ 1807,  3619,   402,   271],\n",
      "        [10899,  2138,   257,  7026],\n",
      "        [15632,   438,  2016,   257],\n",
      "        [  922,  5891,  1576,   438],\n",
      "        [  568,   340,   373,   645],\n",
      "        [ 1049,  5975,   284,   502],\n",
      "        [  284,  3285,   326,    11]])\n",
      "\n",
      "Targets:\n",
      " tensor([[  367,  2885,  1464,  1807],\n",
      "        [ 3619,   402,   271, 10899],\n",
      "        [ 2138,   257,  7026, 15632],\n",
      "        [  438,  2016,   257,   922],\n",
      "        [ 5891,  1576,   438,   568],\n",
      "        [  340,   373,   645,  1049],\n",
      "        [ 5975,   284,   502,   284],\n",
      "        [ 3285,   326,    11,   287]])\n"
     ]
    }
   ],
   "source": [
    "dataloader = create_dataloader_v1(raw_text, batch_size=8, max_length=4, stride=4, shuffle=False)\n",
    "\n",
    "data_iter = iter(dataloader)\n",
    "inputs, targets = next(data_iter)\n",
    "print(\"Inputs:\\n\", inputs)\n",
    "print(\"\\nTargets:\\n\", targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "031a27fc",
   "metadata": {},
   "source": [
    "# Create token embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "726f31d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = torch.tensor([2, 3, 5, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "377254d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 6\n",
    "output_dim = 3\n",
    "\n",
    "torch.manual_seed(123)\n",
    "embedding_layer = torch.nn.Embedding(vocab_size, output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f1ec84a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.3374, -0.1778, -0.1690],\n",
      "        [ 0.9178,  1.5810,  1.3010],\n",
      "        [ 1.2753, -0.2010, -0.1606],\n",
      "        [-0.4015,  0.9666, -1.1481],\n",
      "        [-1.1589,  0.3255, -0.6315],\n",
      "        [-2.8400, -0.7849, -1.4096]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(embedding_layer.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d6a8f936",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.4015,  0.9666, -1.1481]], grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(embedding_layer(torch.tensor([3])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "268df778",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.2753, -0.2010, -0.1606],\n",
      "        [-0.4015,  0.9666, -1.1481],\n",
      "        [-2.8400, -0.7849, -1.4096],\n",
      "        [ 0.9178,  1.5810,  1.3010]], grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(embedding_layer(input_ids))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62bed941",
   "metadata": {},
   "source": [
    "# Positional embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8b8a14a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 50257\n",
    "output_dim = 256\n",
    "\n",
    "token_embedding_layer = torch.nn.Embedding(vocab_size, output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3bd27344",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 4\n",
    "dataloader = create_dataloader_v1(\n",
    "    raw_text, batch_size=8, max_length=max_length,\n",
    "    stride=max_length, shuffle=False\n",
    ")\n",
    "data_iter = iter(dataloader)\n",
    "inputs, targets = next(data_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7537fcdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token IDs:\n",
      " tensor([[   40,   367,  2885,  1464],\n",
      "        [ 1807,  3619,   402,   271],\n",
      "        [10899,  2138,   257,  7026],\n",
      "        [15632,   438,  2016,   257],\n",
      "        [  922,  5891,  1576,   438],\n",
      "        [  568,   340,   373,   645],\n",
      "        [ 1049,  5975,   284,   502],\n",
      "        [  284,  3285,   326,    11]])\n",
      "\n",
      "Inputs shape:\n",
      " torch.Size([8, 4])\n"
     ]
    }
   ],
   "source": [
    "print(\"Token IDs:\\n\", inputs)\n",
    "print(\"\\nInputs shape:\\n\", inputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4985e447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 4, 256])\n"
     ]
    }
   ],
   "source": [
    "token_embeddings = token_embedding_layer(inputs)\n",
    "print(token_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ba5f1288",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_length = max_length\n",
    "pos_embedding_layer = torch.nn.Embedding(context_length, output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e7788af8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 256])\n"
     ]
    }
   ],
   "source": [
    "pos_embeddings = pos_embedding_layer(torch.arange(max_length))\n",
    "print(pos_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9cff635e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 4, 256])\n"
     ]
    }
   ],
   "source": [
    "input_embeddings = token_embeddings + pos_embeddings\n",
    "print(input_embeddings.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b68200e",
   "metadata": {},
   "source": [
    "# Implementing Simplified Attention Mechanism"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f967d5dc",
   "metadata": {},
   "source": [
    "For the sake of simplicity: we are considering 3-D vector so that it fits on the page without linr breaking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "91c8d3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "inputs = torch.tensor(\n",
    "  [[0.43, 0.15, 0.89], # Your     (x^1)\n",
    "   [0.55, 0.87, 0.66], # journey  (x^2)\n",
    "   [0.57, 0.85, 0.64], # starts   (x^3)\n",
    "   [0.22, 0.58, 0.33], # with     (x^4)\n",
    "   [0.77, 0.25, 0.10], # one      (x^5)\n",
    "   [0.05, 0.80, 0.55]] # step     (x^6)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7a57d7d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# Corresponding words\n",
    "words = ['Your', 'journey', 'starts', 'with', 'one', 'step']\n",
    "\n",
    "# Extract x, y, z coordinates\n",
    "x_coords = inputs[:, 0].numpy()\n",
    "y_coords = inputs[:, 1].numpy()\n",
    "z_coords = inputs[:, 2].numpy()\n",
    "\n",
    "# Create 3D plot\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Plot each point and annotate with corresponding word\n",
    "for x, y, z, word in zip(x_coords, y_coords, z_coords, words):\n",
    "    ax.scatter(x, y, z)\n",
    "    ax.text(x, y, z, word, fontsize=10)\n",
    "\n",
    "# Set labels for axes\n",
    "ax.set_xlabel('X')\n",
    "ax.set_ylabel('Y')\n",
    "ax.set_zlabel('Z')\n",
    "\n",
    "\n",
    "plt.title('3D Plot of Word Embeddings')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "087cf55c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.9544, 1.4950, 1.4754, 0.8434, 0.7070, 1.0865])\n"
     ]
    }
   ],
   "source": [
    "query = inputs[1]  # 2nd input token is the query \"journey\"\n",
    "\n",
    "attn_scores_2 = torch.empty(inputs.shape[0])\n",
    "for i, x_i in enumerate(inputs):\n",
    "    attn_scores_2[i] = torch.dot(x_i, query) # dot product (transpose not necessary here since they are 1-dim vectors)\n",
    "\n",
    "print(attn_scores_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d03891",
   "metadata": {},
   "source": [
    "In the next step, we normalize each of the attention scores that we computed previously.\n",
    "\n",
    "The main goal behind the normalization is to obtain attention weights that sum up to 1.\n",
    "\n",
    "This normalization is a convention that is useful for interpretation and for maintaining training stability in an LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e9c1bfb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention weights: tensor([0.1455, 0.2278, 0.2249, 0.1285, 0.1077, 0.1656])\n",
      "Sum: tensor(1.0000)\n"
     ]
    }
   ],
   "source": [
    "attn_weights_2_tmp = attn_scores_2 / attn_scores_2.sum()\n",
    "\n",
    "print(\"Attention weights:\", attn_weights_2_tmp)\n",
    "print(\"Sum:\", attn_weights_2_tmp.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "022bc579",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention weights: tensor([0.1385, 0.2379, 0.2333, 0.1240, 0.1082, 0.1581])\n",
      "Sum: tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "#normal softmax\n",
    "def softmax_naive(x):\n",
    "    return torch.exp(x) / torch.exp(x).sum(dim=0)\n",
    "\n",
    "attn_weights_2_naive = softmax_naive(attn_scores_2)\n",
    "\n",
    "print(\"Attention weights:\", attn_weights_2_naive)\n",
    "print(\"Sum:\", attn_weights_2_naive.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "dde90831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention weights: tensor([0.1385, 0.2379, 0.2333, 0.1240, 0.1082, 0.1581])\n",
      "Sum: tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "#py torch soft max (better and usual practice because of enormous values)\n",
    "attn_weights_2 = torch.softmax(attn_scores_2, dim=0)\n",
    "print(\"Attention weights:\", attn_weights_2)\n",
    "print(\"Sum:\", attn_weights_2.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "02be8c52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.4419, 0.6515, 0.5683])\n"
     ]
    }
   ],
   "source": [
    "context_vec_2 = torch.zeros(query.shape)\n",
    "for i,x_i in enumerate(inputs):\n",
    "    context_vec_2 += attn_weights_2[i]*x_i\n",
    "\n",
    "print(context_vec_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e0c1aa",
   "metadata": {},
   "source": [
    "Now, we can extend this computation to calculate attention weights and context vectors for all inputs.\n",
    "\n",
    "First, we add an additional for-loop to compute the dot products for all pairs of inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3efeeb81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9995, 0.9544, 0.9422, 0.4753, 0.4576, 0.6310],\n",
      "        [0.9544, 1.4950, 1.4754, 0.8434, 0.7070, 1.0865],\n",
      "        [0.9422, 1.4754, 1.4570, 0.8296, 0.7154, 1.0605],\n",
      "        [0.4753, 0.8434, 0.8296, 0.4937, 0.3474, 0.6565],\n",
      "        [0.4576, 0.7070, 0.7154, 0.3474, 0.6654, 0.2935],\n",
      "        [0.6310, 1.0865, 1.0605, 0.6565, 0.2935, 0.9450]])\n"
     ]
    }
   ],
   "source": [
    "attn_scores = torch.empty(6, 6)\n",
    "\n",
    "for i, x_i in enumerate(inputs):\n",
    "    for j, x_j in enumerate(inputs):\n",
    "        attn_scores[i, j] = torch.dot(x_i, x_j)\n",
    "\n",
    "print(attn_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e87f221",
   "metadata": {},
   "source": [
    "this will take ages to compute\n",
    "so what will do is a shortcut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1da21ffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9995, 0.9544, 0.9422, 0.4753, 0.4576, 0.6310],\n",
      "        [0.9544, 1.4950, 1.4754, 0.8434, 0.7070, 1.0865],\n",
      "        [0.9422, 1.4754, 1.4570, 0.8296, 0.7154, 1.0605],\n",
      "        [0.4753, 0.8434, 0.8296, 0.4937, 0.3474, 0.6565],\n",
      "        [0.4576, 0.7070, 0.7154, 0.3474, 0.6654, 0.2935],\n",
      "        [0.6310, 1.0865, 1.0605, 0.6565, 0.2935, 0.9450]])\n"
     ]
    }
   ],
   "source": [
    "attn_scores = inputs @ inputs.T\n",
    "print(attn_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a1c74c9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2098, 0.2006, 0.1981, 0.1242, 0.1220, 0.1452],\n",
      "        [0.1385, 0.2379, 0.2333, 0.1240, 0.1082, 0.1581],\n",
      "        [0.1390, 0.2369, 0.2326, 0.1242, 0.1108, 0.1565],\n",
      "        [0.1435, 0.2074, 0.2046, 0.1462, 0.1263, 0.1720],\n",
      "        [0.1526, 0.1958, 0.1975, 0.1367, 0.1879, 0.1295],\n",
      "        [0.1385, 0.2184, 0.2128, 0.1420, 0.0988, 0.1896]])\n"
     ]
    }
   ],
   "source": [
    "attn_weights = torch.softmax(attn_scores, dim=-1)\n",
    "print(attn_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56673c0a",
   "metadata": {},
   "source": [
    "we now use these attention weights to compute all context vectors via matrix multiplication:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1065998c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4421, 0.5931, 0.5790],\n",
      "        [0.4419, 0.6515, 0.5683],\n",
      "        [0.4431, 0.6496, 0.5671],\n",
      "        [0.4304, 0.6298, 0.5510],\n",
      "        [0.4671, 0.5910, 0.5266],\n",
      "        [0.4177, 0.6503, 0.5645]])\n"
     ]
    }
   ],
   "source": [
    "all_context_vecs = attn_weights @ inputs\n",
    "print(all_context_vecs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e91c6286",
   "metadata": {},
   "source": [
    "# IMPLEMENTING SELF ATTENTION WITH TRAINABLE WEIGHTS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "71dd2717",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_2 = inputs[1] #A\n",
    "d_in = inputs.shape[1] #B\n",
    "d_out = 2 #C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a5d3a465",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W_query:\n",
      " Parameter containing:\n",
      "tensor([[0.2961, 0.5166],\n",
      "        [0.2517, 0.6886],\n",
      "        [0.0740, 0.8665]])\n",
      "W_key :\n",
      " Parameter containing:\n",
      "tensor([[0.1366, 0.1025],\n",
      "        [0.1841, 0.7264],\n",
      "        [0.3153, 0.6871]])\n",
      "W_value:\n",
      " Parameter containing:\n",
      "tensor([[0.0756, 0.1966],\n",
      "        [0.3164, 0.4017],\n",
      "        [0.1186, 0.8274]])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "W_query = torch.nn.Parameter(torch.rand(d_in, d_out), requires_grad=False)\n",
    "W_key = torch.nn.Parameter(torch.rand(d_in, d_out), requires_grad=False)\n",
    "W_value = torch.nn.Parameter(torch.rand(d_in, d_out), requires_grad=False)\n",
    "print(f'W_query:\\n',W_query)\n",
    "print(f'W_key :\\n',W_key )\n",
    "print(f'W_value:\\n',W_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "757d80fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.4306, 1.4551])\n"
     ]
    }
   ],
   "source": [
    "query_2 = x_2 @ W_query\n",
    "key_2 = x_2 @ W_key\n",
    "value_2 = x_2 @ W_value\n",
    "print(query_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7acda12d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "queries.shape: torch.Size([6, 2])\n",
      "queries:\n",
      " tensor([[0.2309, 1.0966],\n",
      "        [0.4306, 1.4551],\n",
      "        [0.4300, 1.4343],\n",
      "        [0.2355, 0.7990],\n",
      "        [0.2983, 0.6565],\n",
      "        [0.2568, 1.0533]])\n",
      "keys.shape: torch.Size([6, 2])\n",
      "keys:\n",
      " tensor([[0.3669, 0.7646],\n",
      "        [0.4433, 1.1419],\n",
      "        [0.4361, 1.1156],\n",
      "        [0.2408, 0.6706],\n",
      "        [0.1827, 0.3292],\n",
      "        [0.3275, 0.9642]])\n",
      "values.shape: torch.Size([6, 2])\n",
      "values:\n",
      " tensor([[0.1855, 0.8812],\n",
      "        [0.3951, 1.0037],\n",
      "        [0.3879, 0.9831],\n",
      "        [0.2393, 0.5493],\n",
      "        [0.1492, 0.3346],\n",
      "        [0.3221, 0.7863]])\n"
     ]
    }
   ],
   "source": [
    "keys = inputs @ W_key\n",
    "values = inputs @ W_value\n",
    "queries = inputs @ W_query\n",
    "print(\"queries.shape:\", queries.shape)\n",
    "print(\"queries:\\n\", queries)\n",
    "\n",
    "print(\"keys.shape:\", keys.shape)\n",
    "print(\"keys:\\n\", keys)\n",
    "\n",
    "print(\"values.shape:\", values.shape)\n",
    "print(\"values:\\n\", values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d3415c1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.8524)\n"
     ]
    }
   ],
   "source": [
    "keys_2 = keys[1] #A\n",
    "attn_score_22 = query_2.dot(keys_2)\n",
    "print(attn_score_22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8ea52fbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.2705, 1.8524, 1.8111, 1.0795, 0.5577, 1.5440])\n"
     ]
    }
   ],
   "source": [
    "attn_scores_2 = query_2 @ keys.T # All attention scores for given query (T because 1x2 dot 6,2 with T = 2,6)\n",
    "print(attn_scores_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "521e29aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9231, 1.3545, 1.3241, 0.7910, 0.4032, 1.1330],\n",
      "        [1.2705, 1.8524, 1.8111, 1.0795, 0.5577, 1.5440],\n",
      "        [1.2544, 1.8284, 1.7877, 1.0654, 0.5508, 1.5238],\n",
      "        [0.6973, 1.0167, 0.9941, 0.5925, 0.3061, 0.8475],\n",
      "        [0.6114, 0.8819, 0.8626, 0.5121, 0.2707, 0.7307],\n",
      "        [0.8995, 1.3165, 1.2871, 0.7682, 0.3937, 1.0996]])\n"
     ]
    }
   ],
   "source": [
    "attn_scores = queries @ keys.T\n",
    "print(attn_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d915e2b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1500, 0.2264, 0.2199, 0.1311, 0.0906, 0.1820])\n"
     ]
    }
   ],
   "source": [
    "d_k = keys.shape[-1]\n",
    "attn_weights_2 = torch.softmax(attn_scores_2 / d_k**0.5, dim=-1)\n",
    "print(attn_weights_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "79891586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1551, 0.2104, 0.2059, 0.1413, 0.1074, 0.1799],\n",
      "        [0.1500, 0.2264, 0.2199, 0.1311, 0.0906, 0.1820],\n",
      "        [0.1503, 0.2256, 0.2192, 0.1315, 0.0914, 0.1819],\n",
      "        [0.1591, 0.1994, 0.1962, 0.1477, 0.1206, 0.1769],\n",
      "        [0.1610, 0.1949, 0.1923, 0.1501, 0.1265, 0.1752],\n",
      "        [0.1557, 0.2092, 0.2048, 0.1419, 0.1089, 0.1794]])\n"
     ]
    }
   ],
   "source": [
    "attn_weights = torch.softmax(attn_scores/d_k**0.5, dim=-1)\n",
    "print(attn_weights) # we got our attention matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ae26ed3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2996, 0.8053],\n",
      "        [0.3061, 0.8210],\n",
      "        [0.3058, 0.8203],\n",
      "        [0.2948, 0.7939],\n",
      "        [0.2927, 0.7891],\n",
      "        [0.2990, 0.8040]])\n"
     ]
    }
   ],
   "source": [
    "context_vec = attn_weights @ values\n",
    "print(context_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a8d2b3",
   "metadata": {},
   "source": [
    "# lets make python class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9b70abcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class SelfAttention_v2(nn.Module):\n",
    "\n",
    "    def __init__(self, d_in, d_out, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_key   = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        keys = self.W_key(x)\n",
    "        queries = self.W_query(x)\n",
    "        values = self.W_value(x)\n",
    "        \n",
    "        attn_scores = queries @ keys.T\n",
    "        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
    "\n",
    "        context_vec = attn_weights @ values\n",
    "        return context_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e05cd599",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.5337, -0.1051],\n",
      "        [-0.5323, -0.1080],\n",
      "        [-0.5323, -0.1079],\n",
      "        [-0.5297, -0.1076],\n",
      "        [-0.5311, -0.1066],\n",
      "        [-0.5299, -0.1081]], grad_fn=<MmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "sa_v2 = SelfAttention_v2(d_in, d_out)\n",
    "print(sa_v2(inputs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7281fc82",
   "metadata": {},
   "source": [
    "# Causal Attention/Masked Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "02da9307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1717, 0.1762, 0.1761, 0.1555, 0.1627, 0.1579],\n",
      "        [0.1636, 0.1749, 0.1746, 0.1612, 0.1605, 0.1652],\n",
      "        [0.1637, 0.1749, 0.1746, 0.1611, 0.1606, 0.1651],\n",
      "        [0.1636, 0.1704, 0.1702, 0.1652, 0.1632, 0.1674],\n",
      "        [0.1667, 0.1722, 0.1721, 0.1618, 0.1633, 0.1639],\n",
      "        [0.1624, 0.1709, 0.1706, 0.1654, 0.1625, 0.1682]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "queries = sa_v2.W_query(inputs) #A\n",
    "keys = sa_v2.W_key(inputs)\n",
    "attn_scores = queries @ keys.T\n",
    "attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=1)\n",
    "print(attn_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b44a99bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1717, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1636, 0.1749, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1637, 0.1749, 0.1746, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1636, 0.1704, 0.1702, 0.1652, 0.0000, 0.0000],\n",
      "        [0.1667, 0.1722, 0.1721, 0.1618, 0.1633, 0.0000],\n",
      "        [0.1624, 0.1709, 0.1706, 0.1654, 0.1625, 0.1682]],\n",
      "       grad_fn=<TrilBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# context_length = attn_scores.shape[0]\n",
    "# mask_simple = torch.tril(torch.ones(context_length, context_length))\n",
    "# print(mask_simple)\n",
    "# masked_simple = attn_weights*mask_simple\n",
    "# print(masked_simple)\n",
    "context_length = attn_scores.shape[0]\n",
    "mask_simple = torch.tril(attn_weights)\n",
    "print(mask_simple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0ebe6580",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.4833, 0.5167, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.3190, 0.3408, 0.3402, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2445, 0.2545, 0.2542, 0.2468, 0.0000, 0.0000],\n",
      "        [0.1994, 0.2060, 0.2058, 0.1935, 0.1953, 0.0000],\n",
      "        [0.1624, 0.1709, 0.1706, 0.1654, 0.1625, 0.1682]],\n",
      "       grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "row_sums = mask_simple.sum(dim=1, keepdim=True)\n",
    "mask_simple_norm = mask_simple / row_sums\n",
    "print(mask_simple_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e91dba",
   "metadata": {},
   "source": [
    "But this leads to data leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "59d87e04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3111,   -inf,   -inf,   -inf,   -inf,   -inf],\n",
      "        [0.1655, 0.2602,   -inf,   -inf,   -inf,   -inf],\n",
      "        [0.1667, 0.2602, 0.2577,   -inf,   -inf,   -inf],\n",
      "        [0.0510, 0.1080, 0.1064, 0.0643,   -inf,   -inf],\n",
      "        [0.1415, 0.1875, 0.1863, 0.0987, 0.1121,   -inf],\n",
      "        [0.0476, 0.1192, 0.1171, 0.0731, 0.0477, 0.0966]],\n",
      "       grad_fn=<MaskedFillBackward0>)\n"
     ]
    }
   ],
   "source": [
    "mask = torch.triu(torch.ones(context_length, context_length), diagonal=1)\n",
    "masked = attn_scores.masked_fill(mask.bool(), -torch.inf)\n",
    "print(masked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ba7f9a14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.4833, 0.5167, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.3190, 0.3408, 0.3402, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2445, 0.2545, 0.2542, 0.2468, 0.0000, 0.0000],\n",
      "        [0.1994, 0.2060, 0.2058, 0.1935, 0.1953, 0.0000],\n",
      "        [0.1624, 0.1709, 0.1706, 0.1654, 0.1625, 0.1682]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "attn_weights = torch.softmax(masked / keys.shape[-1]**0.5, dim=1)\n",
    "print(attn_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbbf8ef4",
   "metadata": {},
   "source": [
    "# Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ef9070",
   "metadata": {},
   "source": [
    "In the following code example, we use a dropout rate of 50%, which means masking out half of the attention weights.\n",
    "\n",
    "When we train the GPT model in later chapters, we will use a lower dropout rate, such as 0.1 or 0.2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6d394d6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2., 2., 0., 2., 2., 0.],\n",
      "        [0., 0., 0., 2., 0., 2.],\n",
      "        [2., 2., 2., 2., 0., 2.],\n",
      "        [0., 2., 2., 0., 0., 2.],\n",
      "        [0., 2., 0., 2., 0., 2.],\n",
      "        [0., 2., 2., 2., 2., 0.]])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "dropout = torch.nn.Dropout(0.5) #A\n",
    "example = torch.ones(6, 6) #B\n",
    "print(dropout(example))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3305b4c8",
   "metadata": {},
   "source": [
    "When applying dropout to an attention weight matrix with a rate of 50%, half of the elements in the matrix are randomly set to zero.\n",
    "\n",
    "To compensate for the reduction in active elements, the values of the remaining elements in the matrix are scaled up by a factor of 1/0.5 =2.\n",
    "\n",
    "This scaling is crucial to maintain the overall balance of the attention weights, ensuring that the average influence of the attention mechanism remains consistent during both the training and inference phases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "af97349a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.6380, 0.6816, 0.6804, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.5090, 0.5085, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.4120, 0.0000, 0.3869, 0.0000, 0.0000],\n",
      "        [0.0000, 0.3418, 0.3413, 0.3308, 0.3249, 0.0000]],\n",
      "       grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "print(dropout(attn_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "13e9edec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 6, 3])\n"
     ]
    }
   ],
   "source": [
    "batch = torch.stack((inputs, inputs,inputs), dim=0) # To compute multiple lines at a time\n",
    "print(batch.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "37a4fb73",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CausalAttention(nn.Module):\n",
    "\n",
    "    def __init__(self, d_in, d_out, context_length,\n",
    "                 dropout, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        self.d_out = d_out\n",
    "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_key   = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.dropout = nn.Dropout(dropout) # New\n",
    "        self.register_buffer('mask', torch.triu(torch.ones(context_length, context_length), diagonal=1)) # New\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, num_tokens, d_in = x.shape # New batch dimension b\n",
    "        keys = self.W_key(x)\n",
    "        queries = self.W_query(x)\n",
    "        values = self.W_value(x)\n",
    "\n",
    "        attn_scores = queries @ keys.transpose(1, 2) # Changed transpose\n",
    "        attn_scores.masked_fill_(  # New, _ ops are in-place\n",
    "            self.mask.bool()[:num_tokens, :num_tokens], -torch.inf)  # `:num_tokens` to account for cases where the number of tokens in the batch is smaller than the supported context_size\n",
    "        attn_weights = torch.softmax(\n",
    "            attn_scores / keys.shape[-1]**0.5, dim=-1\n",
    "        )\n",
    "        attn_weights = self.dropout(attn_weights) # New\n",
    "\n",
    "        context_vec = attn_weights @ values\n",
    "        return context_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7293865b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_vecs.shape: torch.Size([3, 6, 2])\n",
      "tensor([[[-0.4519,  0.2216],\n",
      "         [-0.5874,  0.0058],\n",
      "         [-0.6300, -0.0632],\n",
      "         [-0.5675, -0.0843],\n",
      "         [-0.5526, -0.0981],\n",
      "         [-0.5299, -0.1081]],\n",
      "\n",
      "        [[-0.4519,  0.2216],\n",
      "         [-0.5874,  0.0058],\n",
      "         [-0.6300, -0.0632],\n",
      "         [-0.5675, -0.0843],\n",
      "         [-0.5526, -0.0981],\n",
      "         [-0.5299, -0.1081]],\n",
      "\n",
      "        [[-0.4519,  0.2216],\n",
      "         [-0.5874,  0.0058],\n",
      "         [-0.6300, -0.0632],\n",
      "         [-0.5675, -0.0843],\n",
      "         [-0.5526, -0.0981],\n",
      "         [-0.5299, -0.1081]]], grad_fn=<UnsafeViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "context_length = batch.shape[1]\n",
    "ca = CausalAttention(d_in, d_out, context_length, 0.0)\n",
    "context_vecs = ca(batch)\n",
    "print(\"context_vecs.shape:\", context_vecs.shape)\n",
    "print(context_vecs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3102401",
   "metadata": {},
   "source": [
    "# Multihead ATTENTION LAYER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "96f364f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttentionWrapper(nn.Module):\n",
    "\n",
    "    def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList(\n",
    "            [CausalAttention(d_in, d_out, context_length, dropout, qkv_bias) \n",
    "             for _ in range(num_heads)]\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.cat([head(x) for head in self.heads], dim=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "0558faf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.4519,  0.2216,  0.4772,  0.1063],\n",
      "         [-0.5874,  0.0058,  0.5891,  0.3257],\n",
      "         [-0.6300, -0.0632,  0.6202,  0.3860],\n",
      "         [-0.5675, -0.0843,  0.5478,  0.3589],\n",
      "         [-0.5526, -0.0981,  0.5321,  0.3428],\n",
      "         [-0.5299, -0.1081,  0.5077,  0.3493]],\n",
      "\n",
      "        [[-0.4519,  0.2216,  0.4772,  0.1063],\n",
      "         [-0.5874,  0.0058,  0.5891,  0.3257],\n",
      "         [-0.6300, -0.0632,  0.6202,  0.3860],\n",
      "         [-0.5675, -0.0843,  0.5478,  0.3589],\n",
      "         [-0.5526, -0.0981,  0.5321,  0.3428],\n",
      "         [-0.5299, -0.1081,  0.5077,  0.3493]],\n",
      "\n",
      "        [[-0.4519,  0.2216,  0.4772,  0.1063],\n",
      "         [-0.5874,  0.0058,  0.5891,  0.3257],\n",
      "         [-0.6300, -0.0632,  0.6202,  0.3860],\n",
      "         [-0.5675, -0.0843,  0.5478,  0.3589],\n",
      "         [-0.5526, -0.0981,  0.5321,  0.3428],\n",
      "         [-0.5299, -0.1081,  0.5077,  0.3493]]], grad_fn=<CatBackward0>)\n",
      "context_vecs.shape: torch.Size([3, 6, 4])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "context_length = batch.shape[1] # This is the number of tokens\n",
    "d_in, d_out = 3, 2\n",
    "mha = MultiHeadAttentionWrapper(d_in, d_out, context_length, 0.0, num_heads=2)\n",
    "context_vecs = mha(batch)\n",
    "print(context_vecs)\n",
    "print(\"context_vecs.shape:\", context_vecs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d288d1",
   "metadata": {},
   "source": [
    "# Multihead with splits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e74ae6",
   "metadata": {},
   "source": [
    "Step 1: Reduce the projection dim to match desired output dim\n",
    "\n",
    "Step 2: Use a Linear layer to combine head outputs\n",
    "\n",
    "Step 3: Tensor shape: (b, num_tokens, d_out)\n",
    "\n",
    "Step 4: We implicitly split the matrix by adding a num_heads dimension. Then we unroll last dim: (b, num_tokens, d_out) -> (b, num_tokens, num_heads, head_dim)\n",
    "\n",
    "Step 5: Transpose from shape (b, num_tokens, num_heads, head_dim) to (b, num_heads, num_tokens, head_dim)\n",
    "\n",
    "Step 6: Compute dot product for each head\n",
    "\n",
    "Step 7: Mask truncated to the number of tokens\n",
    "\n",
    "Step 8: Use the mask to fill attention scores\n",
    "\n",
    "Step 9: Tensor shape: (b, num_tokens, n_heads, head_dim)\n",
    "\n",
    "Step 10: Combine heads, where self.d_out = self.num_heads * self.head_dim\n",
    "\n",
    "Step 11: Add an optional linear projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "53e23eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        assert (d_out % num_heads == 0), \\\n",
    "            \"d_out must be divisible by num_heads\"\n",
    "\n",
    "        self.d_out = d_out\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = d_out // num_heads # Reduce the projection dim to match desired output dim\n",
    "\n",
    "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.out_proj = nn.Linear(d_out, d_out)  # Linear layer to combine head outputs\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.register_buffer(\n",
    "            \"mask\",\n",
    "            torch.triu(torch.ones(context_length, context_length),\n",
    "                       diagonal=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, num_tokens, d_in = x.shape\n",
    "\n",
    "        keys = self.W_key(x) # Shape: (b, num_tokens, d_out)\n",
    "        queries = self.W_query(x)\n",
    "        values = self.W_value(x)\n",
    "\n",
    "        # We implicitly split the matrix by adding a `num_heads` dimension\n",
    "        # Unroll last dim: (b, num_tokens, d_out) -> (b, num_tokens, num_heads, head_dim)\n",
    "        keys = keys.view(b, num_tokens, self.num_heads, self.head_dim) \n",
    "        values = values.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "        queries = queries.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "\n",
    "        # Transpose: (b, num_tokens, num_heads, head_dim) -> (b, num_heads, num_tokens, head_dim)\n",
    "        keys = keys.transpose(1, 2)\n",
    "        queries = queries.transpose(1, 2)\n",
    "        values = values.transpose(1, 2)\n",
    "\n",
    "        # Compute scaled dot-product attention (aka self-attention) with a causal mask\n",
    "        attn_scores = queries @ keys.transpose(2, 3)  # Dot product for each head\n",
    "\n",
    "        # Original mask truncated to the number of tokens and converted to boolean\n",
    "        mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n",
    "\n",
    "        # Use the mask to fill attention scores\n",
    "        attn_scores.masked_fill_(mask_bool, -torch.inf)\n",
    "        \n",
    "        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
    "        attn_weights = self.dropout(attn_weights)\n",
    "\n",
    "        # Shape: (b, num_tokens, num_heads, head_dim)\n",
    "        context_vec = (attn_weights @ values).transpose(1, 2) \n",
    "        \n",
    "        # Combine heads, where self.d_out = self.num_heads * self.head_dim\n",
    "        context_vec = context_vec.contiguous().view(b, num_tokens, self.d_out)\n",
    "        context_vec = self.out_proj(context_vec) # optional projection\n",
    "\n",
    "        return context_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "70d4d4f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 3, 6])\n",
      "tensor([[[ 0.1569, -0.0873,  0.0210,  0.0215, -0.3243, -0.2518],\n",
      "         [ 0.1117, -0.0547,  0.0406, -0.0213, -0.3251, -0.2993],\n",
      "         [ 0.1196, -0.0491,  0.0318, -0.0635, -0.2788, -0.2578]],\n",
      "\n",
      "        [[ 0.1569, -0.0873,  0.0210,  0.0215, -0.3243, -0.2518],\n",
      "         [ 0.1117, -0.0547,  0.0406, -0.0213, -0.3251, -0.2993],\n",
      "         [ 0.1196, -0.0491,  0.0318, -0.0635, -0.2788, -0.2578]],\n",
      "\n",
      "        [[ 0.1569, -0.0873,  0.0210,  0.0215, -0.3243, -0.2518],\n",
      "         [ 0.1117, -0.0547,  0.0406, -0.0213, -0.3251, -0.2993],\n",
      "         [ 0.1196, -0.0491,  0.0318, -0.0635, -0.2788, -0.2578]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "context_vecs.shape: torch.Size([3, 3, 6])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "# Define the tensor with 3 rows and 6 columns\n",
    "inputs = torch.tensor(\n",
    "    [[0.43, 0.15, 0.89, 0.55, 0.87, 0.66],  # Row 1\n",
    "     [0.57, 0.85, 0.64, 0.22, 0.58, 0.33],  # Row 2\n",
    "     [0.77, 0.25, 0.10, 0.05, 0.80, 0.55]]  # Row 3\n",
    ")\n",
    "\n",
    "batch = torch.stack((inputs, inputs, inputs), dim=0)\n",
    "print(batch.shape) \n",
    "\n",
    "batch_size, context_length, d_in = batch.shape\n",
    "d_out = 6\n",
    "mha = MultiHeadAttention(d_in, d_out, context_length, 0.0, num_heads=2)\n",
    "context_vecs = mha(batch)\n",
    "print(context_vecs)\n",
    "print(\"context_vecs.shape:\", context_vecs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d7a9e9",
   "metadata": {},
   "source": [
    "# IMPLEMENTING A GPT MODEL FROM SCRATCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "806fd1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,    # Vocabulary size\n",
    "    \"context_length\": 1024, # Context length\n",
    "    \"emb_dim\": 768,         # Embedding dimension\n",
    "    \"n_heads\": 12,          # Number of attention heads\n",
    "    \"n_layers\": 12,         # Number of layers\n",
    "    \"drop_rate\": 0.1,       # Dropout rate\n",
    "    \"qkv_bias\": False       # Query-Key-Value bias\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08089958",
   "metadata": {},
   "source": [
    "# GPT Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b6ce5d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class DummyGPTModel(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
    "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
    "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
    "        \n",
    "        # Use a placeholder for TransformerBlock\n",
    "        self.trf_blocks = nn.Sequential(\n",
    "            *[DummyTransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])])\n",
    "        \n",
    "        # Use a placeholder for LayerNorm\n",
    "        self.final_norm = DummyLayerNorm(cfg[\"emb_dim\"])\n",
    "        self.out_head = nn.Linear(\n",
    "            cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False\n",
    "        )\n",
    "\n",
    "    def forward(self, in_idx):\n",
    "        batch_size, seq_len = in_idx.shape\n",
    "        tok_embeds = self.tok_emb(in_idx)\n",
    "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
    "        x = tok_embeds + pos_embeds\n",
    "        x = self.drop_emb(x)\n",
    "        x = self.trf_blocks(x) # this will do nothing yet\n",
    "        x = self.final_norm(x) # this will do nothing yet (this not the inside normalization of tf block normalization this after the data pass through the tf block)\n",
    "        logits = self.out_head(x)\n",
    "        return logits\n",
    "\n",
    "\n",
    "class DummyTransformerBlock(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        # A simple placeholder\n",
    "\n",
    "    def forward(self, x):\n",
    "        # This block does nothing and just returns its input.\n",
    "        return x\n",
    "\n",
    "\n",
    "class DummyLayerNorm(nn.Module):\n",
    "    def __init__(self, normalized_shape, eps=1e-5):\n",
    "        super().__init__()\n",
    "        # The parameters here are just to mimic the LayerNorm interface.\n",
    "\n",
    "    def forward(self, x):\n",
    "        # This layer does nothing and just returns its input.\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f06a18",
   "metadata": {},
   "source": [
    "# tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "15ced38f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[6109, 3626, 6100,  345],\n",
      "        [6109, 1110, 6622,  257]])\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "batch = []\n",
    "txt1 = \"Every effort moves you\"\n",
    "txt2 = \"Every day holds a\"\n",
    "batch.append(torch.tensor(tokenizer.encode(txt1)))\n",
    "batch.append(torch.tensor(tokenizer.encode(txt2)))\n",
    "batch = torch.stack(batch, dim=0)\n",
    "print(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb7339ee",
   "metadata": {},
   "source": [
    "# Lets try to create an instance of dummy model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "79230b59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([2, 4, 50257])\n",
      "tensor([[[-1.2034,  0.3201, -0.7130,  ..., -1.5548, -0.2390, -0.4667],\n",
      "         [-0.1192,  0.4539, -0.4432,  ...,  0.2392,  1.3469,  1.2430],\n",
      "         [ 0.5307,  1.6720, -0.4695,  ...,  1.1966,  0.0111,  0.5835],\n",
      "         [ 0.0139,  1.6754, -0.3388,  ...,  1.1586, -0.0435, -1.0400]],\n",
      "\n",
      "        [[-1.0908,  0.1798, -0.9484,  ..., -1.6047,  0.2439, -0.4530],\n",
      "         [-0.7860,  0.5581, -0.0610,  ...,  0.4835, -0.0077,  1.6621],\n",
      "         [ 0.3567,  1.2698, -0.6398,  ..., -0.0162, -0.1296,  0.3717],\n",
      "         [-0.2407, -0.7349, -0.5102,  ...,  2.0057, -0.3694,  0.1814]]],\n",
      "       grad_fn=<UnsafeViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "model = DummyGPTModel(GPT_CONFIG_124M)\n",
    "logits = model(batch)\n",
    "print(\"Output shape:\", logits.shape)\n",
    "print(logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf43f21",
   "metadata": {},
   "source": [
    "# Layer normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "084b67f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2260, 0.3470, 0.0000, 0.2216, 0.0000, 0.0000],\n",
      "        [0.2133, 0.2394, 0.0000, 0.5198, 0.3297, 0.0000]],\n",
      "       grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "batch_example = torch.randn(2, 5) #A\n",
    "layer = nn.Sequential(nn.Linear(5, 6), nn.ReLU())\n",
    "out = layer(batch_example)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "0c0aa57c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean:\n",
      " tensor([[0.1324],\n",
      "        [0.2170]], grad_fn=<MeanBackward1>)\n",
      "Variance:\n",
      " tensor([[0.0231],\n",
      "        [0.0398]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "source": [
    "mean = out.mean(dim=-1, keepdim=True)\n",
    "var = out.var(dim=-1, keepdim=True)\n",
    "print(\"Mean:\\n\", mean)\n",
    "print(\"Variance:\\n\", var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "46c4b548",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized layer outputs:\n",
      " tensor([[ 0.6159,  1.4126, -0.8719,  0.5872, -0.8719, -0.8719],\n",
      "        [-0.0189,  0.1121, -1.0876,  1.5173,  0.5647, -1.0876]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "Mean:\n",
      " tensor([[-5.9605e-08],\n",
      "        [ 1.9868e-08]], grad_fn=<MeanBackward1>)\n",
      "Variance:\n",
      " tensor([[1.0000],\n",
      "        [1.0000]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "source": [
    "out_norm = (out - mean) / torch.sqrt(var)\n",
    "mean = out_norm.mean(dim=-1, keepdim=True)\n",
    "var = out_norm.var(dim=-1, keepdim=True)\n",
    "print(\"Normalized layer outputs:\\n\", out_norm)\n",
    "print(\"Mean:\\n\", mean)\n",
    "print(\"Variance:\\n\", var)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8125eaef",
   "metadata": {},
   "source": [
    "Note that the value 2.9802e-08 in the output tensor is the scientific notation for 2.9802 × 10-8, which is 0.0000000298 in decimal form. This value is very close to 0, but it is not exactly 0 due to small numerical errors that can accumulate because of the finite precision with which computers represent numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "04245e05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean:\n",
      " tensor([[    -0.0000],\n",
      "        [     0.0000]], grad_fn=<MeanBackward1>)\n",
      "Variance:\n",
      " tensor([[1.0000],\n",
      "        [1.0000]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.set_printoptions(sci_mode=False)\n",
    "print(\"Mean:\\n\", mean)\n",
    "print(\"Variance:\\n\", var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "b89f6998",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, emb_dim):\n",
    "        super().__init__()\n",
    "        self.eps = 1e-5\n",
    "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
    "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(dim=-1, keepdim=True)\n",
    "        var = x.var(dim=-1, keepdim=True, unbiased=False) #Bessel's correction, which typically uses n-1 instead of n in the denominator to adjust for bias in sample variance estimation.\n",
    "#This decision results in a so-called biased estimate of the variance.\n",
    "#For large-scale language models (LLMs), where the embedding dimension n is significantly large, the difference between using n and n-1 is practically negligible.\n",
    "\n",
    "        norm_x = (x - mean) / torch.sqrt(var + self.eps)\n",
    "        return self.scale * norm_x + self.shift"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "840eb47f",
   "metadata": {},
   "source": [
    "# Feed Forward (GELU Activation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "bed57cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GELU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return 0.5 * x * (1 + torch.tanh(\n",
    "            torch.sqrt(torch.tensor(2.0 / torch.pi)) * \n",
    "            (x + 0.044715 * torch.pow(x, 3))\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "9f8503a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "gelu, relu = GELU(), nn.ReLU()\n",
    "\n",
    "# Some sample data\n",
    "x = torch.linspace(-5, 5, 100)\n",
    "y_gelu, y_relu = gelu(x), relu(x)\n",
    "\n",
    "plt.figure(figsize=(8, 3))\n",
    "for i, (y, label) in enumerate(zip([y_gelu, y_relu], [\"GELU\", \"ReLU\"]), 1):\n",
    "    plt.subplot(1, 2, i)\n",
    "    plt.plot(x, y)\n",
    "    plt.title(f\"{label} activation function\")\n",
    "    plt.xlabel(\"x\")\n",
    "    plt.ylabel(f\"{label}(x)\")\n",
    "    plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "dc509677",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(cfg[\"emb_dim\"], 4 * cfg[\"emb_dim\"]), #Expansion\n",
    "            GELU(),\n",
    "            nn.Linear(4 * cfg[\"emb_dim\"], cfg[\"emb_dim\"]), #Contraction\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "4b4f15ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 768])\n"
     ]
    }
   ],
   "source": [
    "ffn = FeedForward(GPT_CONFIG_124M)\n",
    "x = torch.rand(2, 3, 768) #A\n",
    "out = ffn(x)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f6cab3",
   "metadata": {},
   "source": [
    "# Shortcut Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "f9b57260",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExampleDeepNeuralNetwork(nn.Module):\n",
    "    def __init__(self, layer_sizes, use_shortcut):\n",
    "        super().__init__()\n",
    "        self.use_shortcut = use_shortcut\n",
    "        self.layers = nn.ModuleList([\n",
    "            nn.Sequential(nn.Linear(layer_sizes[0], layer_sizes[1]), GELU()),\n",
    "            nn.Sequential(nn.Linear(layer_sizes[1], layer_sizes[2]), GELU()),\n",
    "            nn.Sequential(nn.Linear(layer_sizes[2], layer_sizes[3]), GELU()),\n",
    "            nn.Sequential(nn.Linear(layer_sizes[3], layer_sizes[4]), GELU()),\n",
    "            nn.Sequential(nn.Linear(layer_sizes[4], layer_sizes[5]), GELU())\n",
    "        ])\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            # Compute the output of the current layer\n",
    "            layer_output = layer(x)\n",
    "            # Check if shortcut can be applied\n",
    "            if self.use_shortcut and x.shape == layer_output.shape:\n",
    "                x = x + layer_output\n",
    "            else:\n",
    "                x = layer_output\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057c5e4c",
   "metadata": {},
   "source": [
    "Implepenting Backward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "8448ac70",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_sizes = [3, 3, 3, 3, 3, 1]\n",
    "sample_input = torch.tensor([[1., 0., -1.]])\n",
    "torch.manual_seed(123) # specify random seed for the initial weights for reproducibility\n",
    "model_without_shortcut = ExampleDeepNeuralNetwork(\n",
    "layer_sizes, use_shortcut=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "5fe35220",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_gradients(model, x):\n",
    "    # Forward pass\n",
    "    output = model(x)\n",
    "    target = torch.tensor([[0.]])\n",
    "\n",
    "    # Calculate loss based on how close the target and output are\n",
    "    loss = nn.MSELoss()\n",
    "    loss = loss(output, target)\n",
    "    \n",
    "    # Backward pass to calculate the gradients\n",
    "    loss.backward()\n",
    "\n",
    "    for name, param in model.named_parameters():\n",
    "        if 'weight' in name:\n",
    "            # Print the mean absolute gradient of the weights\n",
    "            print(f\"{name} has gradient mean of {param.grad.abs().mean().item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "b2a4b983",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers.0.0.weight has gradient mean of 0.00020173587836325169\n",
      "layers.1.0.weight has gradient mean of 0.0001201116101583466\n",
      "layers.2.0.weight has gradient mean of 0.0007152041071094573\n",
      "layers.3.0.weight has gradient mean of 0.0013988735154271126\n",
      "layers.4.0.weight has gradient mean of 0.005049645435065031\n"
     ]
    }
   ],
   "source": [
    "print_gradients(model_without_shortcut, sample_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "4b52724e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers.0.0.weight has gradient mean of 0.22169791162014008\n",
      "layers.1.0.weight has gradient mean of 0.20694106817245483\n",
      "layers.2.0.weight has gradient mean of 0.32896995544433594\n",
      "layers.3.0.weight has gradient mean of 0.2665732204914093\n",
      "layers.4.0.weight has gradient mean of 1.3258540630340576\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "model_with_shortcut = ExampleDeepNeuralNetwork(\n",
    "layer_sizes, use_shortcut=True\n",
    ")\n",
    "print_gradients(model_with_shortcut, sample_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d0e835c",
   "metadata": {},
   "source": [
    "It seems it does solves the problem of vanishing Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a267f405",
   "metadata": {},
   "source": [
    "# Lets put'em All together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "df2c0b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,    # Vocabulary size\n",
    "    \"context_length\": 1024, # Context length\n",
    "    \"emb_dim\": 768,         # Embedding dimension\n",
    "    \"n_heads\": 12,          # Number of attention heads\n",
    "    \"n_layers\": 12,         # Number of layers\n",
    "    \"drop_rate\": 0.1,       # Dropout rate\n",
    "    \"qkv_bias\": False       # Query-Key-Value bias\n",
    "}\n",
    "#tokenizer\n",
    "import tiktoken\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "# #Mutihead-Attention\n",
    "# class MultiHeadAttention(nn.Module):\n",
    "#     def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n",
    "#         super().__init__()\n",
    "#         assert (d_out % num_heads == 0), \\\n",
    "#             \"d_out must be divisible by num_heads\"\n",
    "\n",
    "#         self.d_out = d_out\n",
    "#         self.num_heads = num_heads\n",
    "#         self.head_dim = d_out // num_heads # Reduce the projection dim to match desired output dim\n",
    "\n",
    "#         self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "#         self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "#         self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "#         self.out_proj = nn.Linear(d_out, d_out)  # Linear layer to combine head outputs\n",
    "#         self.dropout = nn.Dropout(dropout)\n",
    "#         self.register_buffer(\n",
    "#             \"mask\",\n",
    "#             torch.triu(torch.ones(context_length, context_length),\n",
    "#                        diagonal=1)\n",
    "#         )\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         b, num_tokens, d_in = x.shape\n",
    "\n",
    "#         keys = self.W_key(x) # Shape: (b, num_tokens, d_out)\n",
    "#         queries = self.W_query(x)\n",
    "#         values = self.W_value(x)\n",
    "\n",
    "#         # We implicitly split the matrix by adding a `num_heads` dimension\n",
    "#         # Unroll last dim: (b, num_tokens, d_out) -> (b, num_tokens, num_heads, head_dim)\n",
    "#         keys = keys.view(b, num_tokens, self.num_heads, self.head_dim) \n",
    "#         values = values.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "#         queries = queries.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "\n",
    "#         # Transpose: (b, num_tokens, num_heads, head_dim) -> (b, num_heads, num_tokens, head_dim)\n",
    "#         keys = keys.transpose(1, 2)\n",
    "#         queries = queries.transpose(1, 2)\n",
    "#         values = values.transpose(1, 2)\n",
    "\n",
    "#         # Compute scaled dot-product attention (aka self-attention) with a causal mask\n",
    "#         attn_scores = queries @ keys.transpose(2, 3)  # Dot product for each head\n",
    "\n",
    "#         # Original mask truncated to the number of tokens and converted to boolean\n",
    "#         mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n",
    "\n",
    "#         # Use the mask to fill attention scores\n",
    "#         attn_scores.masked_fill_(mask_bool, -torch.inf)\n",
    "        \n",
    "#         attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
    "#         attn_weights = self.dropout(attn_weights)\n",
    "\n",
    "#         # Shape: (b, num_tokens, num_heads, head_dim)\n",
    "#         context_vec = (attn_weights @ values).transpose(1, 2) \n",
    "        \n",
    "#         # Combine heads, where self.d_out = self.num_heads * self.head_dim\n",
    "#         context_vec = context_vec.contiguous().view(b, num_tokens, self.d_out)\n",
    "#         context_vec = self.out_proj(context_vec) # optional projection\n",
    "\n",
    "#         return context_vec\n",
    "    \n",
    "# #Layer_Norm\n",
    "# class LayerNorm(nn.Module):\n",
    "#     def __init__(self, emb_dim):\n",
    "#         super().__init__()\n",
    "#         self.eps = 1e-5\n",
    "#         self.scale = nn.Parameter(torch.ones(emb_dim))\n",
    "#         self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         mean = x.mean(dim=-1, keepdim=True)\n",
    "#         var = x.var(dim=-1, keepdim=True, unbiased=False) \n",
    "#         norm_x = (x - mean) / torch.sqrt(var + self.eps)\n",
    "#         return self.scale * norm_x + self.shift\n",
    "    \n",
    "# #GELU_Activation\n",
    "# class GELU(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super().__init__()\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         return 0.5 * x * (1 + torch.tanh(\n",
    "#             torch.sqrt(torch.tensor(2.0 / torch.pi)) * \n",
    "#             (x + 0.044715 * torch.pow(x, 3))\n",
    "#         ))\n",
    "\n",
    "# #FeedForward Function\n",
    "# class FeedForward(nn.Module):\n",
    "#     def __init__(self, cfg):\n",
    "#         super().__init__()\n",
    "#         self.layers = nn.Sequential(\n",
    "#             nn.Linear(cfg[\"emb_dim\"], 4 * cfg[\"emb_dim\"]), #Expansion\n",
    "#             GELU(),                                        #Activation_Function\n",
    "#             nn.Linear(4 * cfg[\"emb_dim\"], cfg[\"emb_dim\"]), #Contraction\n",
    "#         )\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         return self.layers(x)\n",
    "    \n",
    "#Transformerblock  \n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.att = MultiHeadAttention(\n",
    "            d_in=cfg[\"emb_dim\"],\n",
    "            d_out=cfg[\"emb_dim\"],\n",
    "            context_length=cfg[\"context_length\"],\n",
    "            num_heads=cfg[\"n_heads\"], \n",
    "            dropout=cfg[\"drop_rate\"],\n",
    "            qkv_bias=cfg[\"qkv_bias\"])\n",
    "        self.ff = FeedForward(cfg)\n",
    "        self.norm1 = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.norm2 = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.drop_shortcut = nn.Dropout(cfg[\"drop_rate\"])\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Shortcut connection for attention block\n",
    "        shortcut = x\n",
    "        x = self.norm1(x)\n",
    "        x = self.att(x)  # Shape [batch_size, num_tokens, emb_size]\n",
    "        x = self.drop_shortcut(x)\n",
    "        x = x + shortcut  # Add the original input back\n",
    "\n",
    "        # Shortcut connection for feed forward block\n",
    "        shortcut = x\n",
    "        x = self.norm2(x)\n",
    "        x = self.ff(x)\n",
    "        x = self.drop_shortcut(x)\n",
    "        x = x + shortcut  # Add the original input back\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "2050fcf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([2, 6, 768])\n",
      "Output shape: torch.Size([2, 6, 768])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "x = torch.rand(2, 6, 768) #A\n",
    "block = TransformerBlock(GPT_CONFIG_124M)\n",
    "output = block(x)\n",
    "print(\"Input shape:\", x.shape)\n",
    "print(\"Output shape:\", output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4425945",
   "metadata": {},
   "source": [
    "# Alright Avengers Assemble Sorry... LLM Assemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "edcc7481",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[6109, 3626, 6100,  345],\n",
      "        [6109, 1110, 6622,  257]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "#tokenizer\n",
    "import tiktoken\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "batch = []\n",
    "txt1 = \"Every effort moves you\"\n",
    "txt2 = \"Every day holds a\"\n",
    "batch.append(torch.tensor(tokenizer.encode(txt1)))\n",
    "batch.append(torch.tensor(tokenizer.encode(txt2)))\n",
    "batch = torch.stack(batch, dim=0)\n",
    "print(batch)\n",
    "\n",
    "class GPTModel(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
    "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
    "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
    "        \n",
    "        # Use TransformerBlock\n",
    "        self.trf_blocks = nn.Sequential(\n",
    "            *[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])])\n",
    "        \n",
    "        #Use Layer_Normalization\n",
    "        self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.out_head = nn.Linear(\n",
    "            cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False\n",
    "        )\n",
    "\n",
    "    def forward(self, in_idx):\n",
    "        batch_size, seq_len = in_idx.shape\n",
    "        tok_embeds = self.tok_emb(in_idx)\n",
    "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
    "        x = tok_embeds + pos_embeds\n",
    "        x = self.drop_emb(x)\n",
    "        x = self.trf_blocks(x) # this will do nothing yet\n",
    "        x = self.final_norm(x) # this will do nothing yet (this not the inside normalization of tf block normalization this after the data pass through the tf block)\n",
    "        logits = self.out_head(x)\n",
    "        return logits\n",
    "\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.att = MultiHeadAttention(\n",
    "            d_in=cfg[\"emb_dim\"],\n",
    "            d_out=cfg[\"emb_dim\"],\n",
    "            context_length=cfg[\"context_length\"],\n",
    "            num_heads=cfg[\"n_heads\"], \n",
    "            dropout=cfg[\"drop_rate\"],\n",
    "            qkv_bias=cfg[\"qkv_bias\"])\n",
    "        self.ff = FeedForward(cfg)\n",
    "        self.norm1 = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.norm2 = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.drop_shortcut = nn.Dropout(cfg[\"drop_rate\"])\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Shortcut connection for attention block\n",
    "        shortcut = x\n",
    "        x = self.norm1(x)\n",
    "        x = self.att(x)  # Shape [batch_size, num_tokens, emb_size]\n",
    "        x = self.drop_shortcut(x)\n",
    "        x = x + shortcut  # Add the original input back\n",
    "\n",
    "        # Shortcut connection for feed forward block\n",
    "        shortcut = x\n",
    "        x = self.norm2(x)\n",
    "        x = self.ff(x)\n",
    "        x = self.drop_shortcut(x)\n",
    "        x = x + shortcut  # Add the original input back\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, emb_dim):\n",
    "        super().__init__()\n",
    "        self.eps = 1e-5\n",
    "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
    "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(dim=-1, keepdim=True)\n",
    "        var = x.var(dim=-1, keepdim=True, unbiased=False) \n",
    "        norm_x = (x - mean) / torch.sqrt(var + self.eps)\n",
    "        return self.scale * norm_x + self.shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "92492aec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input batch:\n",
      " tensor([[6109, 3626, 6100,  345],\n",
      "        [6109, 1110, 6622,  257]])\n",
      "Input batch:\n",
      " torch.Size([2, 4])\n",
      "\n",
      "Output shape: torch.Size([2, 4, 50257])\n",
      "tensor([[[ 0.3613,  0.4223, -0.0711,  ...,  0.3483,  0.4661, -0.2838],\n",
      "         [-0.1792, -0.5660, -0.9485,  ...,  0.0477,  0.5181, -0.3168],\n",
      "         [ 0.7120,  0.0332,  0.1085,  ...,  0.1018, -0.4327, -0.2553],\n",
      "         [-1.0076,  0.3418, -0.1190,  ...,  0.7195,  0.4023,  0.0532]],\n",
      "\n",
      "        [[-0.2564,  0.0900,  0.0335,  ...,  0.2659,  0.4454, -0.6806],\n",
      "         [ 0.1230,  0.3653, -0.2074,  ...,  0.7705,  0.2710,  0.2246],\n",
      "         [ 1.0558,  1.0318, -0.2800,  ...,  0.6936,  0.3205, -0.3178],\n",
      "         [-0.1565,  0.3926,  0.3288,  ...,  1.2630, -0.1858,  0.0388]]],\n",
      "       grad_fn=<UnsafeViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "out = model(batch)\n",
    "print(\"Input batch:\\n\", batch)\n",
    "print(\"Input batch:\\n\", batch.shape)\n",
    "print(\"\\nOutput shape:\", out.shape)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "cdb9139f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 163,009,536\n"
     ]
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Total number of parameters: {total_params:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03dfdfe8",
   "metadata": {},
   "source": [
    "As we know GPT-2 is a 124 million parameter GPT model, so why is the actual number of parameters 163 million, as shown in the preceding code output?\n",
    "The reason is a concept called weight tying that is used in the original GPT-2 architecture, which means that the original GPT-2 architecture is reusing the weights from the token embedding layer in its output layer.\n",
    "\n",
    "To understand what this means, let's take a look at the shapes of the token embedding layer and linear output layer that we initialized on the model via the GPTModel earlier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "f896baa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token embedding layer shape: torch.Size([50257, 768])\n",
      "Output layer shape: torch.Size([50257, 768])\n"
     ]
    }
   ],
   "source": [
    "print(\"Token embedding layer shape:\", model.tok_emb.weight.shape)\n",
    "print(\"Output layer shape:\", model.out_head.weight.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "3a150a98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of trainable parameters considering weight tying: 124,412,160\n",
      "Total size of the model: 621.83 MB\n"
     ]
    }
   ],
   "source": [
    "total_params_gpt2 = total_params - sum(p.numel() for p in model.out_head.parameters())\n",
    "print(f\"Number of trainable parameters considering weight tying: {total_params_gpt2:,}\")\n",
    "\n",
    "total_size_bytes = total_params * 4 #A\n",
    "total_size_mb = total_size_bytes / (1024 * 1024) #B\n",
    "print(f\"Total size of the model: {total_size_mb:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "861e6a19",
   "metadata": {},
   "source": [
    "# Lets generate text from output logit tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "7e79c72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text_simple(model, idx, max_new_tokens, context_size):\n",
    "    # idx is (batch, n_tokens) array of indices in the current context\n",
    "    for _ in range(max_new_tokens):\n",
    "        \n",
    "        # Crop current context if it exceeds the supported context size\n",
    "        # E.g., if LLM supports only 5 tokens, and the context size is 10\n",
    "        # then only the last 5 tokens are used as context\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "        \n",
    "        # Get the predictions\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond) # (batch, n_tokens, vocab_size)\n",
    "        \n",
    "        # Focus only on the last time step\n",
    "        # (batch, n_tokens, vocab_size) becomes (batch, vocab_size)\n",
    "        logits = logits[:, -1, :]  \n",
    "\n",
    "        # Apply softmax to get proababilities\n",
    "        probas = torch.softmax(logits, dim=-1)  # (batch, vocab_size)\n",
    "\n",
    "        # Get the idx of the vocab entry with the highest probability value\n",
    "        idx_next = torch.argmax(probas, dim=-1, keepdim=True)  # (batch, 1)\n",
    "\n",
    "        # Append sampled index to the running sequence\n",
    "        idx = torch.cat((idx, idx_next), dim=1)  # (batch, n_tokens+1)\n",
    "\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "91fdef05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoded: [15496, 11, 314, 716]\n",
      "encoded_tensor.shape: torch.Size([1, 4])\n"
     ]
    }
   ],
   "source": [
    "start_context = \"Hello, I am\"\n",
    "encoded = tokenizer.encode(start_context)\n",
    "print(\"encoded:\", encoded)\n",
    "encoded_tensor = torch.tensor(encoded).unsqueeze(0) #A\n",
    "print(\"encoded_tensor.shape:\", encoded_tensor.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2cb157a",
   "metadata": {},
   "source": [
    "Next, we put the model into .eval() mode, which disables random components like dropout, which are only used during training, and use the generate_text_simple function on the encoded input tensor:\n",
    "We disable dropout since we are not training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "5a27871c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: tensor([[15496,    11,   314,   716, 27018, 24086, 47843, 30961, 42348,  7267]])\n",
      "Output length: 10\n"
     ]
    }
   ],
   "source": [
    "model.eval() #A\n",
    "out = generate_text_simple(\n",
    "model=model,\n",
    "idx=encoded_tensor,\n",
    "max_new_tokens=6,\n",
    "context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "print(\"Output:\", out)\n",
    "print(\"Output length:\", len(out[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "a62aeed5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, I am Featureiman Byeswickattribute argue\n"
     ]
    }
   ],
   "source": [
    "decoded_text = tokenizer.decode(out.squeeze(0).tolist())\n",
    "print(decoded_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ed3985",
   "metadata": {},
   "source": [
    "# Using GPT to generate text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "45a2f309",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,   # Vocabulary size\n",
    "    \"context_length\": 256, # Shortened context length (orig: 1024)\n",
    "    \"emb_dim\": 768,        # Embedding dimension\n",
    "    \"n_heads\": 12,         # Number of attention heads\n",
    "    \"n_layers\": 12,        # Number of layers\n",
    "    \"drop_rate\": 0.1,      # Dropout rate\n",
    "    \"qkv_bias\": False      # Query-key-value bias\n",
    "}\n",
    "\n",
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.eval();  # Disable dropout during inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "fcbc1c40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you rentingetic wasnم refres RexMeCHicular stren\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "def text_to_token_ids(text, tokenizer):\n",
    "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0) # add batch dimension\n",
    "    return encoded_tensor\n",
    "\n",
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "    flat = token_ids.squeeze(0) # remove batch dimension\n",
    "    return tokenizer.decode(flat.tolist())\n",
    "\n",
    "start_context = \"Every effort moves you\"\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(start_context, tokenizer),\n",
    "    max_new_tokens=10,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9367224f",
   "metadata": {},
   "source": [
    "As we can see above, the model does not produce good text because it has not been trained yet\n",
    "\n",
    "How do we measure or capture what \"good text\" is, in a numeric form, to track it during training?\n",
    "\n",
    "The next subsection introduces metrics to calculate a loss metric for the generated outputs that we can use to measure the training progress\n",
    "\n",
    "The next chapters on finetuning LLMs will also introduce additional ways to measure model quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "94e4a8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.tensor([[16833, 3626, 6100],   # [\"every effort moves\",\n",
    "                       [40,    1107, 588]])   #  \"I really like\"]\n",
    "\n",
    "targets = torch.tensor([[3626, 6100, 345  ],  # [\" effort moves you\",\n",
    "                        [1107,  588, 11311]]) #  \" really like chocolate\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "63e9689a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 50257])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    logits = model(inputs)\n",
    "\n",
    "probas = torch.softmax(logits, dim=-1) # Probability of each token in vocabulary\n",
    "print(probas.shape) # Shape: (batch_size, num_tokens, vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "8c237bec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token IDs:\n",
      " tensor([[[16657],\n",
      "         [  339],\n",
      "         [42826]],\n",
      "\n",
      "        [[49906],\n",
      "         [29669],\n",
      "         [41751]]])\n"
     ]
    }
   ],
   "source": [
    "token_ids = torch.argmax(probas, dim=-1, keepdim=True)\n",
    "print(\"Token IDs:\\n\", token_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "e8e8ee46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Targets batch 1:  effort moves you\n",
      "Outputs batch 1:  Armed heNetflix\n"
     ]
    }
   ],
   "source": [
    "print(f\"Targets batch 1: {token_ids_to_text(targets[0], tokenizer)}\")\n",
    "print(f\"Outputs batch 1: {token_ids_to_text(token_ids[0].flatten(), tokenizer)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65110b14",
   "metadata": {},
   "source": [
    "# Cross entropy loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "f4288744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text 1: tensor([    0.0001,     0.0000,     0.0000])\n",
      "Text 2: tensor([    0.0000,     0.0001,     0.0000])\n"
     ]
    }
   ],
   "source": [
    "text_idx = 0\n",
    "target_probas_1 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
    "print(\"Text 1:\", target_probas_1)\n",
    "\n",
    "text_idx = 1\n",
    "target_probas_2 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
    "print(\"Text 2:\", target_probas_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "1f55b834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ -9.5042, -10.3796, -11.3677, -11.4798,  -9.7764, -12.2561])\n"
     ]
    }
   ],
   "source": [
    "# Compute logarithm of all token probabilities\n",
    "log_probas = torch.log(torch.cat((target_probas_1, target_probas_2)))\n",
    "print(log_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "c43fc271",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-10.7940)\n"
     ]
    }
   ],
   "source": [
    "# Calculate the average probability for each token\n",
    "avg_log_probas = torch.mean(log_probas)\n",
    "print(avg_log_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "d0a33740",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.7940)\n"
     ]
    }
   ],
   "source": [
    "neg_avg_log_probas = avg_log_probas * -1\n",
    "print(neg_avg_log_probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a3cb90",
   "metadata": {},
   "source": [
    "# PyTorch already implements a cross_entropy function that carries out the previous steps\n",
    "\n",
    "Before we apply the cross_entropy function, let's check the shape of the logits and targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "0a64a80d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits shape: torch.Size([2, 3, 50257])\n",
      "Targets shape: torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "# Logits have shape (batch_size, num_tokens, vocab_size)\n",
    "print(\"Logits shape:\", logits.shape)\n",
    "\n",
    "# Targets have shape (batch_size, num_tokens)\n",
    "print(\"Targets shape:\", targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "e39df00e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flattened logits: torch.Size([6, 50257])\n",
      "Flattened targets: torch.Size([6])\n"
     ]
    }
   ],
   "source": [
    "logits_flat = logits.flatten(0, 1)\n",
    "targets_flat = targets.flatten()\n",
    "\n",
    "print(\"Flattened logits:\", logits_flat.shape)\n",
    "print(\"Flattened targets:\", targets_flat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "1844a1d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.7940)\n"
     ]
    }
   ],
   "source": [
    "loss = torch.nn.functional.cross_entropy(logits_flat, targets_flat)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8cdcd97",
   "metadata": {},
   "source": [
    "# Perplexity\n",
    "A concept related to the cross-entropy loss is the perplexity of an LLM.\n",
    "\n",
    "The perplexity is simply the exponential of the cross-entropy loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "567c1929",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(48725.8203)\n"
     ]
    }
   ],
   "source": [
    "perplexity = torch.exp(loss)\n",
    "print(perplexity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa2fb60",
   "metadata": {},
   "source": [
    "We use a relatively small dataset for training the LLM (in fact, only one short story)\n",
    "\n",
    "The reasons are:\n",
    "\n",
    "You can run the code examples in a few minutes on a laptop computer without a suitable GPU.\n",
    "\n",
    "The training finishes relatively fast (minutes instead of weeks), which is good for educational purposes.\n",
    "\n",
    "We use a text from the public domain, which can be included in this GitHub repository without violating any usage rights or bloating the repository size.\n",
    "\n",
    "For example, Llama 2 7B required 184,320 GPU hours on A100 GPUs to be trained on 2 trillion tokens\n",
    "\n",
    "At the time of this writing, the hourly cost of an 8xA100 cloud server at AWS is approximately 30 dollars.\n",
    "\n",
    "So, via an off-the-envelope calculation, training this LLM would cost 184,320 / 8 * 30 = 690,000 dollars\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a34d24f",
   "metadata": {},
   "source": [
    "# Calculating the training and validation set losses on verdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "2ad73270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of characters 20479\n",
      "I HAD always thought Jack Gisburn rather a cheap genius--though a good fellow enough--so it was no \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "\n",
    "file_path = \"the-verdict.txt\"\n",
    "url = \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch02/01_main-chapter-code/the-verdict.txt\"\n",
    "\n",
    "if not os.path.exists(file_path):\n",
    "    with urllib.request.urlopen(url) as response:\n",
    "        text_data = response.read().decode('utf-8')\n",
    "    with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(text_data)\n",
    "else:\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        text_data = file.read()\n",
    "\n",
    "# with open(\"the-verdict.txt\",\"r\", encoding = \"utf-8\") as f:\n",
    "#     text_data=f.read()\n",
    "    \n",
    "print(\"Number of characters\", len(text_data))\n",
    "print(text_data[:99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "e30aee53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Characters: 20479\n",
      "Tokens: 5145\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "total_characters = len(text_data)\n",
    "total_tokens = len(tokenizer.encode(text_data))\n",
    "\n",
    "print(\"Characters:\", total_characters)\n",
    "print(\"Tokens:\", total_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "5640dc14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "class GPTDatasetV1(Dataset):\n",
    "    def __init__(self, txt, tokenizer, max_length, stride):\n",
    "        self.input_ids = []\n",
    "        self.target_ids = []\n",
    "\n",
    "        # Tokenize the entire text\n",
    "        token_ids = tokenizer.encode(txt, allowed_special={\"<|endoftext|>\"})\n",
    "\n",
    "        # Use a sliding window to chunk the book into overlapping sequences of max_length\n",
    "        for i in range(0, len(token_ids) - max_length, stride):\n",
    "            input_chunk = token_ids[i:i + max_length]\n",
    "            target_chunk = token_ids[i + 1: i + max_length + 1]\n",
    "            self.input_ids.append(torch.tensor(input_chunk))\n",
    "            self.target_ids.append(torch.tensor(target_chunk))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_ids[idx], self.target_ids[idx]\n",
    "\n",
    "\n",
    "def create_dataloader_v1(txt, batch_size=4, max_length=256, \n",
    "                         stride=128, shuffle=True, drop_last=True,\n",
    "                         num_workers=0):\n",
    "\n",
    "    # Initialize the tokenizer\n",
    "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "    # Create dataset\n",
    "    dataset = GPTDatasetV1(txt, tokenizer, max_length, stride)\n",
    "\n",
    "    # Create dataloader\n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        drop_last=drop_last,\n",
    "        num_workers=num_workers\n",
    "    )\n",
    "\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "ec164d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,   # Vocabulary size\n",
    "    \"context_length\": 256, # Shortened context length (orig: 1024)\n",
    "    \"emb_dim\": 768,        # Embedding dimension\n",
    "    \"n_heads\": 12,         # Number of attention heads\n",
    "    \"n_layers\": 12,        # Number of layers\n",
    "    \"drop_rate\": 0.1,      # Dropout rate\n",
    "    \"qkv_bias\": False      # Query-key-value bias\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "0e6a8dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/validation ratio\n",
    "train_ratio = 0.90\n",
    "split_idx = int(train_ratio * len(text_data))\n",
    "train_data = text_data[:split_idx]\n",
    "val_data = text_data[split_idx:]\n",
    "\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader = create_dataloader_v1(\n",
    "    train_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=True,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "val_loader = create_dataloader_v1(\n",
    "    val_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=False,\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e94cab",
   "metadata": {},
   "source": [
    "# Sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "de562a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "if total_tokens * (train_ratio) < GPT_CONFIG_124M[\"context_length\"]:\n",
    "    print(\"Not enough tokens for the training loader. \"\n",
    "          \"Try to lower the `GPT_CONFIG_124M['context_length']` or \"\n",
    "          \"increase the `training_ratio`\")\n",
    "\n",
    "if total_tokens * (1-train_ratio) < GPT_CONFIG_124M[\"context_length\"]:\n",
    "    print(\"Not enough tokens for the validation loader. \"\n",
    "          \"Try to lower the `GPT_CONFIG_124M['context_length']` or \"\n",
    "          \"decrease the `training_ratio`\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "641e0890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "\n",
      "Validation loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "9\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(\"Train loader:\")\n",
    "for x, y in train_loader:\n",
    "    print(x.shape, y.shape)\n",
    "\n",
    "print(\"\\nValidation loader:\")\n",
    "for x, y in val_loader:\n",
    "    print(x.shape, y.shape)\n",
    "\n",
    "print(len(train_loader))\n",
    "print(len(val_loader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "8da159e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training tokens: 4608\n",
      "Validation tokens: 512\n",
      "All tokens: 5120\n"
     ]
    }
   ],
   "source": [
    "train_tokens = 0\n",
    "for input_batch, target_batch in train_loader:\n",
    "    train_tokens += input_batch.numel()\n",
    "\n",
    "val_tokens = 0\n",
    "for input_batch, target_batch in val_loader:\n",
    "    val_tokens += input_batch.numel()\n",
    "\n",
    "print(\"Training tokens:\", train_tokens)\n",
    "print(\"Validation tokens:\", val_tokens)\n",
    "print(\"All tokens:\", train_tokens + val_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df158f0",
   "metadata": {},
   "source": [
    "# Here is the GPT Model class we coded earlier. We will need this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "5235805a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTModel(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
    "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
    "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
    "        \n",
    "        self.trf_blocks = nn.Sequential(\n",
    "            *[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])])\n",
    "        \n",
    "        self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.out_head = nn.Linear(\n",
    "            cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False\n",
    "        )\n",
    "\n",
    "    def forward(self, in_idx):\n",
    "        batch_size, seq_len = in_idx.shape\n",
    "        tok_embeds = self.tok_emb(in_idx)\n",
    "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
    "        x = tok_embeds + pos_embeds  # Shape [batch_size, num_tokens, emb_size]\n",
    "        x = self.drop_emb(x)\n",
    "        x = self.trf_blocks(x)\n",
    "        x = self.final_norm(x)\n",
    "        logits = self.out_head(x)\n",
    "        return logits\n",
    "\n",
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.eval();  # Disable dropout during inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "ef1be40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "    logits = model(input_batch)\n",
    "    loss = torch.nn.functional.cross_entropy(logits.flatten(0, 1), target_batch.flatten())\n",
    "    return loss\n",
    "\n",
    "\n",
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0.\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        # Reduce the number of batches to match the total number of batches in the data loader\n",
    "        # if num_batches exceeds the number of batches in the data loader\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "    return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4724470a",
   "metadata": {},
   "source": [
    "If you have a machine with a CUDA-supported GPU, the LLM will train on the GPU without making any changes to the code.\n",
    "\n",
    "Via the device setting, we ensure that the data is loaded onto the same device as the LLM model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "2ca292c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 10.98758347829183\n",
      "Validation loss: 10.98110580444336\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Note:\n",
    "# Uncommenting the following lines will allow the code to run on Apple Silicon chips, if applicable,\n",
    "# which is approximately 2x faster than on an Apple CPU (as measured on an M3 MacBook Air).\n",
    "# However, the resulting loss values may be slightly different.\n",
    "\n",
    "#if torch.cuda.is_available():\n",
    "#    device = torch.device(\"cuda\")\n",
    "#elif torch.backends.mps.is_available():\n",
    "#    device = torch.device(\"mps\")\n",
    "#else:\n",
    "#    device = torch.device(\"cpu\")\n",
    "#\n",
    "# print(f\"Using {device} device.\")\n",
    "\n",
    "\n",
    "model.to(device) # no assignment model = model.to(device) necessary for nn.Module classes\n",
    "\n",
    "\n",
    "torch.manual_seed(123) # For reproducibility due to the shuffling in the data loader\n",
    "\n",
    "with torch.no_grad(): # Disable gradient tracking for efficiency because we are not training, yet\n",
    "    train_loss = calc_loss_loader(train_loader, model, device)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device)\n",
    "\n",
    "print(\"Training loss:\", train_loss)\n",
    "print(\"Validation loss:\", val_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b3a8b64",
   "metadata": {},
   "source": [
    "# Pre training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "bf736fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_simple(model, train_loader, val_loader, optimizer, device, num_epochs,\n",
    "                       eval_freq, eval_iter, start_context, tokenizer):\n",
    "    # Initialize lists to track losses and tokens seen\n",
    "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
    "    tokens_seen, global_step = 0, -1\n",
    "\n",
    "    # Main training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # Set model to training mode\n",
    "        \n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad() # Reset loss gradients from previous batch iteration\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            loss.backward() # Calculate loss gradients\n",
    "            optimizer.step() # Update model weights using loss gradients\n",
    "            tokens_seen += input_batch.numel() # Returns the total number of elements (or tokens) in the input_batch.\n",
    "            global_step += 1\n",
    "\n",
    "            # Optional evaluation step\n",
    "            if global_step % eval_freq == 0: \n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                    model, train_loader, val_loader, device, eval_iter)\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                track_tokens_seen.append(tokens_seen)\n",
    "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
    "                      f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
    "\n",
    "        # Print a sample text after each epoch\n",
    "        generate_and_print_sample(\n",
    "            model, tokenizer, device, start_context\n",
    "        )\n",
    "\n",
    "    return train_losses, val_losses, track_tokens_seen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9354e33",
   "metadata": {},
   "source": [
    "Step 1: Initialize lists to track losses and tokens seen\n",
    "\n",
    "Step 2: Start the main training loop\n",
    "\n",
    "Step 3: Reset loss gradients from previous batch iteration\n",
    "\n",
    "Step 4: Calculate loss gradients\n",
    "\n",
    "Step 5: Update model weights using loss gradients\n",
    "\n",
    "Step 6: Optional evaluation step\n",
    "\n",
    "Step 7: Print a sample text after each epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "4507bf86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "    model.train()\n",
    "    return train_loss, val_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73aaf60b",
   "metadata": {},
   "source": [
    "The evaluate_model function calculates the loss over the training and validation set while ensuring the model is in evaluation mode with gradient tracking and dropout disabled when calculating the loss over the training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "9dd23888",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
    "    model.eval()\n",
    "    context_size = model.pos_emb.weight.shape[0]\n",
    "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
    "    with torch.no_grad():\n",
    "        token_ids = generate_text_simple(\n",
    "            model=model, idx=encoded,\n",
    "            max_new_tokens=50, context_size=context_size\n",
    "        )\n",
    "    decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    print(decoded_text.replace(\"\\n\", \" \"))  # Compact print format\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b44ed2cd",
   "metadata": {},
   "source": [
    "The generate_and_print_sample function is a convenience function that we use to track whether the model improves during the training.\n",
    "\n",
    "In particular, the generate_and_print_sample function takes a text snippet (start_context) as input, converts it into token IDs, and feeds it to the LLM to generate a text sample using the generate_text_simple function we used earlier\n",
    "\n",
    "Let's see this all in action by training a GPTModel instance for 10 epochs using an AdamW optimizer and the train_model_simple function we defined earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "74d95b54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 9.781, Val loss 9.933\n",
      "Ep 1 (Step 000005): Train loss 8.111, Val loss 8.339\n",
      "Every effort moves you,,,,,,,,,,,,.                                     \n",
      "Ep 2 (Step 000010): Train loss 6.661, Val loss 7.048\n",
      "Ep 2 (Step 000015): Train loss 5.961, Val loss 6.616\n",
      "Every effort moves you, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and,, and, and,\n",
      "Ep 3 (Step 000020): Train loss 5.726, Val loss 6.600\n",
      "Ep 3 (Step 000025): Train loss 5.201, Val loss 6.348\n",
      "Every effort moves you, and I had been.                                            \n",
      "Ep 4 (Step 000030): Train loss 4.417, Val loss 6.278\n",
      "Ep 4 (Step 000035): Train loss 4.069, Val loss 6.226\n",
      "Every effort moves you know the                          \"I he had the donkey and I had the and I had the donkey and down the room, I had\n",
      "Ep 5 (Step 000040): Train loss 3.732, Val loss 6.160\n",
      "Every effort moves you know it was not that the picture--I had the fact by the last I had been--his, and in the            \"Oh, and he said, and down the room, and in\n",
      "Ep 6 (Step 000045): Train loss 2.850, Val loss 6.179\n",
      "Ep 6 (Step 000050): Train loss 2.427, Val loss 6.141\n",
      "Every effort moves you know,\" was one of the picture. The--I had a little of a little: \"Yes, and in fact, and in the picture was, and I had been at my elbow and as his pictures, and down the room, I had\n",
      "Ep 7 (Step 000055): Train loss 2.104, Val loss 6.134\n",
      "Ep 7 (Step 000060): Train loss 1.882, Val loss 6.233\n",
      "Every effort moves you know,\" was one of the picture for nothing--I told Mrs.  \"I was no--as! The women had been, in the moment--as Jack himself, as once one had been the donkey, and were, and in his\n",
      "Ep 8 (Step 000065): Train loss 1.320, Val loss 6.238\n",
      "Ep 8 (Step 000070): Train loss 0.985, Val loss 6.242\n",
      "Every effort moves you know,\" was one of the axioms he had been the tips of a self-confident moustache, I felt to see a smile behind his close grayish beard--as if he had the donkey. \"strongest,\" as his\n",
      "Ep 9 (Step 000075): Train loss 0.717, Val loss 6.293\n",
      "Ep 9 (Step 000080): Train loss 0.541, Val loss 6.393\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back the window-curtains, I had the donkey. \"There were days when I\n",
      "Ep 10 (Step 000085): Train loss 0.391, Val loss 6.452\n",
      "Every effort moves you know,\" was one of the axioms he laid down across the Sevres and silver of an exquisitely appointed luncheon-table, when, on a later day, I had again run over from Monte Carlo; and Mrs. Gis\n",
      "Training completed in 4.76 minutes.\n"
     ]
    }
   ],
   "source": [
    "# the following code to calculate the execution time\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0004, weight_decay=0.1)\n",
    "\n",
    "num_epochs = 10\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
    "    start_context=\"Every effort moves you\", tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "# Note:\n",
    "# Uncomment the following code to show the execution time\n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12cc10b1",
   "metadata": {},
   "source": [
    "As we can see, based on the results printed during the training, the training loss improves drastically, starting with a value of 9.781 and converging to 0.391.\n",
    "\n",
    "The language skills of the model have improved quite a lot. In the beginning, the model is only able to append commas to the start context (\"Every effort moves you,,,,,,,,,,,,\") or repeat the word \"and\".\n",
    "\n",
    "At the end of the training, it can generate grammatically correct text.\n",
    "Similar to the training set loss, we can see that the validation loss starts high (9.856) and decreases during the training.\n",
    "\n",
    "However, it never becomes as small as the training set loss and remains at 6.372 after the 10th epoch.\n",
    "\n",
    "Let's create a simple plot that shows the training and validation set losses side by side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "85d1b7e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "\n",
    "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "\n",
    "    # Plot training and validation loss against epochs\n",
    "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
    "    ax1.plot(epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.legend(loc=\"upper right\")\n",
    "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))  # only show integer labels on x-axis\n",
    "\n",
    "    # Create a second x-axis for tokens seen\n",
    "    ax2 = ax1.twiny()  # Create a second x-axis that shares the same y-axis\n",
    "    ax2.plot(tokens_seen, train_losses, alpha=0)  # Invisible plot for aligning ticks\n",
    "    ax2.set_xlabel(\"Tokens seen\")\n",
    "\n",
    "    fig.tight_layout()  # Adjust layout to make room\n",
    "    plt.savefig(\"loss-plot.pdf\")\n",
    "    plt.show()\n",
    "\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce28afc5",
   "metadata": {},
   "source": [
    "Both the training and validation losses start to improve for the first epoch. However, the losses start to diverge past the second epoch.\n",
    "\n",
    "This divergence and the fact that the validation loss is much larger than the training loss indicate that the model is overfitting to the training data.\n",
    "\n",
    "We can confirm that the model memorizes the training data verbatim by searching for the generated text snippets, such as \"quite insensible to the irony\" in the \"The Verdict\" text file.\n",
    "\n",
    "This memorization is expected since we are working with a very, very small training dataset and training the model for multiple epochs.\n",
    "\n",
    "Usually, it's common to train a model on a much, much larger dataset for only one epoch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b45329e",
   "metadata": {},
   "source": [
    "# DECODING STRATEGIES TO CONTROL RANDOMNESS\n",
    "First, we briefly revisit the generate_text_simple function from the previous chapter that we used inside the generate_and_print_sample earlier in this chapter.\n",
    "\n",
    "Then, we will cover two techniques, temperature scaling, and top-k sampling, to improve this function.\n",
    "\n",
    "We begin by transferring the model back from the GPU to the CPU since inference with a relatively small model does not require a GPU. Also, after training, we put the model into evaluation model to turn off random components such as dropout:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "692fedfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(\"cpu\")\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "be835f76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you know,\" was one of the axioms he laid down across the Sevres and silver of an exquisitely appointed lun\n"
     ]
    }
   ],
   "source": [
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
    "    max_new_tokens=25,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade717d4",
   "metadata": {},
   "source": [
    "Previously, inside the generate_text_simple function, we always sampled the token with the highest probability as the next token using torch.argmax, also known as greedy decoding.\n",
    "\n",
    "To generate text with more variety, we can replace the argmax with a function that samples from a probability distribution (here, the probability scores the LLM generates for each vocabulary entry at each token generation step).\n",
    "\n",
    "To illustrate the probabilistic sampling with a concrete example, let's briefly discuss the next-token generation process using a very small vocabulary for illustration purposes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "071c25c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = { \n",
    "    \"closer\": 0,\n",
    "    \"every\": 1, \n",
    "    \"effort\": 2, \n",
    "    \"forward\": 3,\n",
    "    \"inches\": 4,\n",
    "    \"moves\": 5, \n",
    "    \"pizza\": 6,\n",
    "    \"toward\": 7,\n",
    "    \"you\": 8,\n",
    "} \n",
    "\n",
    "inverse_vocab = {v: k for k, v in vocab.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "e26950f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "next_token_logits = torch.tensor(\n",
    "[4.51, 0.89, -1.90, 6.75, 1.63, -1.62, -1.89, 6.28, 1.79]\n",
    ")\n",
    "\n",
    "next_token_logits2 = next_token_logits/0.1\n",
    "\n",
    "next_token_logits3 = next_token_logits/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "68e6134a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([    0.0000,     0.0000,     0.0000,     0.9910,     0.0000,     0.0000,\n",
      "            0.0000,     0.0090,     0.0000])\n"
     ]
    }
   ],
   "source": [
    "probas = torch.softmax(next_token_logits2, dim=0)\n",
    "\n",
    "print(probas)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "e2fef2b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1546, 0.0750, 0.0429, 0.2421, 0.0869, 0.0454, 0.0430, 0.2203, 0.0898])\n"
     ]
    }
   ],
   "source": [
    "probas = torch.softmax(next_token_logits3, dim=0)\n",
    "\n",
    "print(probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b235bf",
   "metadata": {},
   "source": [
    "To implement a probabilistic sampling process, we can now replace the argmax with the multinomial function in PyTorch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "18bc7b8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "every\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "next_token_id = torch.multinomial(probas, num_samples=1).item()\n",
    "print(inverse_vocab[next_token_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f83f3452",
   "metadata": {},
   "source": [
    "The printed output is \"forward\" just like before. What happened? The multinomial function samples the next token proportional to its probability score.\n",
    "\n",
    "In other words, \"forward\" is still the most likely token and will be selected by multinomial most of the time but not all the time.\n",
    "\n",
    "To illustrate this, let's implement a function that repeats this sampling 1000 times:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "8d6b8f58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "165 x closer\n",
      "75 x every\n",
      "42 x effort\n",
      "239 x forward\n",
      "71 x inches\n",
      "46 x moves\n",
      "32 x pizza\n",
      "227 x toward\n",
      "103 x you\n"
     ]
    }
   ],
   "source": [
    "def print_sampled_tokens(probas):\n",
    "    torch.manual_seed(123) # Manual seed for reproducibility\n",
    "    sample = [torch.multinomial(probas, num_samples=1).item() for i in range(1_000)]\n",
    "    sampled_ids = torch.bincount(torch.tensor(sample))\n",
    "    for i, freq in enumerate(sampled_ids):\n",
    "        print(f\"{freq} x {inverse_vocab[i]}\")\n",
    "\n",
    "print_sampled_tokens(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "72ec7988",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def softmax_with_temperature(logits, temperature):\n",
    "    scaled_logits = logits / temperature\n",
    "    return torch.softmax(scaled_logits, dim=0)\n",
    "\n",
    "# Temperature values\n",
    "temperatures = [1, 0.1, 5]  # Original, higher confidence, and lower confidence\n",
    "\n",
    "# Calculate scaled probabilities\n",
    "scaled_probas = [softmax_with_temperature(next_token_logits, T) for T in temperatures]\n",
    "\n",
    "##Multinomial\n",
    "# Plotting\n",
    "x = torch.arange(len(vocab))\n",
    "bar_width = 0.15\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5, 3))\n",
    "for i, T in enumerate(temperatures):\n",
    "    rects = ax.bar(x + i * bar_width, scaled_probas[i], bar_width, label=f'Temperature = {T}')\n",
    "\n",
    "ax.set_ylabel('Probability')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(vocab.keys(), rotation=90)\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"temperature-plot.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f889f5",
   "metadata": {},
   "source": [
    "# Top-k Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "5e138228",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top logits: tensor([6.7500, 6.2800, 4.5100])\n",
      "Top positions: tensor([3, 7, 0])\n"
     ]
    }
   ],
   "source": [
    "top_k = 3\n",
    "top_logits, top_pos = torch.topk(next_token_logits, top_k)\n",
    "print(\"Top logits:\", top_logits)\n",
    "print(\"Top positions:\", top_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "54e22d05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4.5100,   -inf,   -inf, 6.7500,   -inf,   -inf,   -inf, 6.2800,   -inf])\n"
     ]
    }
   ],
   "source": [
    "new_logits = torch.where(condition=next_token_logits < top_logits[-1],input=torch.tensor(float(\"-inf\")), \n",
    "                         other=next_token_logits) #(Replace where, with what?, what about others)\n",
    "\n",
    "print(new_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "37a8e8f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0615, 0.0000, 0.0000, 0.5775, 0.0000, 0.0000, 0.0000, 0.3610, 0.0000])\n"
     ]
    }
   ],
   "source": [
    "topk_probas = torch.softmax(new_logits, dim=0)\n",
    "print(topk_probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff86334",
   "metadata": {},
   "source": [
    "# Top-k + Temp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e35f1073",
   "metadata": {},
   "source": [
    "Step 1: For-loop is the same as before: Get logits, and only focus on last time step\n",
    "\n",
    "Step 2: In this new section, we filter logits with top_k sampling\n",
    "\n",
    "Step 3: This is the new section where we apply temperature scaling\n",
    "\n",
    "Step 4: Carry out greedy next-token selection as before when temperature scaling is disabled\n",
    "\n",
    "Step 5: Stop generating early if end-of-sequence token is encountered and eos_id is specified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "2f365755",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(model, idx, max_new_tokens, context_size, temperature=0.0, top_k=None, eos_id=None):\n",
    "\n",
    "    # For-loop is the same as before: Get logits, and only focus on last time step\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "        logits = logits[:, -1, :]\n",
    "\n",
    "        # New: Filter logits with top_k sampling\n",
    "        if top_k is not None:\n",
    "            # Keep only top_k values\n",
    "            top_logits, _ = torch.topk(logits, top_k)\n",
    "            min_val = top_logits[:, -1]\n",
    "            logits = torch.where(logits < min_val, torch.tensor(float(\"-inf\")).to(logits.device), logits)\n",
    "\n",
    "        # New: Apply temperature scaling\n",
    "        if temperature > 0.0:\n",
    "            logits = logits / temperature\n",
    "\n",
    "            # Apply softmax to get probabilities\n",
    "            probs = torch.softmax(logits, dim=-1)  # (batch_size, context_len)\n",
    "\n",
    "            # Sample from the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)  # (batch_size, 1)\n",
    "\n",
    "        # Otherwise same as before: get idx of the vocab entry with the highest logits value\n",
    "        else:\n",
    "            idx_next = torch.argmax(logits, dim=-1, keepdim=True)  # (batch_size, 1)\n",
    "\n",
    "        if idx_next == eos_id:  # Stop generating early if end-of-sequence token is encountered and eos_id is specified\n",
    "            break\n",
    "\n",
    "        # Same as before: append sampled index to the running sequence\n",
    "        idx = torch.cat((idx, idx_next), dim=1)  # (batch_size, num_tokens+1)\n",
    "\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "164150ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you stand to work on surprise, a one of us had gone with random-dication: \"Yes\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "token_ids = generate(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
    "    max_new_tokens=20,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"],\n",
    "    top_k=25,\n",
    "    temperature=1.4\n",
    ")\n",
    "\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b20c9821",
   "metadata": {},
   "source": [
    "# LOADING AND SAVING MODEL WEIGHTS IN PYTORCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "214b17b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "torch.save(model.state_dict(), \"model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "baa66cd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.load_state_dict(torch.load(\"model.pth\"))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f686073a",
   "metadata": {},
   "source": [
    "Adaptive optimizers such as AdamW store additional parameters for each model weight. AdamW uses historical data to adjust learning rates for each model parameter dynamically.\n",
    "\n",
    "Without it, the optimizer resets, and the model may learn suboptimally or even fail to converge properly, which means that it will lose the ability to generate coherent text.\n",
    "\n",
    "Using torch.save, we can save both the model and optimizer state_dict contents as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "40a6776e",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0004, weight_decay=0.1)\n",
    "\n",
    "torch.save({\n",
    "    \"model_state_dict\": model.state_dict(),\n",
    "    \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "    }, \n",
    "    \"model_and_optimizer.pth\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "f52ba294",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(\"model_and_optimizer.pth\")\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-4, weight_decay=0.1)\n",
    "optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "model.train();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c6df78",
   "metadata": {},
   "source": [
    "# LOADING PRETRAINED WEIGHTS FROM OPENAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "f429964c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: 2.15.0 not found\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow>=2.15.0 tqdm>=4.66"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "0d9813b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.15.0\n",
      "tqdm version: 4.65.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tqdm\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"tqdm version:\", tqdm.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "352e2a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpt_download3 import download_and_load_gpt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "ac424c54",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/junaeidshoaib/anaconda3/lib/python3.11/site-packages/urllib3/connectionpool.py:1056: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2/124M/checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/junaeidshoaib/anaconda3/lib/python3.11/site-packages/urllib3/connectionpool.py:1056: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2/124M/encoder.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/junaeidshoaib/anaconda3/lib/python3.11/site-packages/urllib3/connectionpool.py:1056: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2/124M/hparams.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/junaeidshoaib/anaconda3/lib/python3.11/site-packages/urllib3/connectionpool.py:1056: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2/124M/model.ckpt.data-00000-of-00001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/junaeidshoaib/anaconda3/lib/python3.11/site-packages/urllib3/connectionpool.py:1056: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2/124M/model.ckpt.index\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/junaeidshoaib/anaconda3/lib/python3.11/site-packages/urllib3/connectionpool.py:1056: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2/124M/model.ckpt.meta\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/junaeidshoaib/anaconda3/lib/python3.11/site-packages/urllib3/connectionpool.py:1056: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2/124M/vocab.bpe\n"
     ]
    }
   ],
   "source": [
    "settings, params = download_and_load_gpt2(model_size=\"124M\", models_dir=\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "7889a9e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Settings: {'n_vocab': 50257, 'n_ctx': 1024, 'n_embd': 768, 'n_head': 12, 'n_layer': 12}\n",
      "Parameter dictionary keys or params: dict_keys(['blocks', 'b', 'g', 'wpe', 'wte'])\n"
     ]
    }
   ],
   "source": [
    "print(\"Settings:\", settings)\n",
    "print(\"Parameter dictionary keys or params:\", params.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "7c3aedda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.11010301 -0.03926672  0.03310751 ... -0.1363697   0.01506208\n",
      "   0.04531523]\n",
      " [ 0.04034033 -0.04861503  0.04624869 ...  0.08605453  0.00253983\n",
      "   0.04318958]\n",
      " [-0.12746179  0.04793796  0.18410145 ...  0.08991534 -0.12972379\n",
      "  -0.08785918]\n",
      " ...\n",
      " [-0.04453601 -0.05483596  0.01225674 ...  0.10435229  0.09783269\n",
      "  -0.06952604]\n",
      " [ 0.1860082   0.01665728  0.04611587 ... -0.09625227  0.07847701\n",
      "  -0.02245961]\n",
      " [ 0.05135201 -0.02768905  0.0499369  ...  0.00704835  0.15519823\n",
      "   0.12067825]]\n",
      "Token embedding weight tensor dimensions: (50257, 768)\n"
     ]
    }
   ],
   "source": [
    "print(params[\"wte\"])\n",
    "print(\"Token embedding weight tensor dimensions:\", params[\"wte\"].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abbacdf0",
   "metadata": {},
   "source": [
    "We downloaded and loaded the weights of the smallest GPT-2 model via the download_and_load_gpt2(model_size=\"124M\", ...) setting. However, note that OpenAI also shares the weights of larger models: \"355M\", \"774M\", and \"1558M\".\n",
    "\n",
    "Above, we loaded the 124M GPT-2 model weights into Python, however we still need to transfer them into our GPTModel instance.\n",
    "\n",
    "First, we initialize a new GPTModel instance.\n",
    "\n",
    "Note that the original GPT model initialized the linear layers for the query, key, and value matrices in the multi-head attention module with bias vectors, which is not required or recommended; however, to be able to load the weights correctly, we have to enable these too by setting qkv_bias to True in our implementation, too.\n",
    "\n",
    "We are also using the 1024 token context length that was used by the original GPT-2 model(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "33e91d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model configurations in a dictionary for compactness\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "\n",
    "# Copy the base configuration and update with specific model settings\n",
    "model_name = \"gpt2-small (124M)\"  # Example model name\n",
    "NEW_CONFIG = GPT_CONFIG_124M.copy()\n",
    "NEW_CONFIG.update(model_configs[model_name])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "43552361",
   "metadata": {},
   "outputs": [],
   "source": [
    "NEW_CONFIG.update({\"context_length\": 1024, \"qkv_bias\": True})\n",
    "gpt = GPTModel(NEW_CONFIG)\n",
    "gpt.eval();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55974a5e",
   "metadata": {},
   "source": [
    "Also, OpenAI used bias vectors in the multi-head attention module's linear layers to implement the query, key, and value matrix computations.\n",
    "\n",
    "Bias vectors are not commonly used in LLMs anymore as they don't improve the modeling performance and are thus unnecessary.\n",
    "\n",
    "However, since we are working with pretrained weights, we need to match the settings for consistency and enable these bias vectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "06b05f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign(left, right):\n",
    "    if left.shape != right.shape:\n",
    "        raise ValueError(f\"Shape mismatch. Left: {left.shape}, Right: {right.shape}\")\n",
    "    return torch.nn.Parameter(torch.tensor(right))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "08eca821",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def load_weights_into_gpt(gpt, params):\n",
    "    gpt.pos_emb.weight = assign(gpt.pos_emb.weight, params['wpe'])\n",
    "    gpt.tok_emb.weight = assign(gpt.tok_emb.weight, params['wte'])\n",
    "    \n",
    "    for b in range(len(params[\"blocks\"])):\n",
    "        q_w, k_w, v_w = np.split(\n",
    "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"w\"], 3, axis=-1)\n",
    "        gpt.trf_blocks[b].att.W_query.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_query.weight, q_w.T)\n",
    "        gpt.trf_blocks[b].att.W_key.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_key.weight, k_w.T)\n",
    "        gpt.trf_blocks[b].att.W_value.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_value.weight, v_w.T)\n",
    "\n",
    "        q_b, k_b, v_b = np.split(\n",
    "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"b\"], 3, axis=-1)\n",
    "        gpt.trf_blocks[b].att.W_query.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_query.bias, q_b)\n",
    "        gpt.trf_blocks[b].att.W_key.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_key.bias, k_b)\n",
    "        gpt.trf_blocks[b].att.W_value.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_value.bias, v_b)\n",
    "\n",
    "        gpt.trf_blocks[b].att.out_proj.weight = assign(\n",
    "            gpt.trf_blocks[b].att.out_proj.weight, \n",
    "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].att.out_proj.bias = assign(\n",
    "            gpt.trf_blocks[b].att.out_proj.bias, \n",
    "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"b\"])\n",
    "\n",
    "        gpt.trf_blocks[b].ff.layers[0].weight = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[0].weight, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].ff.layers[0].bias = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[0].bias, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"b\"])\n",
    "        gpt.trf_blocks[b].ff.layers[2].weight = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[2].weight, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].ff.layers[2].bias = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[2].bias, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"b\"])\n",
    "\n",
    "        gpt.trf_blocks[b].norm1.scale = assign(\n",
    "            gpt.trf_blocks[b].norm1.scale, \n",
    "            params[\"blocks\"][b][\"ln_1\"][\"g\"])\n",
    "        gpt.trf_blocks[b].norm1.shift = assign(\n",
    "            gpt.trf_blocks[b].norm1.shift, \n",
    "            params[\"blocks\"][b][\"ln_1\"][\"b\"])\n",
    "        gpt.trf_blocks[b].norm2.scale = assign(\n",
    "            gpt.trf_blocks[b].norm2.scale, \n",
    "            params[\"blocks\"][b][\"ln_2\"][\"g\"])\n",
    "        gpt.trf_blocks[b].norm2.shift = assign(\n",
    "            gpt.trf_blocks[b].norm2.shift, \n",
    "            params[\"blocks\"][b][\"ln_2\"][\"b\"])\n",
    "\n",
    "    gpt.final_norm.scale = assign(gpt.final_norm.scale, params[\"g\"])\n",
    "    gpt.final_norm.shift = assign(gpt.final_norm.shift, params[\"b\"])\n",
    "    gpt.out_head.weight = assign(gpt.out_head.weight, params[\"wte\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6162f892",
   "metadata": {},
   "source": [
    "Next, we define a load_weights_into_gpt function that loads the weights from the params dictionary into a GPTModel instance gpt:\n",
    "\n",
    "Step 1: Setting the model's positional and token embedding weights to those specified in params.\n",
    "\n",
    "Step 2: Iterate over each transformer block in the model.\n",
    "\n",
    "Step 3: The np.split function is used to divide the attention and bias weights into three equal parts for the query, key, and value components.\n",
    "\n",
    "Step 4: The original GPT-2 model by OpenAI reused the token embedding weights in the output layer to reduce the total number of parameters, which is a concept known as weight tying."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "c1ccc1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_weights_into_gpt(gpt, params)\n",
    "gpt.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "25f3237d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " The more you want, I'm guessing it'll take longer than you think! After all, at least 20 hours doesn't feel too bad…\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "token_ids = generate(\n",
    "    model=gpt,\n",
    "    idx=text_to_token_ids(\"The more you want\", tokenizer).to(device),\n",
    "    max_new_tokens=25,\n",
    "    context_size=NEW_CONFIG[\"context_length\"],\n",
    "    top_k=50,\n",
    "    temperature=1.5\n",
    ")\n",
    "\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d7ac653",
   "metadata": {},
   "source": [
    "# FINETUNING FOR CLASSIFICATION\n",
    "\n",
    "Dataset : https://archive.ics.uci.edu/dataset/228/sms+spam+collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "1a006a79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File downloaded and saved as sms_spam_collection/SMSSpamCollection.tsv\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "import ssl\n",
    "import zipfile\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "url = \"https://archive.ics.uci.edu/static/public/228/sms+spam+collection.zip\"\n",
    "zip_path = \"sms_spam_collection.zip\"\n",
    "extracted_path = \"sms_spam_collection\"\n",
    "data_file_path = Path(extracted_path) / \"SMSSpamCollection.tsv\"\n",
    "\n",
    "def download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path):\n",
    "    if data_file_path.exists():\n",
    "        print(f\"{data_file_path} already exists. Skipping download and extraction.\")\n",
    "        return\n",
    "\n",
    "    # Create an unverified SSL context\n",
    "    ssl_context = ssl._create_unverified_context()\n",
    "\n",
    "    # Downloading the file\n",
    "    with urllib.request.urlopen(url, context=ssl_context) as response:\n",
    "        with open(zip_path, \"wb\") as out_file:\n",
    "            out_file.write(response.read())\n",
    "\n",
    "    # Unzipping the file\n",
    "    with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
    "        zip_ref.extractall(extracted_path)\n",
    "\n",
    "    # Add .tsv file extension\n",
    "    original_file_path = Path(extracted_path) / \"SMSSpamCollection\"\n",
    "    os.rename(original_file_path, data_file_path)\n",
    "    print(f\"File downloaded and saved as {data_file_path}\")\n",
    "\n",
    "download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "26953700",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will ü b going to esplanade fr home?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Label                                               Text\n",
       "0      ham  Go until jurong point, crazy.. Available only ...\n",
       "1      ham                      Ok lar... Joking wif u oni...\n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      ham  U dun say so early hor... U c already then say...\n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...\n",
       "...    ...                                                ...\n",
       "5567  spam  This is the 2nd time we have tried 2 contact u...\n",
       "5568   ham               Will ü b going to esplanade fr home?\n",
       "5569   ham  Pity, * was in mood for that. So...any other s...\n",
       "5570   ham  The guy did some bitching but I acted like i'd...\n",
       "5571   ham                         Rofl. Its true to its name\n",
       "\n",
       "[5572 rows x 2 columns]"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(data_file_path, sep=\"\\t\", header=None, names=[\"Label\", \"Text\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "41dd99b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label\n",
      "ham     4825\n",
      "spam     747\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df[\"Label\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f2e7ca2",
   "metadata": {},
   "source": [
    "For simplicity, and because we prefer a small dataset for educational purposes anyway (it will make it possible to finetune the LLM faster), we subsample (undersample) the dataset so that it contains 747 instances from each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "76696dfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label\n",
      "ham     747\n",
      "spam    747\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def create_balanced_dataset(df):\n",
    "    \n",
    "    # Count the instances of \"spam\"\n",
    "    num_spam = df[df[\"Label\"] == \"spam\"].shape[0]\n",
    "    \n",
    "    # Randomly sample \"ham\" instances to match the number of \"spam\" instances\n",
    "    ham_subset = df[df[\"Label\"] == \"ham\"].sample(num_spam, random_state=123)\n",
    "    \n",
    "    # Combine ham \"subset\" with \"spam\"\n",
    "    balanced_df = pd.concat([ham_subset, df[df[\"Label\"] == \"spam\"]])\n",
    "\n",
    "    return balanced_df\n",
    "\n",
    "balanced_df = create_balanced_dataset(df)\n",
    "print(balanced_df[\"Label\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "5e8fb8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_df[\"Label\"] = balanced_df[\"Label\"].map({\"ham\": 0, \"spam\": 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "1b10acd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_split(df, train_frac, validation_frac):\n",
    "    # Shuffle the entire DataFrame\n",
    "    df = df.sample(frac=1, random_state=123).reset_index(drop=True)\n",
    "\n",
    "    # Calculate split indices\n",
    "    train_end = int(len(df) * train_frac)\n",
    "    validation_end = train_end + int(len(df) * validation_frac)\n",
    "\n",
    "    # Split the DataFrame\n",
    "    train_df = df[:train_end]\n",
    "    validation_df = df[train_end:validation_end]\n",
    "    test_df = df[validation_end:]\n",
    "\n",
    "    return train_df, validation_df, test_df\n",
    "\n",
    "train_df, validation_df, test_df = random_split(balanced_df, 0.7, 0.1)\n",
    "# Test size is implied to be 0.2 as the remainder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "14196b45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1045\n",
      "149\n",
      "300\n"
     ]
    }
   ],
   "source": [
    "print(len(train_df))\n",
    "print(len(validation_df))\n",
    "print(len(test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "0ad79ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv(\"train.csv\", index=None)\n",
    "validation_df.to_csv(\"validation.csv\", index=None)\n",
    "test_df.to_csv(\"test.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "fed56066",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class SpamDataset(Dataset):\n",
    "    def __init__(self, csv_file, tokenizer, max_length=None, pad_token_id=50256):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "\n",
    "        # Pre-tokenize texts\n",
    "        self.encoded_texts = [\n",
    "            tokenizer.encode(text) for text in self.data[\"Text\"]\n",
    "        ]\n",
    "\n",
    "        if max_length is None:\n",
    "            self.max_length = self._longest_encoded_length()\n",
    "        else:\n",
    "            self.max_length = max_length\n",
    "            # Truncate sequences if they are longer than max_length\n",
    "            self.encoded_texts = [\n",
    "                encoded_text[:self.max_length]\n",
    "                for encoded_text in self.encoded_texts\n",
    "            ]\n",
    "\n",
    "        # Pad sequences to the longest sequence\n",
    "        self.encoded_texts = [\n",
    "            encoded_text + [pad_token_id] * (self.max_length - len(encoded_text))\n",
    "            for encoded_text in self.encoded_texts\n",
    "        ]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        encoded = self.encoded_texts[index]\n",
    "        label = self.data.iloc[index][\"Label\"]\n",
    "        return (\n",
    "            torch.tensor(encoded, dtype=torch.long),\n",
    "            torch.tensor(label, dtype=torch.long)\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def _longest_encoded_length(self):\n",
    "        max_length = 0\n",
    "        for encoded_text in self.encoded_texts:\n",
    "            encoded_length = len(encoded_text)\n",
    "            if encoded_length > max_length:\n",
    "                max_length = encoded_length\n",
    "        return max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "e422c404",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n"
     ]
    }
   ],
   "source": [
    "train_dataset = SpamDataset(\n",
    "    csv_file=\"train.csv\",\n",
    "    max_length=None,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "print(train_dataset.max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "98362b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = SpamDataset(\n",
    "    csv_file=\"validation.csv\",\n",
    "    max_length=train_dataset.max_length,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "test_dataset = SpamDataset(\n",
    "    csv_file=\"test.csv\",\n",
    "    max_length=train_dataset.max_length,\n",
    "    tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "9b945f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "num_workers = 0\n",
    "batch_size = 8\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=True,\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    dataset=val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=False,\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "4770ff81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "Input batch dimensions: torch.Size([8, 120])\n",
      "Label batch dimensions torch.Size([8])\n"
     ]
    }
   ],
   "source": [
    "print(\"Train loader:\")\n",
    "for input_batch, target_batch in train_loader:\n",
    "    pass\n",
    "\n",
    "print(\"Input batch dimensions:\", input_batch.shape)\n",
    "print(\"Label batch dimensions\", target_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "9d4ab93e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130 training batches\n",
      "19 validation batches\n",
      "38 test batches\n"
     ]
    }
   ],
   "source": [
    "print(f\"{len(train_loader)} training batches\")\n",
    "print(f\"{len(val_loader)} validation batches\")\n",
    "print(f\"{len(test_loader)} test batches\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5505658",
   "metadata": {},
   "source": [
    "\n",
    "In this section, we prepare the model we will use for the classification-finetuning to identify spam messages.\n",
    "\n",
    "We start with initializing the pretrained model we worked with in the previous chapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "38555c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHOOSE_MODEL = \"gpt2-small (124M)\"\n",
    "INPUT_PROMPT = \"Every effort moves\"\n",
    "\n",
    "BASE_CONFIG = {\n",
    "    \"vocab_size\": 50257,     # Vocabulary size\n",
    "    \"context_length\": 1024,  # Context length\n",
    "    \"drop_rate\": 0.0,        # Dropout rate\n",
    "    \"qkv_bias\": True         # Query-key-value bias\n",
    "}\n",
    "\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "\n",
    "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])\n",
    "\n",
    "assert train_dataset.max_length <= BASE_CONFIG[\"context_length\"], (\n",
    "    f\"Dataset length {train_dataset.max_length} exceeds model's context \"\n",
    "    f\"length {BASE_CONFIG['context_length']}. Reinitialize data sets with \"\n",
    "    f\"`max_length={BASE_CONFIG['context_length']}`\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "00595fb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/junaeidshoaib/anaconda3/lib/python3.11/site-packages/urllib3/connectionpool.py:1056: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2/124M/checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/junaeidshoaib/anaconda3/lib/python3.11/site-packages/urllib3/connectionpool.py:1056: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2/124M/encoder.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/junaeidshoaib/anaconda3/lib/python3.11/site-packages/urllib3/connectionpool.py:1056: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2/124M/hparams.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/junaeidshoaib/anaconda3/lib/python3.11/site-packages/urllib3/connectionpool.py:1056: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2/124M/model.ckpt.data-00000-of-00001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/junaeidshoaib/anaconda3/lib/python3.11/site-packages/urllib3/connectionpool.py:1056: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2/124M/model.ckpt.index\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/junaeidshoaib/anaconda3/lib/python3.11/site-packages/urllib3/connectionpool.py:1056: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2/124M/model.ckpt.meta\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/junaeidshoaib/anaconda3/lib/python3.11/site-packages/urllib3/connectionpool.py:1056: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2/124M/vocab.bpe\n"
     ]
    }
   ],
   "source": [
    "model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\n",
    "\n",
    "from gpt_download3 import download_and_load_gpt2\n",
    "\n",
    "settings, params = download_and_load_gpt2(model_size=model_size, models_dir=\"gpt2\")\n",
    "\n",
    "model = GPTModel(BASE_CONFIG)\n",
    "load_weights_into_gpt(model, params)\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "7dcba4bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Every effort moves you forward.\n",
      "\n",
      "The first step is to understand the importance of your work.\n"
     ]
    }
   ],
   "source": [
    "#To ensure that the model was loaded correctly, let's double-check that it generates coherent text\n",
    "text_1 = \"Every effort moves you\"\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(text_1, tokenizer),\n",
    "    max_new_tokens=16,\n",
    "    context_size=BASE_CONFIG[\"context_length\"]\n",
    ")\n",
    "\n",
    "print(token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "bc461cfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is the following text 'spam'? Answer with 'yes' or 'no': 'You are a winner you have been specially selected to receive $1000 cash or a $2000 award.'\n",
      "\n",
      "The following text 'spam'? Answer with 'yes' or 'no': 'You are a winner\n"
     ]
    }
   ],
   "source": [
    "text_2 = (\n",
    "    \"Is the following text 'spam'? Answer with 'yes' or 'no':\"\n",
    "    \" 'You are a winner you have been specially\"\n",
    "    \" selected to receive $1000 cash or a $2000 award.'\"\n",
    ")\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(text_2, tokenizer),\n",
    "    max_new_tokens=23,\n",
    "    context_size=BASE_CONFIG[\"context_length\"]\n",
    ")\n",
    "\n",
    "print(token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e46cd6ad",
   "metadata": {},
   "source": [
    "# ADDING A CLASSIFICATION HEAD\n",
    "In this section, we modify the pretrained large language model to prepare it for classification-finetuning.\n",
    "\n",
    "To do this, we replace the original output layer, which maps the hidden representation to a vocabulary of 50,257, with a smaller output layer that maps to two classes: 0 (\"not spam\") and 1 (\"spam\"),\n",
    "\n",
    "We could technically use a single output node since we are dealing with a binary classification task.\n",
    "\n",
    "However, this would require modifying the loss function.\n",
    "\n",
    "Therefore, we choose a more general approach where the number of output nodes matches the number of classes.\n",
    "\n",
    "For example, for a 3-class problem, such as classifying news articles as \"Technology\", \"Sports\", or \"Politics\", we would use three output nodes, and so forth.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "f027394e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPTModel(\n",
      "  (tok_emb): Embedding(50257, 768)\n",
      "  (pos_emb): Embedding(1024, 768)\n",
      "  (drop_emb): Dropout(p=0.0, inplace=False)\n",
      "  (trf_blocks): Sequential(\n",
      "    (0): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (1): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (2): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (3): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (4): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (5): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (6): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (7): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (8): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (9): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (10): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (11): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (final_norm): LayerNorm()\n",
      "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb1f75c",
   "metadata": {},
   "source": [
    "the GPTModel consists of embedding layers followed by 12 identical transformer blocks (only the last block is shown for brevity), followed by a final LayerNorm and the output layer, out_head.\n",
    "\n",
    "Next, we replace the out_head with a new output layer, as illustrated in figure 6.9, that we will finetune."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "0e58694e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e1308bc",
   "metadata": {},
   "source": [
    "We could technically use a single output node since we are dealing with a binary classification task.\n",
    "\n",
    "However, this would require modifying the loss function.\n",
    "\n",
    "Therefore, we choose a more general approach where the number of output nodes matches the number of classes.\n",
    "\n",
    "For example, for a 3-class problem, such as classifying news articles as \"Technology\", \"Sports\", or \"Politics\", we would use three output nodes, and so forth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "b8f1d5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "num_classes = 2\n",
    "model.out_head = torch.nn.Linear(in_features=BASE_CONFIG[\"emb_dim\"], out_features=num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421a846b",
   "metadata": {},
   "source": [
    "Note that in the preceding code, we use BASE_CONFIG[\"emb_dim\"], which is equal to 768 in the \"gpt2-small (124M)\" model, to keep the code below more general.\n",
    "\n",
    "This means we can also use the same code to work with the larger GPT-2 model variants.\n",
    "\n",
    "This new model.out_head output layer has its requires_grad attribute set to True by default, which means that it's the only layer in the model that will be updated during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "ef873b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.trf_blocks[-1].parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "for param in model.final_norm.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "225c3163",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs: tensor([[5211,  345,  423,  640]])\n",
      "Inputs dimensions: torch.Size([1, 4])\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer.encode(\"Do you have time\")\n",
    "inputs = torch.tensor(inputs).unsqueeze(0)\n",
    "print(\"Inputs:\", inputs)\n",
    "print(\"Inputs dimensions:\", inputs.shape) # shape: (batch_size, num_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "4f5b598f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outputs:\n",
      " tensor([[[-1.5854,  0.9904],\n",
      "         [-3.7235,  7.4548],\n",
      "         [-2.2661,  6.6049],\n",
      "         [-3.5983,  3.9902]]])\n",
      "Outputs dimensions: torch.Size([1, 4, 2])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = model(inputs)\n",
    "\n",
    "print(\"Outputs:\\n\", outputs)\n",
    "print(\"Outputs dimensions:\", outputs.shape) # shape: (batch_size, num_tokens, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "11395a7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last output token: tensor([[-3.5983,  3.9902]])\n"
     ]
    }
   ],
   "source": [
    "print(\"Last output token:\", outputs[:, -1, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3668cdc",
   "metadata": {},
   "source": [
    "# CALCULATING THE CLASSIFICATION LOSS AND ACCURACY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "064926df",
   "metadata": {},
   "source": [
    "we computed the token ID of the next token generated by the LLM by converting the 50,257 outputs into probabilities via the softmax function and then returning the position of the highest probability via the argmax function.\n",
    "\n",
    "Here, we take the same approach to calculate whether the model outputs a \"spam\" or \"not spam\" prediction for a given input, with the only difference being that we work with 2-dimensional instead of 50,257-dimensional outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "fa691531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0.0005,     0.9995]])\n",
      "Class label: 1\n"
     ]
    }
   ],
   "source": [
    "probas = torch.softmax(outputs[:, -1, :], dim=-1)\n",
    "print(probas)\n",
    "label = torch.argmax(probas)\n",
    "print(\"Class label:\", label.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "ab6d744e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_accuracy_loader(data_loader, model, device, num_batches=None):\n",
    "    model.eval()\n",
    "    correct_predictions, num_examples = 0, 0\n",
    "\n",
    "    if num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                logits = model(input_batch)[:, -1, :]  # Logits of last output token\n",
    "            predicted_labels = torch.argmax(logits, dim=-1)\n",
    "\n",
    "            num_examples += predicted_labels.shape[0]\n",
    "            correct_predictions += (predicted_labels == target_batch).sum().item()\n",
    "        else:\n",
    "            break\n",
    "    return correct_predictions / num_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "d4fdf360",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 46.25%\n",
      "Validation accuracy: 45.00%\n",
      "Test accuracy: 48.75%\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Note:\n",
    "# Uncommenting the following lines will allow the code to run on Apple Silicon chips, if applicable,\n",
    "# which is approximately 2x faster than on an Apple CPU (as measured on an M3 MacBook Air).\n",
    "# As of this writing, in PyTorch 2.4, the results obtained via CPU and MPS were identical.\n",
    "# However, in earlier versions of PyTorch, you may observe different results when using MPS.\n",
    "\n",
    "#if torch.cuda.is_available():\n",
    "#    device = torch.device(\"cuda\")\n",
    "#elif torch.backends.mps.is_available():\n",
    "#    device = torch.device(\"mps\")\n",
    "#else:\n",
    "#    device = torch.device(\"cpu\")\n",
    "#print(f\"Running on {device} device.\")\n",
    "\n",
    "model.to(device) # no assignment model = model.to(device) necessary for nn.Module classes\n",
    "\n",
    "torch.manual_seed(123) # For reproducibility due to the shuffling in the training data loader\n",
    "\n",
    "train_accuracy = calc_accuracy_loader(train_loader, model, device, num_batches=10)\n",
    "val_accuracy = calc_accuracy_loader(val_loader, model, device, num_batches=10)\n",
    "test_accuracy = calc_accuracy_loader(test_loader, model, device, num_batches=10)\n",
    "\n",
    "print(f\"Training accuracy: {train_accuracy*100:.2f}%\")\n",
    "print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c817c7c0",
   "metadata": {},
   "source": [
    "As we can see, the prediction accuracies are near a random prediction, which would be 50% in this case.\n",
    "\n",
    "To improve the prediction accuracies, we need to finetune the model.\n",
    "\n",
    "Classification accuracy is not a differentiable function, so we use cross entropy loss as a proxy to maximize accuracy.\n",
    "\n",
    "This is the same cross entropy loss discussed earlier.\n",
    "\n",
    "Accordingly, the calc_loss_batch function remains the same as in earlier, with one adjustment: we focus on optimizing only the last token, model(input_batch)[:, -1, :], rather than all tokens, model(input_batch):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "22bc72a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "    logits = model(input_batch)[:, -1, :]  # Logits of last output token\n",
    "    loss = torch.nn.functional.cross_entropy(logits, target_batch)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "267d1993",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same as in chapter 5\n",
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0.\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        # Reduce the number of batches to match the total number of batches in the data loader\n",
    "        # if num_batches exceeds the number of batches in the data loader\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "    return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "d3cdf6fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 2.453\n",
      "Validation loss: 2.583\n",
      "Test loss: 2.322\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad(): # Disable gradient tracking for efficiency because we are not training, yet\n",
    "    train_loss = calc_loss_loader(train_loader, model, device, num_batches=5)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device, num_batches=5)\n",
    "    test_loss = calc_loss_loader(test_loader, model, device, num_batches=5)\n",
    "\n",
    "print(f\"Training loss: {train_loss:.3f}\")\n",
    "print(f\"Validation loss: {val_loss:.3f}\")\n",
    "print(f\"Test loss: {test_loss:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf1a7e4",
   "metadata": {},
   "source": [
    "# FINETUNING THE MODEL ON SUPERVISED DATA\n",
    "The training function also closely mirrors the train_model_simple function used for pretraining the model earlier.\n",
    "\n",
    "The only two distinctions are that we now track the number of training examples seen (examples_seen) instead of the number of tokens, and we calculate the accuracy after each epoch instead of printing a sample text:\n",
    "\n",
    "Step 1: Set model to training mode\n",
    "\n",
    "Step 2: Reset loss gradients from previous batch iteration\n",
    "\n",
    "Step 3: Calculate loss gradients\n",
    "\n",
    "Step 4: Update model weights using loss gradients\n",
    "\n",
    "Step 5: New: track examples instead of tokens\n",
    "\n",
    "Step 6: Optional evaluation step\n",
    "\n",
    "Step 7: Calculate accuracy after each epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "85d8c4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall the same as `train_model_simple` \n",
    "def train_classifier_simple(model, train_loader, val_loader, optimizer, device, num_epochs,\n",
    "                            eval_freq, eval_iter):\n",
    "    # Initialize lists to track losses and examples seen\n",
    "    train_losses, val_losses, train_accs, val_accs = [], [], [], []\n",
    "    examples_seen, global_step = 0, -1\n",
    "\n",
    "    # Main training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # Set model to training mode\n",
    "\n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad() # Reset loss gradients from previous batch iteration\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            loss.backward() # Calculate loss gradients\n",
    "            optimizer.step() # Update model weights using loss gradients\n",
    "            examples_seen += input_batch.shape[0] # New: track examples instead of tokens\n",
    "            global_step += 1\n",
    "\n",
    "            # Optional evaluation step\n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                    model, train_loader, val_loader, device, eval_iter)\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
    "                      f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
    "\n",
    "        # Calculate accuracy after each epoch\n",
    "        train_accuracy = calc_accuracy_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_accuracy = calc_accuracy_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "        print(f\"Training accuracy: {train_accuracy*100:.2f}% | \", end=\"\")\n",
    "        print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "        train_accs.append(train_accuracy)\n",
    "        val_accs.append(val_accuracy)\n",
    "\n",
    "    return train_losses, val_losses, train_accs, val_accs, examples_seen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "235ece89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same as chapter 5\n",
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "    model.train()\n",
    "    return train_loss, val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "1c7e6106",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 2.153, Val loss 2.392\n",
      "Ep 1 (Step 000050): Train loss 0.617, Val loss 0.637\n",
      "Ep 1 (Step 000100): Train loss 0.523, Val loss 0.557\n",
      "Training accuracy: 70.00% | Validation accuracy: 72.50%\n",
      "Ep 2 (Step 000150): Train loss 0.561, Val loss 0.489\n",
      "Ep 2 (Step 000200): Train loss 0.419, Val loss 0.397\n",
      "Ep 2 (Step 000250): Train loss 0.409, Val loss 0.353\n",
      "Training accuracy: 82.50% | Validation accuracy: 85.00%\n",
      "Ep 3 (Step 000300): Train loss 0.333, Val loss 0.320\n",
      "Ep 3 (Step 000350): Train loss 0.340, Val loss 0.306\n",
      "Training accuracy: 90.00% | Validation accuracy: 90.00%\n",
      "Ep 4 (Step 000400): Train loss 0.136, Val loss 0.200\n",
      "Ep 4 (Step 000450): Train loss 0.153, Val loss 0.132\n",
      "Ep 4 (Step 000500): Train loss 0.222, Val loss 0.137\n",
      "Training accuracy: 100.00% | Validation accuracy: 97.50%\n",
      "Ep 5 (Step 000550): Train loss 0.207, Val loss 0.143\n",
      "Ep 5 (Step 000600): Train loss 0.083, Val loss 0.074\n",
      "Training accuracy: 100.00% | Validation accuracy: 97.50%\n",
      "Training completed in 7.51 minutes.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5, weight_decay=0.1)\n",
    "\n",
    "num_epochs = 5\n",
    "train_losses, val_losses, train_accs, val_accs, examples_seen = train_classifier_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=50, eval_iter=5,\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "85b9f4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_values(epochs_seen, examples_seen, train_values, val_values, label=\"loss\"):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "\n",
    "    # Plot training and validation loss against epochs\n",
    "    ax1.plot(epochs_seen, train_values, label=f\"Training {label}\")\n",
    "    ax1.plot(epochs_seen, val_values, linestyle=\"-.\", label=f\"Validation {label}\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(label.capitalize())\n",
    "    ax1.legend()\n",
    "\n",
    "    # Create a second x-axis for examples seen\n",
    "    ax2 = ax1.twiny()  # Create a second x-axis that shares the same y-axis\n",
    "    ax2.plot(examples_seen, train_values, alpha=0)  # Invisible plot for aligning ticks\n",
    "    ax2.set_xlabel(\"Examples seen\")\n",
    "\n",
    "    fig.tight_layout()  # Adjust layout to make room\n",
    "    plt.savefig(f\"{label}-plot.pdf\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "b9c5582c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "examples_seen_tensor = torch.linspace(0, examples_seen, len(train_losses))\n",
    "\n",
    "plot_values(epochs_tensor, examples_seen_tensor, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9afb0239",
   "metadata": {},
   "source": [
    "As we can see based on the sharp downward slope, the model is learning well from the training data, and there is little to no indication of overfitting; that is, there is no noticeable gap between the training and validation set losses).\n",
    "\n",
    "Using the same plot_values function, let's now also plot the classification accuracies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "52e0814a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_accs))\n",
    "examples_seen_tensor = torch.linspace(0, examples_seen, len(train_accs))\n",
    "\n",
    "plot_values(epochs_tensor, examples_seen_tensor, train_accs, val_accs, label=\"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6951130",
   "metadata": {},
   "source": [
    "Based on the accuracy plot in figure 6.17, the model achieves a relatively high training and validation accuracy after epochs 4 and 5.\n",
    "\n",
    "However, it's important to note that we previously set eval_iter=5 when using the train_classifier_simple function, which means our estimations of training and validation performance were based on only 5 batches for efficiency during training.\n",
    "\n",
    "Now, we will calculate the performance metrics for the training, validation, and test sets across the entire dataset by running the following code, this time without defining the eval_iter value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "7bf46489",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 97.21%\n",
      "Validation accuracy: 97.32%\n",
      "Test accuracy: 95.67%\n"
     ]
    }
   ],
   "source": [
    "train_accuracy = calc_accuracy_loader(train_loader, model, device)\n",
    "val_accuracy = calc_accuracy_loader(val_loader, model, device)\n",
    "test_accuracy = calc_accuracy_loader(test_loader, model, device)\n",
    "\n",
    "print(f\"Training accuracy: {train_accuracy*100:.2f}%\")\n",
    "print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d4f94b",
   "metadata": {},
   "source": [
    "The training and test set performances are almost identical.\n",
    "\n",
    "A slight discrepancy between the training and test set accuracies suggests minimal overfitting of the training data.\n",
    "\n",
    "Typically, the validation set accuracy is somewhat higher than the test set accuracy because the model development often involves tuning hyperparameters to perform well on the validation set, which might not generalize as effectively to the test set.\n",
    "\n",
    "This situation is common, but the gap could potentially be minimized by adjusting the model's settings, such as increasing the dropout rate (drop_rate) or the weight_decay parameter in the optimizer configuration."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a89d782",
   "metadata": {},
   "source": [
    "# USING THE LLM AS A SPAM CLASSIFIER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ef8431",
   "metadata": {},
   "source": [
    "After finetuning and evaluating the model in the previous sections, we are now in the final stage of this chapter: using the model to classify spam messages.\n",
    "\n",
    "Finally, let's use the finetuned GPT-based spam classification model.\n",
    "\n",
    "The following classify_review function follows data preprocessing steps similar to those we used in the SpamDataset implemented earlier in this chapter.\n",
    "\n",
    "And then, after processing text into token IDs, the function uses the model to predict an integer class label, similar to what we have implemented earlier, and then returns the corresponding class name:\n",
    "\n",
    "Step 1: Prepare inputs to the model\n",
    "\n",
    "Step 2: Truncate sequences if they too long\n",
    "\n",
    "Step 3: Pad sequences to the longest sequence\n",
    "\n",
    "Step 4: Add batch dimension\n",
    "\n",
    "Step 5: Model inference without gradient tracking\n",
    "\n",
    "Step 6: Logits of the last output token\n",
    "\n",
    "Step 7: Return the classified result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "3f588edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_review(text, model, tokenizer, device, max_length=None, pad_token_id=50256):\n",
    "    model.eval()\n",
    "\n",
    "    # Prepare inputs to the model\n",
    "    input_ids = tokenizer.encode(text)\n",
    "    supported_context_length = model.pos_emb.weight.shape[0]\n",
    "    # Note: In the book, this was originally written as pos_emb.weight.shape[1] by mistake\n",
    "    # It didn't break the code but would have caused unnecessary truncation (to 768 instead of 1024)\n",
    "\n",
    "    # Truncate sequences if they too long\n",
    "    input_ids = input_ids[:min(max_length, supported_context_length)]\n",
    "\n",
    "    # Pad sequences to the longest sequence\n",
    "    input_ids += [pad_token_id] * (max_length - len(input_ids))\n",
    "    input_tensor = torch.tensor(input_ids, device=device).unsqueeze(0) # add batch dimension\n",
    "\n",
    "    # Model inference\n",
    "    with torch.no_grad():\n",
    "        logits = model(input_tensor)[:, -1, :]  # Logits of the last output token\n",
    "    predicted_label = torch.argmax(logits, dim=-1).item()\n",
    "\n",
    "    # Return the classified result\n",
    "    return \"spam\" if predicted_label == 1 else \"not spam\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "ff8f8046",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spam\n"
     ]
    }
   ],
   "source": [
    "text_1 = (\n",
    "    \"You are a winner you have been specially\"\n",
    "    \" selected to receive $1000 cash or a $2000 award.\"\n",
    ")\n",
    "\n",
    "print(classify_review(\n",
    "    text_1, model, tokenizer, device, max_length=train_dataset.max_length\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "a84a58cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not spam\n"
     ]
    }
   ],
   "source": [
    "text_2 = (\n",
    "    \"Hey, just wanted to check if we're still on\"\n",
    "    \" for dinner tonight? Let me know!\"\n",
    ")\n",
    "\n",
    "print(classify_review(\n",
    "    text_2, model, tokenizer, device, max_length=train_dataset.max_length\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "a0a7d04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"review_classifier.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "4d2508ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_state_dict = torch.load(\"review_classifier.pth\")\n",
    "model.load_state_dict(model_state_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccdc5e4a",
   "metadata": {},
   "source": [
    "# Instruction finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "5eeebdb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries: 1100\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import urllib\n",
    "import ssl\n",
    "\n",
    "def download_and_load_file(file_path, url):\n",
    "    ssl_context = ssl.create_default_context()\n",
    "    ssl_context.check_hostname = False\n",
    "    ssl_context.verify_mode = ssl.CERT_NONE\n",
    "\n",
    "    if not os.path.exists(file_path):\n",
    "        with urllib.request.urlopen(url, context=ssl_context) as response:\n",
    "            text_data = response.read().decode(\"utf-8\")\n",
    "        with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "            file.write(text_data)\n",
    "    else:\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "            text_data = file.read()\n",
    "\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "file_path = \"instruction-data.json\"\n",
    "url = (\n",
    "    \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch\"\n",
    "    \"/main/ch07/01_main-chapter-code/instruction-data.json\"\n",
    ")\n",
    "\n",
    "data = download_and_load_file(file_path, url)\n",
    "print(\"Number of entries:\", len(data))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690ed9eb",
   "metadata": {},
   "source": [
    "The data list , which we loaded from the JSON file contains the 1100 entries of the instruction dataset.\n",
    "\n",
    "Let's print one of the entries to see how each entry is structured:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "e0b554fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example entry:\n",
      " {'instruction': 'Identify the correct spelling of the following word.', 'input': 'Ocassion', 'output': \"The correct spelling is 'Occasion.'\"}\n"
     ]
    }
   ],
   "source": [
    "print(\"Example entry:\\n\", data[50])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "722e81f6",
   "metadata": {},
   "source": [
    "# CONVERTING INSTRUCTIONS INTO ALPACA FORMAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "a5b06c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_input(entry):\n",
    "    instruction_text = (\n",
    "        f\"Below is an instruction that describes a task. \"\n",
    "        f\"Write a response that appropriately completes the request.\"\n",
    "        f\"\\n\\n### Instruction:\\n{entry['instruction']}\"\n",
    "    )\n",
    "\n",
    "    input_text = f\"\\n\\n### Input:\\n{entry['input']}\" if entry[\"input\"] else \"\"\n",
    "\n",
    "    x =instruction_text + input_text\n",
    "    response_text = f\"\\n\\n### Response:\\n{entry['output']}\"\n",
    "    \n",
    "    return x + response_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719a55fe",
   "metadata": {},
   "source": [
    "Lets test the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "ca853aa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Identify the correct spelling of the following word.\n",
      "\n",
      "### Input:\n",
      "Ocassion\n",
      "\n",
      "### Response:\n",
      "The correct spelling is 'Occasion.'\n"
     ]
    }
   ],
   "source": [
    "model_input = format_input(data[50])\n",
    "\n",
    "\n",
    "print(model_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "9c719474",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What is an antonym of 'complicated'?\n",
      "\n",
      "### Response:\n",
      "An antonym of 'complicated' is 'simple'.\n"
     ]
    }
   ],
   "source": [
    "model_input = format_input(data[999])\n",
    "\n",
    "\n",
    "print(model_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d85114",
   "metadata": {},
   "source": [
    "# SPLITTING DATASET INTO TRAIN-TEST-VALIDATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "b03a05c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_portion = int(len(data) * 0.85)  # 85% for training\n",
    "test_portion = int(len(data) * 0.1)    # 10% for testing\n",
    "val_portion = len(data) - train_portion - test_portion  # Remaining 5% for validation\n",
    "\n",
    "train_data = data[:train_portion]\n",
    "test_data = data[train_portion:train_portion + test_portion]\n",
    "val_data = data[train_portion + test_portion:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "1aa11e5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set length: 935\n",
      "Validation set length: 55\n",
      "Test set length: 110\n"
     ]
    }
   ],
   "source": [
    "print(\"Training set length:\", len(train_data))\n",
    "print(\"Validation set length:\", len(val_data))\n",
    "print(\"Test set length:\", len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "9ff9ce6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class InstructionDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer):\n",
    "        self.data = data\n",
    "\n",
    "        # Pre-tokenize texts\n",
    "        self.encoded_texts = []\n",
    "        for entry in data:\n",
    "            full_text = format_input(entry)\n",
    "            self.encoded_texts.append(\n",
    "                tokenizer.encode(full_text)\n",
    "            )\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.encoded_texts[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "603260f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 1100\n",
      "Sample 0 tokens: [21106, 318, 281, 12064, 326, 8477, 257, 4876, 13, 19430, 257, 2882, 326, 20431, 32543, 262, 2581, 13, 198, 198, 21017, 46486, 25, 198, 33234, 1958, 262, 3376, 24993, 286, 262, 1708, 1573, 13, 198, 198, 21017, 23412, 25, 198, 46, 66, 11857, 198, 198, 21017, 18261, 25, 198, 464, 3376, 24993, 318, 705, 29223, 4247, 2637]\n",
      "Decoded sample 0: Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What is an antonym of 'complicated'?\n",
      "\n",
      "### Response:\n",
      "An antonym of 'complicated' is 'simple'.\n"
     ]
    }
   ],
   "source": [
    "dataset = InstructionDataset(data, tokenizer)\n",
    "\n",
    "print(\"Number of samples:\", len(dataset))\n",
    "print(\"Sample 0 tokens:\", dataset[50])\n",
    "print(\"Decoded sample 0:\", tokenizer.decode(dataset[999]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d962a7",
   "metadata": {},
   "source": [
    "Moving on, here, we adopt a more sophisticated approach by developing a custom collate function that we can pass to the data loader.\n",
    "\n",
    "This custom collate function pads the training examples in each batch to have the same length, while allowing different batches to have different lengths.\n",
    "\n",
    "This approach minimizes unnecessary padding by only extending sequences to match the longest one in each batch, not the whole dataset.\n",
    "\n",
    "We can implement the padding process with a custom collate function as follows:\n",
    "\n",
    "Step 1: Find the longest sequence in the batch\n",
    "\n",
    "Step 2: Pad and prepare inputs\n",
    "\n",
    "Step 3: Remove extra padded token added earlier\n",
    "\n",
    "Step 4: Convert list of inputs to tensor and transfer to target device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "8e1de7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate_draft_1(\n",
    "    batch,\n",
    "    pad_token_id=50256,\n",
    "    device=\"cpu\"\n",
    "):\n",
    "    # Find the longest sequence in the batch\n",
    "    # and increase the max length by +1, which will add one extra\n",
    "    # padding token below\n",
    "    batch_max_length = max(len(item)+1 for item in batch)\n",
    "\n",
    "    # Pad and prepare inputs\n",
    "    inputs_lst = []\n",
    "\n",
    "    for item in batch:\n",
    "        new_item = item.copy()\n",
    "        # Add an <|endoftext|> token\n",
    "        new_item += [pad_token_id]\n",
    "        # Pad sequences to batch_max_length\n",
    "        padded = (\n",
    "            new_item + [pad_token_id] *\n",
    "            (batch_max_length - len(new_item))\n",
    "        )\n",
    "        # Via padded[:-1], we remove the extra padded token\n",
    "        # that has been added via the +1 setting in batch_max_length\n",
    "        # (the extra padding token will be relevant in later codes)\n",
    "        inputs = torch.tensor(padded[:-1])\n",
    "        inputs_lst.append(inputs)\n",
    "\n",
    "    # Convert list of inputs to tensor and transfer to target device\n",
    "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
    "    return inputs_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "c0abd5e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,     1,     2,     3,     4],\n",
      "        [    5,     6, 50256, 50256, 50256],\n",
      "        [    7,     8,     9, 50256, 50256]])\n"
     ]
    }
   ],
   "source": [
    "inputs_1 = [0, 1, 2, 3, 4]\n",
    "inputs_2 = [5, 6]\n",
    "inputs_3 = [7, 8, 9]\n",
    "\n",
    "batch = (\n",
    "    inputs_1,\n",
    "    inputs_2,\n",
    "    inputs_3\n",
    ")\n",
    "\n",
    "print(custom_collate_draft_1(batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "87b28ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate_draft_2(\n",
    "    batch,\n",
    "    pad_token_id=50256,\n",
    "    device=\"cpu\"\n",
    "):\n",
    "    # Find the longest sequence in the batch\n",
    "    batch_max_length = max(len(item)+1 for item in batch)\n",
    "\n",
    "    # Pad and prepare inputs\n",
    "    inputs_lst, targets_lst = [], []\n",
    "\n",
    "    for item in batch:\n",
    "        new_item = item.copy()\n",
    "        # Add an <|endoftext|> token\n",
    "        new_item += [pad_token_id]\n",
    "        # Pad sequences to max_length\n",
    "        padded = (\n",
    "            new_item + [pad_token_id] *\n",
    "            (batch_max_length - len(new_item))\n",
    "        )\n",
    "        inputs = torch.tensor(padded[:-1])  # Truncate the last token for inputs\n",
    "        targets = torch.tensor(padded[1:])  # Shift +1 to the right for targets\n",
    "        inputs_lst.append(inputs)\n",
    "        targets_lst.append(targets)\n",
    "\n",
    "    # Convert list of inputs to tensor and transfer to target device\n",
    "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
    "    targets_tensor = torch.stack(targets_lst).to(device)\n",
    "    return inputs_tensor, targets_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "19d42768",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,     1,     2,     3,     4],\n",
      "        [    5,     6, 50256, 50256, 50256],\n",
      "        [    7,     8,     9, 50256, 50256]])\n",
      "tensor([[    1,     2,     3,     4, 50256],\n",
      "        [    6, 50256, 50256, 50256, 50256],\n",
      "        [    8,     9, 50256, 50256, 50256]])\n"
     ]
    }
   ],
   "source": [
    "inputs_1 = [0, 1, 2, 3, 4]\n",
    "inputs_2 = [5, 6]\n",
    "inputs_3 = [7, 8, 9]\n",
    "\n",
    "batch = (\n",
    "    inputs_1,\n",
    "    inputs_2,\n",
    "    inputs_3\n",
    ")\n",
    "\n",
    "inputs, targets = custom_collate_draft_2(batch)\n",
    "print(inputs)\n",
    "print(targets)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e97374f4",
   "metadata": {},
   "source": [
    "In the next step, we assign a -100 placeholder value to all padding tokens.\n",
    "This special value allows us to exclude these padding tokens from contributing to the training loss calculation, ensuring that only meaningful data influences model learning.\n",
    "\n",
    "In classification fine-tuning, we did not have to worry about this since we only trained the model based on the last output token.)\n",
    "Note that we retain one end-of-text token, ID 50256, in the target list.\n",
    "\n",
    "This allows the LLM to learn when to generate an end-of-text token in response to instructions, which we use as an indicator that the generated response is complete.\n",
    "\n",
    "In the following code, we modify our custom collate function to replace tokens with ID 50256 with -100 in the target lists.\n",
    "\n",
    "Additionally, we introduce an allowed_max_length parameter to optionally limit the length of the samples.\n",
    "\n",
    "This adjustment will be useful if you plan to work with your own datasets that exceed the 1024- token context size supported by the GPT-2 model.\n",
    "\n",
    "The code for this updated collate function is as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "7cd7bce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate_fn(\n",
    "    batch,\n",
    "    pad_token_id=50256,\n",
    "    ignore_index=-100,\n",
    "    allowed_max_length=None,\n",
    "    device=\"cpu\"\n",
    "):\n",
    "    # Find the longest sequence in the batch\n",
    "    batch_max_length = max(len(item)+1 for item in batch)\n",
    "\n",
    "    # Pad and prepare inputs and targets\n",
    "    inputs_lst, targets_lst = [], []\n",
    "\n",
    "    for item in batch:\n",
    "        new_item = item.copy()\n",
    "        # Add an <|endoftext|> token\n",
    "        new_item += [pad_token_id]\n",
    "        # Pad sequences to max_length\n",
    "        padded = (\n",
    "            new_item + [pad_token_id] *\n",
    "            (batch_max_length - len(new_item))\n",
    "        )\n",
    "        inputs = torch.tensor(padded[:-1])  # Truncate the last token for inputs\n",
    "        targets = torch.tensor(padded[1:])  # Shift +1 to the right for targets\n",
    "\n",
    "        # New: Replace all but the first padding tokens in targets by ignore_index\n",
    "        mask = targets == pad_token_id\n",
    "        indices = torch.nonzero(mask).squeeze()\n",
    "        if indices.numel() > 1:\n",
    "            targets[indices[1:]] = ignore_index\n",
    "\n",
    "        # New: Optionally truncate to maximum sequence length\n",
    "        if allowed_max_length is not None:\n",
    "            inputs = inputs[:allowed_max_length]\n",
    "            targets = targets[:allowed_max_length]\n",
    "\n",
    "        inputs_lst.append(inputs)\n",
    "        targets_lst.append(targets)\n",
    "\n",
    "    # Convert list of inputs and targets to tensors and transfer to target device\n",
    "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
    "    targets_tensor = torch.stack(targets_lst).to(device)\n",
    "\n",
    "    return inputs_tensor, targets_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "03b24d5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,     1,     2,     3,     4],\n",
      "        [    5,     6, 50256, 50256, 50256],\n",
      "        [    7,     8,     9, 50256, 50256]])\n",
      "tensor([[    1,     2,     3,     4, 50256],\n",
      "        [    6, 50256,  -100,  -100,  -100],\n",
      "        [    8,     9, 50256,  -100,  -100]])\n"
     ]
    }
   ],
   "source": [
    "inputs_1 = [0, 1, 2, 3, 4]\n",
    "inputs_2 = [5, 6]\n",
    "inputs_3 = [7, 8, 9]\n",
    "\n",
    "batch = (\n",
    "    inputs_1,\n",
    "    inputs_2,\n",
    "    inputs_3\n",
    ")\n",
    "\n",
    "inputs, targets = custom_collate_fn(batch)\n",
    "print(inputs)\n",
    "print(targets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "66426c6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.1269)\n"
     ]
    }
   ],
   "source": [
    "logits_1 = torch.tensor(\n",
    "    [[-1.0, 1.0],  # 1st training example\n",
    "     [-0.5, 1.5]]  # 2nd training example\n",
    ")\n",
    "targets_1 = torch.tensor([0, 1])\n",
    "\n",
    "\n",
    "loss_1 = torch.nn.functional.cross_entropy(logits_1, targets_1)\n",
    "print(loss_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "14d39c1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7936)\n"
     ]
    }
   ],
   "source": [
    "logits_2 = torch.tensor(\n",
    "    [[-1.0, 1.0],\n",
    "     [-0.5, 1.5],\n",
    "     [-0.5, 1.5]]  # New 3rd training example\n",
    ")\n",
    "targets_2 = torch.tensor([0, 1, 1])\n",
    "\n",
    "loss_2 = torch.nn.functional.cross_entropy(logits_2, targets_2)\n",
    "print(loss_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "d36da53e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.1269)\n",
      "loss_1 == loss_3: tensor(True)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "targets_3 = torch.tensor([0, 1, -100])\n",
    "\n",
    "loss_3 = torch.nn.functional.cross_entropy(logits_2, targets_3)\n",
    "print(loss_3)\n",
    "print(\"loss_1 == loss_3:\", loss_1 == loss_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d90c17",
   "metadata": {},
   "source": [
    "# Creating Data loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "495c5543",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: mps\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Note:\n",
    "# Uncommenting the following lines will allow the code to run on Apple Silicon chips, if applicable,\n",
    "# which is much faster than on an Apple CPU (as measured on an M3 MacBook Air).\n",
    "# However, the resulting loss values may be slightly different.\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "   device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "   device = torch.device(\"mps\")\n",
    "else:\n",
    "   device = torch.device(\"cpu\")\n",
    "\n",
    "print(\"Device:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b0fec95",
   "metadata": {},
   "source": [
    "Next, to reuse the chosen device setting in custom_collate_fn when we plug it into the PyTorch DataLoader class later in this section, we use the partial function from Python's functools standard library to create a new version of the function with the device argument pre-filled.\n",
    "\n",
    "Additionally, we set the allowed_max_length to 1024, which truncates the data to the maximum context length supported by the GPT-2 model we finetune later:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "66dcf506",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "customized_collate_fn = partial(custom_collate_fn, device=device, allowed_max_length=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "c81aa106",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "num_workers = 0\n",
    "batch_size = 8\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_dataset = InstructionDataset(train_data, tokenizer)\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "\n",
    "val_dataset = InstructionDataset(val_data, tokenizer)\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "\n",
    "test_dataset = InstructionDataset(test_data, tokenizer)\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=num_workers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "4ae1beec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 73]) torch.Size([8, 73])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 77]) torch.Size([8, 77])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 79]) torch.Size([8, 79])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 59]) torch.Size([8, 59])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 91]) torch.Size([8, 91])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 89]) torch.Size([8, 89])\n",
      "torch.Size([8, 59]) torch.Size([8, 59])\n",
      "torch.Size([8, 88]) torch.Size([8, 88])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 58]) torch.Size([8, 58])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 87]) torch.Size([8, 87])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 57]) torch.Size([8, 57])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 91]) torch.Size([8, 91])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 81]) torch.Size([8, 81])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 82]) torch.Size([8, 82])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 77]) torch.Size([8, 77])\n",
      "torch.Size([8, 91]) torch.Size([8, 91])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 78]) torch.Size([8, 78])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n"
     ]
    }
   ],
   "source": [
    "print(\"Train loader:\")\n",
    "for inputs, targets in train_loader:\n",
    "    print(inputs.shape, targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c82851c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
